---
layout: single
date:   2019-10-23 15:53:16 +0800
title: Machine Learning Part 5：Clustering
categories: machine_learning
excerpt: "Introduction to several useful unsupervised algorithms for clustering, dimensionality reduction and anomaly detection."


tags: clustering unsupervised pca k-means anomaly_detection
sidebar:
        nav: "docs"
toc_sticky: false
---

<h2 id="toc_0">Unsupervised Learning -- Clustering</h2>

<h3 id="toc_1">K-means Algorithms</h3>

<p>\[<br/>
\begin{array}{l}{\text { K-means algorithm }} \\ {\text { Input: }} \\ {\qquad \begin{array}{l}{-\quad K( \text { number of clusters) } } \\ {-\quad \text { Training set }\left\{x^{(1)}, x^{(2)}, \ldots, x^{(m)}\right\}} \\ {x^{(i)} \in \mathbb{R}^{n}\left(\text { drop } x_{0}=1 \text { convention }\right)}\end{array}}\end{array}\]</p>

<p>Algorithm:<br/>
\[\begin{array}{l}{\text { K-means algorithm }} \\ {\text { Randomly initialize } K \text { cluster centroids } \mu_{1}, \mu_{2}, \ldots, \mu_{K} \in \mathbb{R}^{n}} \\ {\text { Repeat }\{} \\ {\qquad \begin{aligned}\left.c^{(i)} :=\text { index ( from } 1 \text { to } K\right) \text { of cluster centroid }  \text { closest to } x^{(i)} \\ \mu_{k} :=\text { average (mean) of points assigned to cluster } k \end{aligned}}  \\ {}\end{array} \]</p>

<p>K-means for Non-separated clusters<br/>
<img src="media/15718172032236/15718196173619.jpg" alt="" style="width:652px;"/>￼</p>

<h3 id="toc_2">Optimization Objective for K-means</h3>

<p>\[\begin{array}{l}{J\left(c^{(1)}, \ldots, c^{(m)}, \mu_{1}, \ldots, \mu_{K}\right)=\frac{1}{m} \sum_{i=1}^{m}\left\|x^{(i)}-\mu_{c^{(i)}}\right\|^{2}} \\ {\min _{c^{(1)}, \ldots, c^{(m)}} J\left(c^{(1)}, \ldots, c^{(m)}, \mu_{1}, \ldots, \mu_{K}\right)} \\ {\mu_{1}, \ldots, \mu_{K}}\end{array}\]</p>

<p>where<br/>
\(\begin{aligned} c^{(i)} &amp;=\text { index of cluster }(1,2, \ldots, K) \text { to which example } x^{(i)} \text { is currently } \\ &amp; \text { assigned } \\ \mu_{k} &amp;=\text { cluster centroid } k\left(\mu_{k} \in \mathbb{R}^{n}\right) \end{aligned}\)</p>

<p>\(\begin{aligned} \mu_{c^{(i)}} &amp;=\text { cluster centroid of cluster to which example } x^{(i)} \text { has been } \\ &amp; \text { assigned } \end{aligned}\)</p>

<p><img src="media/15718172032236/15718355986198.jpg" alt="" style="width:500px;"/>￼</p>

<p>It is equivalent to repeatedly solving the optimization problem for \(C^{(i)} ～for ~i=1,...,m\) first, then for \(\mu_k ~for ~k=1,...,K\)</p>

<h3 id="toc_3">Initial Guesses - Random Initialization</h3>

<p>Bad starting point can lead to local optimum:<br/>
<img src="media/15718172032236/15718367117880.jpg" alt="" style="width:895px;"/>￼</p>

<p>Solution: more trials with different starting point.<br/>
Then pick the lowers cost function.</p>

<h3 id="toc_4">Choose the number of clusters</h3>

<p><img src="media/15718172032236/15718385140287.jpg" alt="" style="width:510px;"/>￼<br/>
Evaluate it based on the later/downstream purposes.<br/>
<img src="media/15718172032236/15718386040729.jpg" alt="" style="width:1039px;"/>￼</p>

<h2 id="toc_5">Dimensionality Reduction</h2>

<h3 id="toc_6">Motivation</h3>

<ul>
<li>Data </li>
<li>Data Visualization
<img src="media/15718172032236/15718450287423.jpg" alt="" style="width:916px;"/>￼</li>
</ul>

<p><img src="media/15718172032236/15718453210197.jpg" alt="" style="width:542px;"/>￼</p>

<p>But what is the meaning of these new features? -&gt; it is a difficult to explain. </p>

<h3 id="toc_7">Principle Component Analysis</h3>

<p><img src="media/15718172032236/15718459312632.jpg" alt="" style="width:572px;"/>￼<br/>
\[<br/>
\begin{array}{l}{\text { Reduce from n-dimension to k-dimension: Find } k \text { vectors } u^{(1)}, u^{(2)}, \ldots, u^{(k)}} \\ {\text { onto which to project the data, so as to minimize the projection error. }}\end{array}<br/>
\]</p>

<p><img src="media/15718172032236/15718470092968.jpg" alt="" style="width:800px;"/>￼</p>

<p>For the linear regression:<br/>
\(min ||Ax-y||^2\)<br/>
since \(Ax=(a1,a2,...,a_n)x\), the linear regression is essentially the projection of y onto the linear space of column vectors of A.</p>

<p>For the PCA, the first principle component is the one that:<br/>
\(\max ||A\mu||^2 \)</p>

<p>Mathematically, for the linear regression, it is a problem of project a point in \(R^m \) into the linear space of \(\{x_0,x_1,...,x_n\}\). In other words, the base is given. </p>

<p>for the PCA, however, it is a problem of find a sub-space for the data given, so that most of the information can be maintained. In other words, the task is to find the base of the sub-space. (\(\mu_1, ..., \mu_k \in R^n\))</p>

<h4 id="toc_8">Details in Mathematics</h4>

<p><strong>First Component</strong><br/>
In order to maximize variance, the first weight vector w(1) thus has to satisfy:<br/>
\({\mathbf  {w}}_{{(1)}}={\underset  {\Vert {\mathbf  {w}}\Vert =1}{\operatorname {\arg \,max}}}\,\left\{\sum _{i}\left(t_{1}\right)_{{(i)}}^{2}\right\}={\underset  {\Vert {\mathbf  {w}}\Vert =1}{\operatorname {\arg \,max}}}\,\left\{\sum _{i}\left({\mathbf  {x}}_{{(i)}}\cdot {\mathbf  {w}}\right)^{2}\right\}\)</p>

<p>Equivalently, writing this in matrix form gives<br/>
\({\displaystyle \mathbf {w} _{(1)}={\underset {\Vert \mathbf {w} \Vert =1}{\operatorname {\arg \,max} }}\,\{\Vert \mathbf {Xw} \Vert ^{2}\}={\underset {\Vert \mathbf {w} \Vert =1}{\operatorname {\arg \,max} }}\,\left\{\mathbf {w} ^{T}\mathbf {X^{T}} \mathbf {Xw} \right\}}\)<br/>
Since w(1) has been defined to be a unit vector, it equivalently also satisfies<br/>
\({\displaystyle \mathbf {w} _{(1)}={\operatorname {\arg \,max} }\,\left\{{\frac {\mathbf {w} ^{T}\mathbf {X^{T}} \mathbf {Xw} }{\mathbf {w} ^{T}\mathbf {w} }}\right\}}\)</p>

<p>The quantity to be maximised can be recognised as a Rayleigh quotient. A standard result for a positive semidefinite matrix such as \(X^TX\)  is that the quotient&#39;s maximum possible value is the largest <strong>eigenvalue</strong> of the matrix, which occurs when w is the corresponding <strong>eigenvector</strong>.</p>

<p>With \(w_{(1)}\) found, the first principal component of a data vector \(x_{(i)}\) can then be given as a score \(t_{1(i)} = x_{(i)} ⋅ w_{(1)}\) in the transformed co-ordinates,  or as the corresponding vector in the original variables \(t_{1(i)}w_{(1)} = &lt;x_{(i)} * w_{(1)}&gt;w_{(1)}\)</p>

<p><strong>Further Component</strong><br/>
The kth component can be found by subtracting the first k − 1 principal components from X:<br/>
\({\mathbf  {{\hat  {X}}}}_{{k}}={\mathbf  {X}}-\sum _{{s=1}}^{{k-1}}{\mathbf  {X}}{\mathbf  {w}}_{{(s)}}{\mathbf  {w}}_{{(s)}}^{{{\rm {T}}}}\)<br/>
and then finding the weight vector which extracts the maximum variance from this new data matrix<br/>
\({\mathbf  {w}}_{{(k)}}={\underset  {\Vert {\mathbf  {w}}\Vert =1}{\operatorname {arg\,max}}}\left\{\Vert {\mathbf  {{\hat  {X}}}}_{{k}}{\mathbf  {w}}\Vert ^{2}\right\}={\operatorname {\arg \,max}}\,\left\{{\tfrac  {{\mathbf  {w}}^{T}{\mathbf  {{\hat  {X}}}}_{{k}}^{T}{\mathbf  {{\hat  {X}}}}_{{k}}{\mathbf  {w}}}{{\mathbf  {w}}^{T}{\mathbf  {w}}}}\right\}\)</p>

<p>It turns out that this gives the remaining eigenvectors of \(X^TX\), with the maximum values for the quantity in brackets given by their corresponding eigenvalues. Thus the weight vectors are eigenvectors of \(X^TX\).<br/>
The full principal components decomposition of X can therefore be given as<br/>
\(\mathbf{T} = \mathbf{X} \mathbf{W}\)<br/>
where W is a p-by-p matrix of weights whose columns are the eigenvectors of \(X^TX\).  The transpose of W is sometimes called the whitening or sphering transformation.<br/>
Columns of W multiplied by the square root of corresponding eigenvalues, i.e. eigenvectors scaled up by the variances, are called loadings in PCA or in Factor analysis.</p>

<h4 id="toc_9">PCA algorithm</h4>

<p><strong>Step 1: Data Preprocessing</strong><br/>
Mean Normalization, so that the features centers in the original point. <br/>
Feature scaling is necessary;</p>

<p>\(X=\frac{[X-mean(X)]}{std(X)}\)<br/>
<img src="media/15718172032236/15718483847487.jpg" alt="" style="width:880px;"/>￼<br/>
<img src="media/15718172032236/15718487654558.jpg" alt="" style="width:507px;"/>￼</p>

<h4 id="toc_10">Vectorization:</h4>

<p>Mean normalization and optionally feature scaling:<br/>
\[X= \text{bsxfun}(@minus, X, mean(X,1))\]<br/>
\[\sum =\frac{1}{m} X^TX\]<br/>
\[[U,S,V]=svd(\sum )\]<br/>
Then we have: <br/>
\[<br/>
U=\left[\begin{array}{cccc}{|} &amp; {|} &amp; {} &amp; {|} \\ {u^{(1)}} &amp; {u^{(2)}} &amp; {\ldots} &amp; {u^{(n)}} \\ {|} &amp; {|} &amp; {} &amp; {|}\end{array}\right] \in \mathbb{R}^{n \times n}<br/>
\]</p>

<p>\(x\in R^n \to z\in R^k: \) <br/>
\(\text{Ureduce}=U(~: ~, 1:k)\)<br/>
\(z=\text{Ureduce}^T*X\)</p>

<p>Note 1: \(x_0^{i} \neq 0\) for this convention. <br/>
Note 2: \(U\) is from \(USV^*=X^TX\), therefore U is \(R^{n\times n}\). It is the eigenvector of X.</p>

<h3 id="toc_11">Applying PCA</h3>

<h4 id="toc_12">Reconstruction from compressed representation</h4>

<p>\(z=\text{Ureduce}^T*X \Longrightarrow X_{Approx}=\text{Ureduce}*z\)<br/>
here \( X_{Approx } \in R^n \)</p>

<h4 id="toc_13">Choose the number of principle component</h4>

<p><img src="media/15718172032236/15719080855261.jpg" alt="" style="width:594px;"/>￼</p>

<p>Since S is the eigenvalues for \(X^TX\), \(s_ii\) is actually the square of \(s_i\), which is the eigenvalue for X.</p>

<p>\[<br/>
\begin{array}{l}{\text { Choosing } k \text { (number of principal components) }} \\ {[\mathrm{U}, \mathrm{S}, \mathrm{V}]=\mathrm{svd}(\text { Sigma })} \\ {\text { Pick smallest value of } k \text { for which }} \\ {\qquad \frac{\sum_{i=1}^{k} S_{i i}}{\sum_{i=1}^{m} S_{i i}} \geq 0.99} \\ {\text { (99% of variance retained) }}\end{array}<br/>
\]</p>

<h3 id="toc_14">Advice for applying PCA</h3>

<h4 id="toc_15">Supervised learning speedup</h4>

<p><img src="media/15718172032236/15719091055242.jpg" alt="" style="width:617px;"/>￼<br/>
Note: must normalize the X before PCA. feature scaling is optional but recommended if large variance among features.</p>

<p>The same transformation must be done for \(x_{val}\) and \(x_{test}\)</p>

<p>In summary, application for PCA:</p>

<ul>
<li>Compression
<ul>
<li>Reduce memory/disk needed for storage of data</li>
<li>speed up learning algorithm</li>
</ul></li>
<li>Visualization</li>
</ul>

<p>Note: It might work ok, but it is generally a bad application to use PCA to prevent overfitting. Use regularization instead<br/>
\[<br/>
\min _{\theta} \frac{1}{2 m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right)^{2}+\frac{\lambda}{2 m} \sum_{j=1}^{n} \theta_{j}^{2}<br/>
\]<br/>
If the overfitting is the problem, utilization of PCA would probably throw away some useful information. </p>

<p>People like to utilized PCA for any ML problem:<br/>
\[<br/>
\begin{array}{l}{\text { Design of ML system: }} \\ {\text { - Get training set }\left\{\left(x^{(1)}, y^{(1)}\right),\left(x^{(2)}, y^{(2)}\right), \ldots,\left(x^{(m)}, y^{(m)}\right)\right\}} \\ {\left.\left. \text { - Run PCA to reduce } x^{(i)} \text { in dimension to get } z^{(i)} \right)\right\}} \\ {\text { - Train logistic regression on }\left\{\left(z^{(1)}, y^{(1)}\right), \ldots,\left(z^{(m)}, y^{(m)}\right)\right\}} \\ {\text { - Test on test set: Map } x_{t e s t}^{(i)} \text { to } z_{test}^{(i)} . \text { Run } h_{\theta}(z) \text { on }} \\ {\quad\left\{\left(z_{t e s t}^{(1)}, y_{t e s t}^{(1)}\right), \ldots,\left(z_{t e s t}^{(m)}, y_{t e s t}^{(m)}\right)\right\}}\end{array}<br/>
\]</p>

<p>Before implementing PCA, it is better to try running without the PCA with the original/raw data. Only if it does not do what is desired, then implement PCA.</p>

<h2 id="toc_16">Anomaly Detection</h2>

<h3 id="toc_17">Density Estimation</h3>

<h4 id="toc_18">Problem Motivation</h4>

<p><img src="media/15718172032236/15719110811698.jpg" alt="" style="width:497px;"/>￼</p>

<p><img src="media/15718172032236/15719111371947.jpg" alt="" style="width:474px;"/>￼</p>

<h4 id="toc_19">Algorithm for a Anomaly detection</h4>

<p><img src="media/15718172032236/15719183544358.jpg" alt="" style="width:529px;"/>￼</p>

<h3 id="toc_20">Building Anomaly Detection System</h3>

<p><img src="media/15718172032236/15719198195844.jpg" alt="" style="width:513px;"/>￼<br/>
Due to possible skewness of the data or label, the accuracy of prediction is not a good measure of the performance of algorithm.</p>

<ul>
<li>Possible evaluation metrics:</li>
</ul>

<p><strong>Precision</strong>:<br/>
\(\frac{\# True ~Positives}{\#~ Total~Predicted~Positives}\)<br/>
<strong>Recall</strong>:<br/>
\(\frac{\# True ~Positives}{\#~ Total~Actual~Positives}\)</p>

<p><img src="media/15689769464157/15689791419155.jpg" alt="" style="width:549px;"/>￼ </p>

<p>\(F_1 ~ Score=2 \frac{PR}{P+R}\)</p>

<ul>
<li>Use cross validation set to choose parameter \(\epsilon  \)</li>
</ul>

<h4 id="toc_21">Anomaly Detection (Gaussian) VS. Supervised Learning</h4>

<p>Since we have labeled data, why not just use supervised learning to detect to anomaly?</p>

<p><img src="media/15718172032236/15719205588140.jpg" alt="" style="width:592px;"/>￼<br/>
Few features: use anomaly detection, as the limited number of features make it hard to learn. </p>

<p><img src="media/15718172032236/15719207332155.jpg" alt="" style="width:595px;"/>￼</p>

<h4 id="toc_22">Choosing What Features to Use in the Anomaly Detection</h4>

<ul>
<li>If the feature is Non-Gaussian, it is better to transform the feature to be more like Gaussian distribution</li>
<li><p>If it is difficult to identify the anomaly with the current features, it will helpful if more features can be added, specially based on observation of anomaly. </p>
<h3 id="toc_23">Multivariant Gaussian Distribution</h3>
<p>In the previous anomaly detection algorithm, the features are assumed to be independent and normally distributed. If we want to consider the dependency or correlation among the n features, we can use multivariant gaussian distribution. <br/>
<img src="media/15718172032236/15719224082729.jpg" alt="" style="width:908px;"/>￼<br/>
Note: use PCA to capture the normal?<br/>
\[<br/>
\begin{array}{l}{\text { Multivariate Gaussian (Normal) distribution }} \\ {x \in \mathbb{R}^{n} . \text { Don&#39;t model } p\left(x_{1}\right), p\left(x_{2}\right), \ldots, \text { etc. separately. }} \\ {\text { Model } p(x) \text { all in one go. }} \\ {\text { Parameters: } \mu \in \mathbb{R}^{n}, \Sigma \in \mathbb{R}^{n \times n} \text { (covariance matrix) }}\end{array}<br/>
\]<br/>
\[{\displaystyle f_{\mathbf {X} }(x_{1},\ldots ,x_{k})={\frac {\exp \left(-{\frac {1}{2}}({\mathbf {x} }-{\boldsymbol {\mu }})^{\mathrm {T} }{\boldsymbol {\Sigma }}^{-1}({\mathbf {x} }-{\boldsymbol {\mu }})\right)}{\sqrt {(2\pi )^{k}|{\boldsymbol {\Sigma }}|}}}}\]<br/>
\[<br/>
\begin{array}{l}{\text { Parameters } \mu, \Sigma} \\ {\qquad p(x ; \mu, \Sigma)=\frac{1}{(2 \pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}} \exp \left(-\frac{1}{2}(x-\mu)^{T} \Sigma^{-1}(x-\mu)\right)}\end{array}<br/>
\]</p></li>
<li><p>Parameter Filtering:<br/>
Given training set \(\left\{x^{(1)}, x^{(2)}, \ldots, x^{(m)}\right\}\), we can calculate the parameters: <br/>
\[<br/>
\mu=\frac{1}{m} \sum_{i=1}^{m} x^{(i)} \quad \Sigma=\frac{1}{m} \sum_{i=1}^{m}\left(x^{(i)}-\mu\right)\left(x^{(i)}-\mu\right)^{T}<br/>
\]<br/>
here \(\mu , x^{(i)} \in R^n\), in other words:<br/>
\(\sum =E(X-\mu)^T (X-\mu)\)<br/>
here \(X=[{x^{(1)}}&#39;;{x^{(2)}}&#39;;...;{x^{(m)}}&#39;]\)<br/>
therefore we have:<br/>
\(X&#39;=[{x^{(1)}},{x^{(2)}},...,{x^{(m)}}]\)</p></li>
<li><p>Algorithm:<br/>
<img src="media/15718172032236/15719333498155.jpg" alt="" style="width:548px;"/>￼</p></li>
</ul>

<p>Note that for the multivariate gaussion:</p>

<ul>
<li>the n features \(\in R^m\) must be linearly independent, i.e. full rank of n:==&gt; must have m\(\geq\)n, otherwise we have some \(x^T \sum x=0\) which means \(\sum \) in non-invertible.</li>
<li>Computationally more expensive</li>
</ul>

<h2 id="toc_24">Recommender System</h2>

<h3 id="toc_25">Predicting Movie Rating</h3>

<p><img src="media/15718172032236/15719679748913.jpg" alt="" style="width:923px;"/>￼<br/>
Content Based Recommender system<br/>
<img src="media/15718172032236/15719919502453.jpg" alt="" style="width:1438px;"/>￼</p>

<p>Note: For each movie i, we have some features, with \(x^{(i)}_0=1\).</p>

<p><strong>Problem Formulation</strong><br/>
<img src="media/15718172032236/15719922485281.jpg" alt="" style="width:543px;"/>￼</p>

<p><strong>Optimization Objective</strong><br/>
<strong>To learn \(\theta^{(j)} \) (parameters for user j):</strong><br/>
\[\min _{\theta(j)} \frac{1}{2} \sum_{i: r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right)^{2}+\frac{\lambda}{2} \sum_{k=1}^{n}\left(\theta_{k}^{(j)}\right)^{2}\]<br/>
<strong>To learn \(\theta^{(j)}, \forall j\):</strong><br/>
\[\min _{\theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)}} \frac{1}{2} \sum_{j=1}^{n_{u}} \sum_{i: r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right)^{2}+\frac{\lambda}{2} \sum_{j=1}^{n_{u}} \sum_{k=1}^{n}\left(\theta_{k}^{(j)}\right)^{2}\]</p>

<p>My Thoughts:<br/>
After we get the \(\theta \in R^{n+1}\) for each user, we can try to use PCA to divide the user into a limited number of representative groups: \(Group_g,g=1,....,G\). <br/>
Since for these group, we can have more ratings available, we can get more information about this group, and derive better \(\theta\) for each of these group. <br/>
After this, we find the approximation to \(user_j\): which is a linear combination of \(Group_g,g=1,....,G\). <br/>
The r(i,j) is then approximated by the linear combination of the rating for the groups.</p>

<h3 id="toc_26">Collaborative Filtering</h3>

<p>A algorithm which can find which feature to use. <br/>
After we already get the \(\theta\) for the user, based on their ratings on a movie, we can estimate the features of the movie.</p>

<p><strong>Optimization Algorithm</strong><br/>
\[\begin{array}{l}{\text { Given } \theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)}, \text { to learn } x^{(i)}:} \\ {\quad \min _{x^{(i)}} \frac{1}{2} \sum_{j: r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right)^{2}+\frac{\lambda}{2} \sum_{k=1}^{n}\left(x_{k}^{(i)}\right)^{2}}\end{array}\]</p>

<p>Further, we can learn the features \(x_{k}\) for all the movies.<br/>
\[\begin{array}{l}{\text { Given } \theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)}, \text { to learn } x^{(1)}, \ldots, x^{\left(n_{m}\right)}:} \\ {\qquad \begin{array}{l}{\min _{x^{(1)}, \ldots, x^{\left(n_{m}\right)}} \frac{1}{2} \sum_{i=1}^{n_{m}} \sum_{j: r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right)^{2}+\frac{\lambda}{2} \sum_{i=1}^{n_{m}} \sum_{k=1}^{n}\left(x_{k}^{(i)}\right)^{2}}\end{array}} \\ \end{array}\]<br/>
<img src="media/15718172032236/15719956163624.jpg" alt="" style="width:495px;"/>￼</p>

<p><strong>Collaboration between users in the sense of better estimation of features:</strong> every user gives the system their preference, with which the system learn better feature x_i, and then further helping make the estimation of preference for each user.</p>

<h4 id="toc_27">Algorithm for Collaborative Filtering</h4>

<p>\(\text { Given } x^{(1)}, \ldots, x^{\left(n_{m}\right)}, \text { estimate } \theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)}:\)<br/>
\[\min _{\theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)}} \frac{1}{2} \sum_{j=1}^{n_{u}} \sum_{i: r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right)^{2}+\frac{\lambda}{2} \sum_{j=1}^{n_{u}} \sum_{k=1}^{n}\left(\theta_{k}^{(j)}\right)^{2}\]</p>

<p>\({\text { Given } \theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)}, \text { to learn } x^{(1)}, \ldots, x^{\left(n_{m}\right)}:}\)<br/>
\[\min _{x^{(1)}, \ldots, x^{\left(n_{m}\right)}} \frac{1}{2} \sum_{i=1}^{n_{m}} \sum_{j: r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right)^{2}+\frac{\lambda}{2} \sum_{i=1}^{n_{m}} \sum_{k=1}^{n}\left(x_{k}^{(i)}\right)^{2}\]</p>

<p>We combine this process:<br/>
\(\text { Minimizing } x^{(1)}, \ldots, x^{\left(n_{m}\right)} \text { and } \theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)} \text { simultaneously: }\)</p>

<p>\[J\left(x^{(1)}, \ldots, x^{\left(n_{m}\right)}, \theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)}\right)=\frac{1}{2} \sum_{(i, j): r(i, j)=1}\left(\left(\theta^{(j)}\right)^{T} x^{(i)}-y^{(i, j)}\right)^{2}+\frac{\lambda}{2} \sum_{i=1}^{n_{m}} \sum_{k=1}^{n}\left(x_{k}^{(i)}\right)^{2}+\frac{\lambda}{2} \sum_{j=1}^{n_{u}} \sum_{k=1}^{n}\left(\theta_{k}^{(j)}\right)^{2}\]</p>

<p>The optimization problem:<br/>
\[\min_{x,\theta} J(x,\theta)\]<br/>
where: <br/>
\(x=x^{(1)}, \ldots, x^{\left(n_{m}\right)}\)<br/>
\(\theta=\theta^{(1)}, \ldots, \theta^{\left(n_{u}\right)}\)</p>

<p>Note: when we combine the two learning process, we can get rid of \(x^{(i)}_0=1\). This is because the features can be learned during the process. If the algorithm really thinks a constant feature is needed, it will make one by itself during the iteration. </p>

<p>In conclusion:<br/>
<img src="media/15718172032236/15719970299401.jpg" alt="" style="width:619px;"/>￼<br/>
Note: </p>

<ul>
<li>here \(x,\theta \in R^n\) without the constant term. </li>
<li>The final predicted star rating is \(\theta^T x\)</li>
<li>Initialization of the x and \(\theta\) is for the purpose of breaking the symmetry and ensuring the learned \(x_i\) and \(\theta_j\) are different.</li>
</ul>

<h4 id="toc_28">Implementation/vectorization of Collaborative Filtering--Low Rank matrix Factorization</h4>

<p>For the collaborative filtering, we basically deal with the problem of finding parameters given the result.<br/>
<img src="media/15718172032236/15720756142253.jpg" alt="" style="width:701px;"/>￼<br/>
In other words:</p>

<p>\(Y= X^T *\theta \)<br/>
where <br/>
\(\Theta=[{\theta^{(1)}},\theta^{(2)},...,\theta^{(n_u)}]\)<br/>
\(X=[{x^{(1)}},x^{(2)},...,x^{(n_m)}]\)</p>

<h5 id="toc_29">Mathematics about Low-Rank matrix factorization</h5>

<p>\(\min \|\boldsymbol A - \boldsymbol UV^{T} \|_2 \text{,   subject to}~  rank(\boldsymbol UV^{T}) \leq r\), where \(\|\cdot\|_2\) denotes the Frobenius norm.</p>

<p>We start with the basic MF model, formulated as:<br/>
\[\min _{\mathbf{U}, \mathbf{V}}\left\|\mathbf{X}-\mathbf{U} \mathbf{V}^{T}\right\|+\mathcal{L}(\mathbf{U}, \mathbf{V})\]<br/>
where \(X\in R^{m\times n}\) is the data matrix to be approximated, and \(U\in R^{m\times k},V\in R^{n\times k}\) are two low-dimensional matrices (\(k&lt;&lt;min(m,m)\)), \(\mathcal{L}(U,V)\) is a regularization part to avoid overfitting.</p>

<h4 id="toc_30">Implementation/vectorization of Collaborative Filtering--Mean Normalization</h4>

<p>If we do not have a mean normalization process, then for a guy that gives no rating, the \(\theta\) will be set to be 0. In this case, no recommendation can be made, as the predicted ratings will be 0 for any movie. <br/>
<img src="media/15718172032236/15720780158815.jpg" alt="" style="width:815px;"/>￼</p>

<h4 id="toc_31">Implementation of mean normalization</h4>

<p>\(Y=\left[\begin{array}{lllll}{5} &amp; {5} &amp; {0} &amp; {0} &amp; {?} \\ {5} &amp; {?} &amp; {?} &amp; {0} &amp; {?} \\ {?} &amp; {4} &amp; {0} &amp; {?} &amp; {?} \\ {0} &amp; {0} &amp; {5} &amp; {4} &amp; {?} \\ {0} &amp; {0} &amp; {5} &amp; {0} &amp; {?}\end{array}\right]\)</p>

<p>then we can compute the average rating:<br/>
\(\mu=\left[\begin{array}{c}{2.5} \\ {2.5} \\ {2} \\ {2.25} \\ {1.25}\end{array}\right]\)</p>

<p>bsfun(@minus,Y,mu):<br/>
\(Y=\left[\begin{array}{ccccc}{2.5} &amp; {2.5} &amp; {-2.5} &amp; {-2.5} &amp; {?} \\ {2.5} &amp; {?} &amp; {?} &amp; {-2.5} &amp; {?} \\ {?} &amp; {2} &amp; {-2} &amp; {?} &amp; {?} \\ {-2.25} &amp; {-2.25} &amp; {2.75} &amp; {1.75} &amp; {?} \\ {-1.25} &amp; {-1.25} &amp; {3.75} &amp; {-1.25} &amp; {?}\end{array}\right]\)</p>

<p>Now for user j and movie i, the predicted rating is:<br/>
\(&lt;\theta^{(j)},x^{(i)} &gt;+\mu_i\)</p>

<p>In this case, even for the user who has not given any ratings, the ratings can be predicted as \(0+\mu\).</p>

