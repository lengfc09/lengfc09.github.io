I"&:<p class="notice--info">This series of Data Science posts are my notes for the <a href="https://www.coursera.org/professional-certificates/ibm-data-science">IBM Data Science Professional Certificate</a>.</p>

<p><strong>Skills:</strong></p>

<ul>
  <li>Regression: predicting continuous values</li>
  <li>Classification: predicting the item class of a case</li>
  <li>Clustering: finding the structure of data, summarization</li>
  <li>Associations: associating frequent co-occurring items/events</li>
  <li>Anomaly detection: discovering abnormal and unusual cases</li>
  <li>Sequence mining: predicting next events</li>
  <li>Dimension Reduction: reducing the size of data(PCA)</li>
  <li>Recommendation systems</li>
  <li>Scikit Learn:</li>
  <li>Scipy</li>
</ul>

<p><strong>Projects:</strong></p>

<ul>
  <li>Cancer detection</li>
  <li>Predicting economic trends</li>
  <li>Predicting customer churn</li>
  <li>Recommendation Engines</li>
  <li>Many more..</li>
</ul>

<h2 id="introduction-to-machine-learning">Introduction to Machine Learning</h2>

<p><strong>What is machine learning?</strong>
Machine learning is the subfield of computer science that gives “computers the ability to learn without being explicitly programmed.”</p>

<p><strong>Difference bewteen artificial intelligence, machine learning, and deep learning.</strong></p>

<ul>
  <li>AI components: AI tries to make computers intelligent in order to mimic the cognitive functions of humans.
    <ul>
      <li>Computer vision</li>
      <li>Language processing</li>
      <li>Creativity</li>
      <li>Summarization.</li>
    </ul>
  </li>
  <li>Machine Learning: Machine Learning is the branch of AI that covers the statistical part of artificial intelligence. It teaches the computer to solve problems by looking at hundreds or thousands of examples, learning from them, and then using that experience to solve the same problem in new situations.
    <ul>
      <li>Classification</li>
      <li>Clustering</li>
      <li>Neural Network</li>
    </ul>
  </li>
  <li>Revolution in ML
    <ul>
      <li>Deep learning: Deep Learning is a very special field of Machine Learning where computers can actually learn and make intelligent decisions on their own.</li>
    </ul>
  </li>
</ul>

<h3 id="python-for-machine-learning">Python for Machine Learning</h3>

<p><strong>Numpy</strong>
The first package is NumPy which is a math library to work with N-dimensional arrays in Python. It enables you to do computation efficiently and effectively. It is better than regular Python because of its amazing capabilities</p>

<p><strong>Scipy</strong> is a collection of numerical algorithms and domain specific toolboxes, including signal processing, optimization, statistics and much more</p>

<p><strong>Pandas</strong> library is a very high-level Python library that provides high performance easy to use data structures. It has many functions for data importing, manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and timeseries.</p>

<p><strong>SciKit Learn</strong> is a collection of algorithms and tools for machine learning</p>

<p>Most of the tasks that need to be done in a machine learning pipeline are implemented already in Scikit Learn including pre-processing of data, feature selection, feature extraction, train test splitting, defining the algorithms, fitting models, tuning parameters, prediction, evaluation, and exporting the model.</p>

<h3 id="supervised-vs-unsupervised">Supervised vs Unsupervised</h3>

<p><strong>Supervised:</strong> deal with labeled data</p>

<ul>
  <li>regression</li>
  <li>classification</li>
</ul>

<p><strong>Unsupervised:</strong> deal with unlabeled data</p>

<ul>
  <li>dimension reduction</li>
  <li>density estimate</li>
  <li>market basket analysis</li>
  <li>clustering
    <ul>
      <li>Discovering structure</li>
      <li>Summarization</li>
      <li>Anomaly detection</li>
    </ul>
  </li>
</ul>

<h2 id="introduction-to-regression">Introduction to Regression</h2>

<p><strong>Regression algorithms:</strong></p>

<p><img src="/media/15842755659220/15842791297055.jpg" alt="-w600" width="600px" /></p>

<h3 id="model-evaluation-approaches">Model Evaluation approaches</h3>

<ul>
  <li>Train and Test on the same Dataset</li>
  <li>Train/Test split</li>
  <li>Regression Evaluation Metrics</li>
</ul>

<p><strong>Training Accuracy:</strong></p>

<ul>
  <li>High training accuracy isn’t necessarily a good thing</li>
  <li>Result of over-fitting: the model is overly trained to the dataset, which may capture noise and produce a non-generalized model.</li>
</ul>

<p><strong>Out-of-sample accuracy</strong></p>

<p><img src="/media/15842755659220/15842796732468.jpg" alt="-w800" width="600px" /></p>

<p>Since the result highly depend on which datasets the data is trained and tested, we better use <strong>K-fold cross-validation</strong>.</p>

<p><img src="/media/15842755659220/15842798152714.jpg" alt="-w800" width="600px" /></p>

<p><strong>Evaluation Metrics in regression models</strong></p>

<ul>
  <li>R square：R^2=1-RSE</li>
  <li>MSE: mean square error</li>
  <li>MAE: mean absolute error</li>
  <li>RMES: root of mean square error</li>
  <li>RSE: relative square error</li>
  <li>
    <p>RAE: relative average error</p>

    <p><img src="/media/15842755659220/15842800057018.jpg" alt="-w260" width="260px" /></p>
  </li>
</ul>

<h3 id="lab-section---linear-regression">Lab section - Linear Regression</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="n">pl</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="err">!</span><span class="n">wget</span> <span class="o">-</span><span class="n">O</span> <span class="n">FuelConsumption</span><span class="p">.</span><span class="n">csv</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">s3</span><span class="o">-</span><span class="n">api</span><span class="p">.</span><span class="n">us</span><span class="o">-</span><span class="n">geo</span><span class="p">.</span><span class="n">objectstorage</span><span class="p">.</span><span class="n">softlayer</span><span class="p">.</span><span class="n">net</span><span class="o">/</span><span class="n">cf</span><span class="o">-</span><span class="n">courses</span><span class="o">-</span><span class="n">data</span><span class="o">/</span><span class="n">CognitiveClass</span><span class="o">/</span><span class="n">ML0101ENv3</span><span class="o">/</span><span class="n">labs</span><span class="o">/</span><span class="n">FuelConsumptionCo2</span><span class="p">.</span><span class="n">csv</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"FuelConsumption.csv"</span><span class="p">)</span>

<span class="c1"># use color map to see the correlation
</span><span class="n">cdf</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'ENGINESIZE'</span><span class="p">,</span><span class="s">'CYLINDERS'</span><span class="p">,</span><span class="s">'FUELCONSUMPTION_COMB'</span><span class="p">,</span><span class="s">'CO2EMISSIONS'</span><span class="p">]]</span>
<span class="n">cdf</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span>
<span class="n">cdf</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pcolor</span><span class="p">(</span><span class="n">cdf</span><span class="p">.</span><span class="n">corr</span><span class="p">())</span>
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># scatter plot
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cdf</span><span class="p">.</span><span class="n">FUELCONSUMPTION_COMB</span><span class="p">,</span> <span class="n">cdf</span><span class="p">.</span><span class="n">CO2EMISSIONS</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"FUELCONSUMPTION_COMB"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Emission"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1"># Lets split our dataset into train and test sets, 80% of the entire data for training, and the 20% for testing. We create a mask to select random rows using np.random.rand() function:
</span>
<span class="n">msk</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.8</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">cdf</span><span class="p">[</span><span class="n">msk</span><span class="p">]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">cdf</span><span class="p">[</span><span class="o">~</span><span class="n">msk</span><span class="p">]</span>

<span class="c1"># Train Data Distribution
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">ENGINESIZE</span><span class="p">,</span> <span class="n">train</span><span class="p">.</span><span class="n">CO2EMISSIONS</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Engine size"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Emission"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># modeling with sklearn package
</span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="n">lr</span><span class="o">=</span><span class="n">linear_model</span><span class="p">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="c1"># Note the X must be a matrix, and must use [['col_Xs']]
</span><span class="n">lr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="s">'ENGINESIZE'</span><span class="p">]],</span><span class="n">train</span><span class="p">[</span><span class="s">'CO2EMISSIONS'</span><span class="p">])</span>
<span class="n">lr</span><span class="p">.</span><span class="n">coef_</span>
<span class="n">lr</span><span class="p">.</span><span class="n">intercept_</span>


<span class="c1"># plot output
</span><span class="n">train_X</span><span class="o">=</span><span class="n">train</span><span class="p">[[</span><span class="s">'ENGINESIZE'</span><span class="p">]]</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">ENGINESIZE</span><span class="p">,</span> <span class="n">train</span><span class="p">.</span><span class="n">CO2EMISSIONS</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train_X</span><span class="p">),</span> <span class="s">'-r'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Engine size"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Emission"</span><span class="p">)</span>

<span class="c1"># Evaluation
</span><span class="n">lr</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s">'ENGINESIZE'</span><span class="p">]],</span> <span class="n">test</span><span class="p">.</span><span class="n">CO2EMISSIONS</span><span class="p">)</span>

<span class="c1"># or use r2_score for non-linear regression
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s">'ENGINESIZE'</span><span class="p">]])</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s">'CO2EMISSIONS'</span><span class="p">]])</span>
<span class="n">test_y_hat</span> <span class="o">=</span> <span class="n">lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Mean absolute error: %.2f"</span> <span class="o">%</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">test_y_hat</span> <span class="o">-</span> <span class="n">test_y</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Residual sum of squares (MSE): %.2f"</span> <span class="o">%</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">test_y_hat</span> <span class="o">-</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"R2-score: %.2f"</span> <span class="o">%</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test_y_hat</span> <span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="p">)</span>


<span class="c1"># Note that, r2_socre(y_hat, y_real)
</span></pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="non-linear-regression">Non-Linear Regression</h3>

<p>It is important to pick a regression model that fits the data the best.</p>

<p><img src="/media/15842755659220/15842826072287.jpg" alt="-w700" width="600px" /></p>

<p>How should I model my data, if it displays non-linear on a scatter plot?</p>

<ul>
  <li>Polynomial regression</li>
  <li>Non-Linear regression model</li>
  <li>transform the data</li>
</ul>

<h3 id="lab-polynomial-regression">Lab: Polynomial regression</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="s">'ENGINESIZE'</span><span class="p">]])</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">train</span><span class="p">[[</span><span class="s">'CO2EMISSIONS'</span><span class="p">]])</span>

<span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s">'ENGINESIZE'</span><span class="p">]])</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asanyarray</span><span class="p">(</span><span class="n">test</span><span class="p">[[</span><span class="s">'CO2EMISSIONS'</span><span class="p">]])</span>


<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">train_x_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
<span class="n">train_x_poly</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="p">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x_poly</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
<span class="c1"># The coefficients
</span><span class="k">print</span> <span class="p">(</span><span class="s">'Coefficients: '</span><span class="p">,</span> <span class="n">clf</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Intercept: '</span><span class="p">,</span><span class="n">clf</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>


<span class="c1"># Print the output
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">ENGINESIZE</span><span class="p">,</span> <span class="n">train</span><span class="p">.</span><span class="n">CO2EMISSIONS</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>
<span class="n">XX</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="c1"># Note that we only accept the matrix as input for the predcit and fit function! Better use reshape(-1,1)
</span><span class="n">yy</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">poly</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">XX</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="s">'-r'</span> <span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Engine size"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Emission"</span><span class="p">)</span>

<span class="c1"># Evaluation
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="n">test_x_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
<span class="n">test_y_</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_x_poly</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Mean absolute error: %.2f"</span> <span class="o">%</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">test_y_</span> <span class="o">-</span> <span class="n">test_y</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Residual sum of squares (MSE): %.2f"</span> <span class="o">%</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">test_y_</span> <span class="o">-</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"R2-score: %.2f"</span> <span class="o">%</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test_y_</span> <span class="p">,</span> <span class="n">test_y</span><span class="p">)</span> <span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="lab-non-linear-regression-analysis">Lab: Non-linear regression analysis</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

<span class="c1">##You can adjust the slope and intercept to verify the changes in the graph
</span><span class="n">y</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">3</span>
<span class="n">y_noise</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
<span class="n">ydata</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">y_noise</span>
<span class="c1">#plt.figure(figsize=(8,6))
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span>  <span class="s">'bo'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Dependent Variable'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Indepdendent Variable'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p>Non-linear regressions are a relationship between independent variables $x$ and a dependent variable $y$ which result in a non-linear function modeled data. Essentially any relationship that is not linear can be termed as non-linear, and is usually represented by the polynomial of $k$ degrees (maximum power of $x$).</p>

\[\ y = a x^3 + b x^2 + c x + d \\]

<p>Non-linear functions can have elements like exponentials, logarithms, fractions, and others. For example: 
\(y = \log(x)\)</p>

<p>Or even, more complicated such as :</p>

\[y = \log(a x^3 + b x^2 + c x + d)\]

<p><strong>Non-linear regression example</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="c1">#downloading dataset
</span><span class="err">!</span><span class="n">wget</span> <span class="o">-</span><span class="n">nv</span> <span class="o">-</span><span class="n">O</span> <span class="n">china_gdp</span><span class="p">.</span><span class="n">csv</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">s3</span><span class="o">-</span><span class="n">api</span><span class="p">.</span><span class="n">us</span><span class="o">-</span><span class="n">geo</span><span class="p">.</span><span class="n">objectstorage</span><span class="p">.</span><span class="n">softlayer</span><span class="p">.</span><span class="n">net</span><span class="o">/</span><span class="n">cf</span><span class="o">-</span><span class="n">courses</span><span class="o">-</span><span class="n">data</span><span class="o">/</span><span class="n">CognitiveClass</span><span class="o">/</span><span class="n">ML0101ENv3</span><span class="o">/</span><span class="n">labs</span><span class="o">/</span><span class="n">china_gdp</span><span class="p">.</span><span class="n">csv</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"china_gdp.csv"</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># plot the data
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"Year"</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">"Value"</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="s">'ro'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'GDP'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Year'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># choosing a model
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mf">5.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">X</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Dependent Variable'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Indepdendent Variable'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The formula for the logistic function is the following:</p>

\[\hat{Y} = \frac1{1+e^{-\beta_1(X-\beta_2)}}\]

<p>$\beta_1$: Controls the curve’s steepness,</p>

<p>$\beta_2$: Slides the curve on the x-axis.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Beta_1</span><span class="p">,</span> <span class="n">Beta_2</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">Beta_1</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">Beta_2</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">y</span>

<span class="n">beta_1</span> <span class="o">=</span> <span class="mf">0.10</span>
<span class="n">beta_2</span> <span class="o">=</span> <span class="mf">1990.0</span>

<span class="c1">#logistic function
</span><span class="n">Y_pred</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">beta_1</span> <span class="p">,</span> <span class="n">beta_2</span><span class="p">)</span>

<span class="c1">#plot initial prediction against datapoints
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">Y_pred</span><span class="o">*</span><span class="mf">15000000000000.</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="s">'ro'</span><span class="p">)</span>


<span class="c1"># find the best parameters
# Lets normalize our data
</span><span class="n">xdata</span> <span class="o">=</span><span class="n">x_data</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span>
<span class="n">ydata</span> <span class="o">=</span><span class="n">y_data</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">y_data</span><span class="p">)</span>


</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>How we find the best parameters for our fit line?</strong>
we can use <strong>curve_fit</strong> which uses non-linear least squares to fit our sigmoid function, to data. Optimal values for the parameters so that the sum of the squared residuals of sigmoid(xdata, *popt) - ydata is minimized.</p>

<p>popt are our optimized parameters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">curve_fit</span>
<span class="n">popt</span><span class="p">,</span> <span class="n">pcov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">,</span> <span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">)</span>
<span class="c1">#print the final parameters
</span><span class="k">print</span><span class="p">(</span><span class="s">" beta_1 = %f, beta_2 = %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">popt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">popt</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># Now plot the output
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1960</span><span class="p">,</span> <span class="mi">2015</span><span class="p">,</span> <span class="mi">55</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">popt</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="s">'ro'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'data'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'fit'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'GDP'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Year'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1"># evaluation
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="c1"># split data into train/test
</span><span class="n">msk</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.8</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">xdata</span><span class="p">[</span><span class="n">msk</span><span class="p">]</span>
<span class="n">test_x</span> <span class="o">=</span> <span class="n">xdata</span><span class="p">[</span><span class="o">~</span><span class="n">msk</span><span class="p">]</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">ydata</span><span class="p">[</span><span class="n">msk</span><span class="p">]</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">ydata</span><span class="p">[</span><span class="o">~</span><span class="n">msk</span><span class="p">]</span>

<span class="c1"># build the model using train set
</span><span class="n">popt</span><span class="p">,</span> <span class="n">pcov</span> <span class="o">=</span> <span class="n">curve_fit</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>

<span class="c1"># predict using test set
</span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="o">*</span><span class="n">popt</span><span class="p">)</span>

<span class="c1"># Finally we have the following result:
</span><span class="k">print</span><span class="p">(</span><span class="s">"Mean absolute error: %.2f"</span> <span class="o">%</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">absolute</span><span class="p">(</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">test_y</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Residual sum of squares (MSE): %.2f"</span> <span class="o">%</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">test_y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="k">print</span><span class="p">(</span><span class="s">"R2-score: %.2f"</span> <span class="o">%</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test_y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span> <span class="p">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="introduction-to-classification">Introduction to Classification</h2>

<p>Classification algorithms in machine learning:</p>

<ul>
  <li>Decision Trees</li>
  <li>Naive Bayes</li>
  <li>Linear Discriminant Analysis</li>
  <li>K-nearest Neighbor</li>
  <li>Logistic Regression</li>
  <li>Neural Networks</li>
  <li>Support Vector Machines (SVM)</li>
</ul>

<h3 id="k-nearest-neighbors">K-Nearest Neighbors</h3>

<h4 id="supervised-learning-case">Supervised Learning case</h4>

<ol>
  <li>Pick a value for K</li>
  <li>Calculate the distance of unknown case from all cases.</li>
  <li>Select the K-observations in the training data that are ‘nearest’ the unknown data point.</li>
  <li>Predict the response of the unknown data point using the most popular response value from the K-nearest neighbors.</li>
</ol>

<p><strong>K=1</strong>: overfitting.
<strong>K too big</strong>: high train error
<strong>Plot accuracy VS K</strong>: find the optimal K.</p>

<h4 id="lab-knn">Lab: KNN</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="n">NullFormatter</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.ticker</span> <span class="k">as</span> <span class="n">ticker</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c1"># Load Data
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'teleCust1000t.csv'</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">df</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">column</span><span class="o">=</span><span class="s">'income'</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'region'</span><span class="p">,</span> <span class="s">'tenure'</span><span class="p">,</span><span class="s">'age'</span><span class="p">,</span> <span class="s">'marital'</span><span class="p">,</span> <span class="s">'address'</span><span class="p">,</span> <span class="s">'income'</span><span class="p">,</span> <span class="s">'ed'</span><span class="p">,</span> <span class="s">'employ'</span><span class="p">,</span><span class="s">'retire'</span><span class="p">,</span> <span class="s">'gender'</span><span class="p">,</span> <span class="s">'reside'</span><span class="p">]]</span> <span class="p">.</span><span class="n">values</span>  <span class="c1">#.astype(float)
</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'custcat'</span><span class="p">].</span><span class="n">values</span>
<span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>


<span class="c1"># Preprocess Data
# Normalize Data
</span><span class="n">X</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))</span>
<span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># Train Test Split
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Train set:'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span>  <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Test set:'</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span>  <span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Train data
</span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">6</span>
<span class="c1">#Train Model and Predict
</span><span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">k</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">neigh</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">neigh</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># Evaluation
</span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Train set Accuracy: "</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">neigh</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Test set Accuracy: "</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">))</span>


<span class="c1"># Plot accuracy VS K
</span>
<span class="n">Ks</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">mean_acc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Ks</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">std_acc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Ks</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">ConfustionMx</span> <span class="o">=</span> <span class="p">[];</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">Ks</span><span class="p">):</span>

    <span class="c1">#Train Model and Predict
</span>    <span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">n</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">yhat</span><span class="o">=</span><span class="n">neigh</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">mean_acc</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>


    <span class="n">std_acc</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">yhat</span><span class="o">==</span><span class="n">y_test</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">yhat</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">mean_acc</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">Ks</span><span class="p">),</span><span class="n">mean_acc</span><span class="p">,</span><span class="s">'g'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">Ks</span><span class="p">),</span><span class="n">mean_acc</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">std_acc</span><span class="p">,</span><span class="n">mean_acc</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">std_acc</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">((</span><span class="s">'Accuracy '</span><span class="p">,</span> <span class="s">'+/- 3xstd'</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Accuracy '</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Number of Nabors (K)'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="evaluation-metrics-in-classification">Evaluation metrics in classification</h3>

<p><strong>Jaccard index:</strong>
$\begin{equation}
J(y, \hat{y})=\frac{|y \cap \hat{y}|}{|y \cup \hat{y}|}=\frac{|y \cap \hat{y}|}{|y|+|\hat{y}|-|y \cap \hat{y}|}
\end{equation}$</p>

<p><strong>F1-score</strong></p>

<ul>
  <li>Precision = TP/(TP+FP)</li>
  <li>Recall = TP/(TP+FN)</li>
  <li>$F1-score= \frac{2<em>Pre</em>Rec}{(Pre+Rec)}$</li>
</ul>

<p><img src="/media/15689769464157/15689791419155.jpg" alt="-w549" width="600px" /></p>

<p>$F_1 ~ Score=2 \frac{PR}{P+R}$</p>

<p><strong>Log loss</strong>
The cost function for logistic regression:</p>

\[\begin{array}{ll}{J(\theta)=\frac{1}{m} \sum_{i=1}^{m} \operatorname{cost}\left(h_{\theta}\left(x^{(i)}\right), y^{(i)}\right)} \\ {\operatorname{Cost}\left(h_{\theta}(x), y\right)=-\log \left(h_{\theta}(x)\right)} &amp; {\text { if } y=1} \\ {\operatorname{Cost}\left(h_{\theta}(x), y\right)=-\log \left(1-h_{\theta}(x)\right)} &amp; {\text { if } y=0}\end{array}\]

<p>Log loss:
$\begin{equation}
\text { LogLoss }=-\frac{1}{n} \sum[y \times \log (\hat{y})+(1-y) \times \log (1-\hat{y})]
\end{equation}$</p>

<p>where: y is the actual value, $\hat{y}$ is the predicted value.</p>

<h3 id="decisions-tress">Decisions Tress</h3>

<p><img src="/media/15842755659220/15843682196886.jpg" alt="-w700" width="600px" /></p>

<p><strong>Algorithm:</strong></p>

<ol>
  <li>Choose an attribute from your dataset</li>
  <li>Calculate the significance of attribute in splitting of data</li>
  <li>Split data based on the value of the best attribute</li>
  <li>Go to step 1</li>
</ol>

<p>Apparently, the most import step in decision tree model is to find the <strong>best attribute</strong>.</p>

<p><img src="/media/15842755659220/15843685879908.jpg" alt="-w700" width="600px" /></p>

<p><strong>Entropy:</strong> measure of randomness or uncertainty.
The lower the Entropy, the less uniform the distribution, the purer the node.</p>

\[Entropy=-p(A)log_2 (p(A))-p(B)log_2 (p(B))\]

<p>Which Attribute?
-&gt; The Tree with the higher <strong>information gain</strong> after splitting.</p>

<p><strong>Information gain</strong> is the information tha can increase the level of certainty after splitting.</p>

<p>$information gain = \text{Entropy before split} - \text{Weighted Entropy after split}$</p>

<p><img src="/media/15842755659220/15843699345073.jpg" alt="-w600" width="600px" /></p>

<p>we then repeat the process for each branch to reach the most pure leaves.</p>

\[Entropy=-p(A)log_2 (p(A))-p(B)log_2 (p(B))\]

<p>Given a random variable ${\displaystyle X}$, with possible outcomes ${\displaystyle x_{i}}$, each with probability ${\displaystyle P_{X}(x_{i})}$, the entropy ${\displaystyle H(X)}$ of ${\displaystyle X}$ is as follows:</p>

\[H(X)=-\sum _{i}P_{X}(x_{i})\log _{b}{P_{X}(x_{i})}=\sum _{i}P_{X}(x_{i})I_{X}(x_{i})=\operatorname {E} [I_{X}]\]

<p>where ${\displaystyle I_{X}(x_{i})}$ is the self-information associated with particular outcome; ${\displaystyle I_{X}}$ is the self-information of the random variable X in general, treated as a new derived random variable; and ${\displaystyle \operatorname {E} [I_{X}]}$ is the expected value of this new random variable, equal to the sum of the self-information of each outcome, weighted by the probability of each outcome occurring[3]; and b, the base of the logarithm, is a new parameter that can be set different ways to determine the choice of units for information entropy.</p>

<p>Information entropy is typically measured in bits (alternatively called “shannons”), corresponding to base 2 in the above equation. It is also sometimes measured in “natural units” (nats), corresponding to base e, or decimal digits (called “dits”, “bans”, or “hartleys”), corresponding to base 10.</p>

<h4 id="lab-decisiontreeclassifier">Lab: DecisionTreeClassifier</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="c1">#Load Data
</span><span class="n">my_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"drug200.csv"</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">","</span><span class="p">)</span>

<span class="c1"># Preprocessing
</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">my_data</span><span class="p">[[</span><span class="s">'Age'</span><span class="p">,</span> <span class="s">'Sex'</span><span class="p">,</span> <span class="s">'BP'</span><span class="p">,</span> <span class="s">'Cholesterol'</span><span class="p">,</span> <span class="s">'Na_to_K'</span><span class="p">]].</span><span class="n">values</span>
<span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="n">le_sex</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_sex</span><span class="p">.</span><span class="n">fit</span><span class="p">([</span><span class="s">'F'</span><span class="p">,</span><span class="s">'M'</span><span class="p">])</span>
<span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_sex</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>


<span class="n">le_BP</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_BP</span><span class="p">.</span><span class="n">fit</span><span class="p">([</span> <span class="s">'LOW'</span><span class="p">,</span> <span class="s">'NORMAL'</span><span class="p">,</span> <span class="s">'HIGH'</span><span class="p">])</span>
<span class="n">X</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_BP</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">2</span><span class="p">])</span>


<span class="n">le_Chol</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_Chol</span><span class="p">.</span><span class="n">fit</span><span class="p">([</span> <span class="s">'NORMAL'</span><span class="p">,</span> <span class="s">'HIGH'</span><span class="p">])</span>
<span class="n">X</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_Chol</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">3</span><span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">my_data</span><span class="p">[</span><span class="s">"Drug"</span><span class="p">]</span>

<span class="c1">#Split the data
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_trainset</span><span class="p">,</span> <span class="n">X_testset</span><span class="p">,</span> <span class="n">y_trainset</span><span class="p">,</span> <span class="n">y_testset</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>


<span class="c1"># Train the model
</span><span class="n">drugTree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s">"entropy"</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">drugTree</span> <span class="c1"># it shows the default parameters
</span>
<span class="n">drugTree</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_trainset</span><span class="p">,</span><span class="n">y_trainset</span><span class="p">)</span>

<span class="n">predTree</span> <span class="o">=</span> <span class="n">drugTree</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_testset</span><span class="p">)</span>

<span class="c1"># Evaluation
</span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="k">print</span><span class="p">(</span><span class="s">"DecisionTrees's Accuracy: "</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_testset</span><span class="p">,</span> <span class="n">predTree</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="logistic-regression">Logistic Regression</h3>

<p>While Linear Regression is suited for estimating continuous values (e.g. estimating house price), it is not the best tool for predicting the class of an observed data point. In order to estimate the class of a data point, we need some sort of guidance on what would be the <b>most probable class</b> for that data point. For this, we use <b>Logistic Regression</b>.</p>

<p>Recall linear regression:
As you know, Linear regression finds a function that relates a continuous dependent variable, y to some predictors (independent variables $x_1$, $x_2$, etc.). For example, Simple linear regression assumes a function of the form:</p>

\[y = \theta_0 + \theta_1  x_1 + \theta_2  x_2 + \cdots\]

<p>and finds the values of parameters $\theta_0, \theta_1, \theta_2$, etc, where the term $\theta_0$ is the “intercept”. It can be generally shown as:</p>

\[ℎ_\theta(𝑥) = \theta^TX\]

<p>Logistic Regression is a variation of Linear Regression, useful when the observed dependent variable, <b>y</b>, is categorical. It produces a formula that predicts the probability of the class label as a function of the independent variables.</p>

<p>Logistic regression fits a special s-shaped curve by taking the linear regression and transforming the numeric estimate into a probability with the following function, which is called sigmoid function 𝜎:</p>

\[ℎ_\theta(𝑥) = \sigma({\theta^TX}) =  \frac {e^{(\theta_0 + \theta_1  x_1 + \theta_2  x_2 +...)}}{1 + e^{(\theta_0 + \theta_1  x_1 + \theta_2  x_2 +\cdots)}}\]

<p>Or:</p>

\[ProbabilityOfaClass_1 =  P(Y=1|X) = \sigma({\theta^TX}) = \frac{e^{\theta^TX}}{1+e^{\theta^TX}}\]

<p>In this equation, ${\theta^TX}$ is the regression result (the sum of the variables weighted by the coefficients), <code class="language-plaintext highlighter-rouge">exp</code> is the exponential function and $\sigma(\theta^TX)$ is the sigmoid or <a href="http://en.wikipedia.org/wiki/Logistic_function">logistic function</a>, also called logistic curve. It is a common “S” shape (sigmoid curve).</p>

<p>So, briefly, Logistic Regression passes the input through the logistic/sigmoid but then treats the result as a probability:</p>

<p>The objective of <strong>Logistic Regression</strong> algorithm, is to find the best parameters θ, for $ℎ_\theta(𝑥)$ = $\sigma({\theta^TX})$, in such a way that the model best predicts the class of each case.</p>

<p><img src="/media/15842755659220/15844476195206.jpg" alt="-w700" width="600px" /></p>

<p><strong>Algorithm:</strong></p>

<ol>
  <li>Initialize $\theta$</li>
  <li>calculate $\hat{y}=g(\theta^T X)$ for a customer</li>
  <li>get the cost function</li>
  <li>optimize the cost function over $\theta$</li>
</ol>

\[\begin{aligned} J(\theta) &amp;=\frac{1}{m} \sum_{i=1}^{m} \operatorname{cost}\left(h_{\theta}\left(x^{(i)}\right), y^{(i)}\right) \\ &amp;=-\frac{1}{m}\left[\sum_{i=1}^{m} y^{(i)} \log h_{\theta}\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right] \end{aligned}\]

<p>Which is still convex function.</p>

<h4 id="proposition-about-convex-functions">Proposition about convex functions</h4>

<ul>
  <li>If $f(\cdot)$ is convex function, $g(\cdot)$ is an linear/affine function, then $f(g(\cdot))$ is a convex function.</li>
  <li>If $f(\cdot)$ and $g(\cdot)$ are both convex function, then $af(x)+bg(y)$ is still convex function if $a,b&gt;=0$.</li>
</ul>

<p>Essentially, $Cost~function \in [0,+\infty )$</p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$Cost~function \to +\infty$ if $</td>
          <td>h_\theta(x)-y</td>
          <td>\to 1 $.</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$Cost~function \to 0$ if $</td>
          <td>h_\theta(x)-y</td>
          <td>\to 0 $.</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p>Note that writing the cost function in this way guarantees that $J(\theta )$ is convex for logistic regression.</p>

<h4 id="gradient-descent">Gradient Descent</h4>

\[\begin{array}{l}{\text { Gradient Descent }} \\ {\qquad \begin{array}{l}{J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^{m} y^{(i)} \log h_{\theta}\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]} \\ {\text { Want } \min _{\theta} J(\theta) :} \\ {\text { Repeat }\{ } \end{array}} \\ {\qquad \begin{array}{ll} {\theta_{j} :=\theta_{j}-\alpha \frac{\partial}{\partial \theta_{j}} J(\theta)} \\ { \}} &amp; {\left.\text { (simultaneously update all } \theta_{j}\right)}\end{array}}\end{array}\]

<p>Since $\frac{\partial} {\partial \theta_j} J(\theta)=\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$, we get:</p>

\[\begin{array}{l}{\text { Gradient Descent }} \\ {\qquad \begin{array}{l}{J(\theta)=-\frac{1}{m}\left[\sum_{i=1}^{m} y^{(i)} \log h_{\theta}\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-h_{\theta}\left(x^{(i)}\right)\right)\right]} \\ {\text { Want } \min _{\theta} J(\theta) :} \\ {\text { Repeat }\{ } \end{array}} \\ {\qquad \begin{array}{ll} {\theta_{j} :=\theta_{j}-\frac{\alpha}{m} \sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}} \\ { \}} &amp; {\left.\text { (simultaneously update all } \theta_{j}\right)}\end{array}}\end{array}\]

<h4 id="vectorization">Vectorization</h4>

<p>Use the built in functions to solve the calculation. Try not to implement the loop by ourselves.</p>

<p>For example, in the gradient descent method, we need to calculate simultaneously:</p>

\[\begin{array}{l}{\text { repeat until convergence: } } \\ {\theta_{j} :=\theta_{j}-\alpha \frac{1}{m} \sum_{i=1}^{m}\left(h_{\theta}\left(x^{(i)}\right)-y^{(i)}\right) \cdot x_{j}^{(i)} \quad \text { for } j :=0 \ldots n}\end{array}\]

<p>In fact, this is equivalent to:</p>

<p>$\theta_{new}=\theta-\frac{\alpha}{m}X^T[g(X\theta)-y)]$</p>

<h4 id="lab-logistic-regression">Lab: logistic regression</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="n">pl</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">scipy.optimize</span> <span class="k">as</span> <span class="n">opt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">churn_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"ChurnData.csv"</span><span class="p">)</span>
<span class="n">churn_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1"># Data pre-processing and selection
</span><span class="n">churn_df</span> <span class="o">=</span> <span class="n">churn_df</span><span class="p">[[</span><span class="s">'tenure'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'address'</span><span class="p">,</span> <span class="s">'income'</span><span class="p">,</span> <span class="s">'ed'</span><span class="p">,</span> <span class="s">'employ'</span><span class="p">,</span> <span class="s">'equip'</span><span class="p">,</span>  <span class="s">'callcard'</span><span class="p">,</span> <span class="s">'wireless'</span><span class="p">,</span><span class="s">'churn'</span><span class="p">]]</span>
<span class="n">churn_df</span><span class="p">[</span><span class="s">'churn'</span><span class="p">]</span> <span class="o">=</span> <span class="n">churn_df</span><span class="p">[</span><span class="s">'churn'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'int'</span><span class="p">)</span>
<span class="n">churn_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">churn_df</span><span class="p">[[</span><span class="s">'tenure'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="s">'address'</span><span class="p">,</span> <span class="s">'income'</span><span class="p">,</span> <span class="s">'ed'</span><span class="p">,</span> <span class="s">'employ'</span><span class="p">,</span> <span class="s">'equip'</span><span class="p">]])</span>
<span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">churn_df</span><span class="p">[</span><span class="s">'churn'</span><span class="p">])</span>
<span class="n">y</span> <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># Normalize the dataset
</span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># Split the test and train set
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Train set:'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span>  <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Test set:'</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span>  <span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Training
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="n">LR</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s">'liblinear'</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">LR</span>

<span class="n">yhat</span> <span class="o">=</span> <span class="n">LR</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">yhat</span>

<span class="n">yhat_prob</span> <span class="o">=</span> <span class="n">LR</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">yhat_prob</span>

<span class="c1"># __predict_proba__  returns estimates for all classes, ordered by the label of classes. So, the first column is the probability of class 1, P(Y=1|X), and second column is probability of class 0, P(Y=0|X):
</span>
<span class="c1"># Evaluation
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">jaccard_similarity_score</span>
<span class="n">jaccard_similarity_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>

<span class="c1"># Confusion matrix
</span><span class="k">print</span> <span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">))</span>

<span class="c1"># log loss
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>
<span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat_prob</span><span class="p">)</span>


</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="support-vector-machine">Support Vector Machine</h3>

<p>SVM is a supervised algorithm that classifies cases by finding a separator.</p>

<ol>
  <li>Mapping data to a high-dimensional feature spaces.</li>
  <li>Finding a separator.</li>
</ol>

<h4 id="data-transformation">Data Transformation</h4>

<p><img src="/media/15842755659220/15844574971744.jpg" alt="-w700" width="600px" /></p>

<p>Basically, mapping data into a dimensional space is called <strong>Kernelling.</strong> The mathematical function which is used for the transformation is called the kernel function.</p>

<ul>
  <li>Linear</li>
  <li>Polynomial</li>
  <li>RBF</li>
  <li>Sigmoid</li>
</ul>

<h4 id="using-svm-to-find-the-hyperplane">Using SVM to find the hyperplane</h4>

<p><img src="/media/15842755659220/15844577582220.jpg" alt="-w700" width="600px" /></p>

<h4 id="pros-and-cons-of-svm">Pros and Cons of SVM</h4>

<ul>
  <li>
    <p>Advantages:</p>

    <ul>
      <li>Accurate in high-dimensional spaces</li>
      <li>Memory efficient.(only use support vectors)</li>
    </ul>
  </li>
  <li>
    <p>Disadvantages:</p>

    <ul>
      <li>Prone to over-fitting</li>
      <li>No probability estimation</li>
      <li>Small datasets</li>
    </ul>

    <p>SVM Applications: (works well with high-dimensional data)</p>

    <ul>
      <li>Image recognition</li>
      <li>Text category assignment</li>
      <li>Detecting spam</li>
      <li>Sentiment analysis</li>
      <li>Gene expression classiciation</li>
      <li>regression, outlier detection and clustering.</li>
    </ul>
  </li>
</ul>

<h4 id="lab-svm">LAB: svm</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">pylab</span> <span class="k">as</span> <span class="n">pl</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">scipy.optimize</span> <span class="k">as</span> <span class="n">opt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">cell_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"cell_samples.csv"</span><span class="p">)</span>
<span class="n">cell_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1"># Plot the distribution of the classes:
# Note: when plot composite of axes, use the "label=" parameter to differentiate between different draws.
</span><span class="n">ax</span> <span class="o">=</span> <span class="n">cell_df</span><span class="p">[</span><span class="n">cell_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'scatter'</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Clump'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'UnifSize'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'DarkBlue'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'malignant'</span><span class="p">);</span>
<span class="n">cell_df</span><span class="p">[</span><span class="n">cell_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'scatter'</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">'Clump'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'UnifSize'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'Yellow'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'benign'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">);</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Preprocessing
# convert BareNuc into numerical dtypes
</span><span class="n">cell_df</span> <span class="o">=</span> <span class="n">cell_df</span><span class="p">[</span><span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">cell_df</span><span class="p">[</span><span class="s">'BareNuc'</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s">'coerce'</span><span class="p">).</span><span class="n">notnull</span><span class="p">()]</span>
<span class="n">cell_df</span><span class="p">[</span><span class="s">'BareNuc'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cell_df</span><span class="p">[</span><span class="s">'BareNuc'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'int'</span><span class="p">)</span>
<span class="n">cell_df</span><span class="p">.</span><span class="n">dtypes</span>

<span class="n">feature_df</span> <span class="o">=</span> <span class="n">cell_df</span><span class="p">[[</span><span class="s">'Clump'</span><span class="p">,</span> <span class="s">'UnifSize'</span><span class="p">,</span> <span class="s">'UnifShape'</span><span class="p">,</span> <span class="s">'MargAdh'</span><span class="p">,</span> <span class="s">'SingEpiSize'</span><span class="p">,</span> <span class="s">'BareNuc'</span><span class="p">,</span> <span class="s">'BlandChrom'</span><span class="p">,</span> <span class="s">'NormNucl'</span><span class="p">,</span> <span class="s">'Mit'</span><span class="p">]]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feature_df</span><span class="p">)</span>
<span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="n">cell_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cell_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'int'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">cell_df</span><span class="p">[</span><span class="s">'Class'</span><span class="p">])</span>
<span class="n">y</span> <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># Train/Test Split
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Train set:'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span>  <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Test set:'</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span>  <span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>The SVM algorithm offers a choice of kernel functions for performing its processing. Basically, mapping data into a higher dimensional space is called kernelling. The mathematical function used for the transformation is known as the kernel function, and can be of different types, such as:</p>

<ol>
  <li>Linear</li>
  <li>Polynomial</li>
  <li>Radial basis function (RBF)</li>
  <li>Sigmoid</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
</pre></td><td class="rouge-code"><pre><span class="c1"># Training/Modeling
</span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


<span class="n">yhat</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">yhat</span> <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># Evaluation
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="nn">itertools</span>

<span class="k">def</span> <span class="nf">plot_confusion_matrix</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span>
                          <span class="n">normalize</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                          <span class="n">title</span><span class="o">=</span><span class="s">'Confusion matrix'</span><span class="p">,</span>
                          <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Blues</span><span class="p">):</span>
    <span class="s">"""
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """</span>
    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">cm</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">)</span> <span class="o">/</span> <span class="n">cm</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Normalized confusion matrix"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'Confusion matrix, without normalization'</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="n">cm</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">'nearest'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
    <span class="n">tick_marks</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">))</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">tick_marks</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>

    <span class="n">fmt</span> <span class="o">=</span> <span class="s">'.2f'</span> <span class="k">if</span> <span class="n">normalize</span> <span class="k">else</span> <span class="s">'d'</span>
    <span class="n">thresh</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="o">/</span> <span class="mf">2.</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">itertools</span><span class="p">.</span><span class="n">product</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">range</span><span class="p">(</span><span class="n">cm</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])):</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nb">format</span><span class="p">(</span><span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">fmt</span><span class="p">),</span>
                <span class="n">horizontalalignment</span><span class="o">=</span><span class="s">"center"</span><span class="p">,</span>
                <span class="n">color</span><span class="o">=</span><span class="s">"white"</span> <span class="k">if</span> <span class="n">cm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">thresh</span> <span class="k">else</span> <span class="s">"black"</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True label'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Predicted label'</span><span class="p">)</span>


<span class="c1"># Compute confusion matrix
</span><span class="n">cnf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="n">np</span><span class="p">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">))</span>

<span class="c1"># Plot non-normalized confusion matrix
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plot_confusion_matrix</span><span class="p">(</span><span class="n">cnf_matrix</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="p">[</span><span class="s">'Benign(2)'</span><span class="p">,</span><span class="s">'Malignant(4)'</span><span class="p">],</span><span class="n">normalize</span><span class="o">=</span> <span class="bp">False</span><span class="p">,</span>  <span class="n">title</span><span class="o">=</span><span class="s">'Confusion matrix'</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/media/15842755659220/15845326583489.jpg" alt="-w500" width="600px" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre>
<span class="c1"># Other Evaluation
# f1_score
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
<span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s">'weighted'</span><span class="p">)</span>

<span class="c1"># Jaccard index
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">jaccard_similarity_score</span>
<span class="n">jaccard_similarity_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="intro-to-clustering">Intro to Clustering</h2>

<p><img src="/media/15842755659220/15845332650470.jpg" alt="-w800" width="600px" /></p>

<p><img src="/media/15842755659220/15845335250963.jpg" alt="-w800" width="600px" /></p>

<p><strong>Applications:</strong></p>

<ul>
  <li>
    <p>Retail/Marketing</p>

    <ul>
      <li>Identifying buying patterns of customers</li>
      <li>Recommending new books or movies to new customers</li>
    </ul>
  </li>
  <li>
    <p>Banking</p>

    <ul>
      <li>Fraud detection in credit card use</li>
      <li>Identifying clusters of customers</li>
    </ul>
  </li>
  <li>Insurance
    <ul>
      <li>Fraud detection in claim analysis</li>
      <li>Insurance risk of customers</li>
    </ul>
  </li>
  <li>
    <p>Publication:</p>

    <ul>
      <li>Auto-categorizing news based on their content</li>
      <li>Recommending similar news articles</li>
    </ul>
  </li>
  <li>
    <p>Medicine</p>

    <ul>
      <li>Characterizing patient behavior</li>
    </ul>
  </li>
  <li>Biology
    <ul>
      <li>Group genes</li>
    </ul>
  </li>
</ul>

<p><strong>Why clustering?</strong></p>

<ul>
  <li>Exploratory data analysis</li>
  <li>Summary generation</li>
  <li>Outlier detection</li>
  <li>Finding duplicates</li>
  <li>Pre-processing step</li>
</ul>

<p><strong>Algorithms:</strong></p>

<ul>
  <li>
    <p>Partition-based clustering
_ Relatively efficient
_ K-means, K-median, Fuzzy C-Means</p>

    <p><img src="/media/15842755659220/15845339986558.jpg" alt="-w300" width="600px" /></p>
  </li>
  <li>
    <p>Hierarchical clustering: very intuitive and generally good for small size of data set.
_ Produces trees of clusters
_ Agglomerative, divisive</p>

    <p><img src="/media/15842755659220/15845340344042.jpg" alt="-w300" width="600px" /></p>
  </li>
  <li>
    <p>Density-based clustering: especially good when dealing spacial clusters or when there is noise in the data set.</p>
    <ul>
      <li>Produces arbitrary shaped clusters</li>
      <li>e.g.: DBSCAN</li>
    </ul>
  </li>
</ul>

<p><img src="/media/15842755659220/15845340938265.jpg" alt="-w300" width="600px" /></p>

<h3 id="k-means-clustering">K-means clustering</h3>

<p>It is an Unsupervised Learning algorithm.</p>

\[\begin{array}{l}{J\left(c^{(1)}, \ldots, c^{(m)}, \mu_{1}, \ldots, \mu_{K}\right)=\frac{1}{m} \sum_{i=1}^{m}\left\|x^{(i)}-\mu_{c^{(i)}}\right\|^{2}} \\ {\min _{c^{(1)}, \ldots, c^{(m)}} J\left(c^{(1)}, \ldots, c^{(m)}, \mu_{1}, \ldots, \mu_{K}\right)} \\ {\mu_{1}, \ldots, \mu_{K}}\end{array}\]

<p>where
$\begin{aligned} c^{(i)} &amp;=\text { index of cluster }(1,2, \ldots, K) \text { to which example } x^{(i)} \text { is currently } \ &amp; \text { assigned } \ \mu_{k} &amp;=\text { cluster centroid } k\left(\mu_{k} \in \mathbb{R}^{n}\right) \end{aligned}$</p>

<p>$\begin{aligned} \mu_{c^{(i)}} &amp;=\text { cluster centroid of cluster to which example } x^{(i)} \text { has been } \ &amp; \text { assigned } \end{aligned}$</p>

<p><img src="/media/15718172032236/15718355986198.jpg" alt="-w500" width="600px" /></p>

<p>Choose K s.t. the mean distance of data points to cluster centroid is acceptable.</p>

<p>The cost function (distance of data points to the appointed cluster centroid) decreases as K increases. <strong>Elbow point</strong> is determined where the rate of decrease sharply <strong>shifts.</strong></p>

<p><img src="/media/15842755659220/15845418514372.jpg" alt="-w500" width="600px" /></p>

<h4 id="lab-k-means">Lab: K-means</h4>

<p>Lets create the data set for this lab. First we need to set up a random seed. Use numpy’s random.seed() function, where the seed will be set to 0.</p>

<p>Next we will be making <em>random clusters</em> of points by using the <strong>make_blobs</strong> class. The <strong>make_blobs</strong> class can take in many inputs, but we will be using these specific ones.</p>

<p><strong>Input</strong></p>

<ul>
  <li>
    <p><strong>n_samples</strong>: The total number of points equally divided among clusters.</p>
  </li>
  <li>
    <ul>
      <li>Value will be: 5000</li>
    </ul>
  </li>
  <li>
    <p><strong>centers</strong>: The number of centers to generate, or the fixed center locations.</p>
  </li>
  <li>
    <ul>
      <li>Value will be: [[4, 4], [-2, -1], [2, -3],[1,1]]</li>
    </ul>
  </li>
  <li>
    <p><strong>cluster_std</strong>: The standard deviation of the clusters.</p>
  </li>
  <li>
    <ul>
      <li>Value will be: 0.9</li>
    </ul>
  </li>
</ul>

<p><strong>Output</strong></p>

<ul>
  <li>
    <p><strong>X</strong>: Array of shape [n_samples, n_features]. (Feature Matrix)</p>
  </li>
  <li>
    <ul>
      <li>The generated samples.</li>
    </ul>
  </li>
  <li>
    <p><strong>y</strong>: Array of shape [n_samples]. (Response Vector)</p>
  </li>
  <li>
    <ul>
      <li>The integer labels for cluster membership of each sample.</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="p">[[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p>The KMeans class has many parameters that can be used, but we will be using these three:</p>

<ul>
  <li>
    <p><strong>init</strong>: Initialization method of the centroids.</p>
  </li>
  <li>
    <ul>
      <li>Value will be: “k-means++”</li>
      <li>k-means++: Selects initial cluster centers for k-mean clustering in a smart way to speed up convergence.</li>
    </ul>
  </li>
  <li>
    <p><strong>n_clusters</strong>: The number of clusters to form as well as the number of centroids to generate.</p>
  </li>
  <li>
    <ul>
      <li>Value will be: 4 (since we have 4 centers)</li>
    </ul>
  </li>
  <li>
    <p><strong>n_init</strong>: Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.</p>
  </li>
  <li>
    <ul>
      <li>Value will be: 12</li>
    </ul>
  </li>
</ul>

<p>Initialize KMeans with these parameters, where the output parameter is called <strong>k_means</strong>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
</pre></td><td class="rouge-code"><pre><span class="c1"># Train the model
</span><span class="n">k_means</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">init</span> <span class="o">=</span> <span class="s">"k-means++"</span><span class="p">,</span> <span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">n_init</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>

<span class="c1"># Now let's grab the labels for each point in the model using KMeans' .labels_ attribute
</span>
<span class="n">k_means</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">k_means_labels</span> <span class="o">=</span> <span class="n">k_means</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">k_means_labels</span>

<span class="c1">#We will also get the coordinates of the cluster centers using KMeans' .cluster_centers_
</span>
<span class="n">k_means_cluster_centers</span> <span class="o">=</span> <span class="n">k_means</span><span class="p">.</span><span class="n">cluster_centers_</span>
<span class="n">k_means_cluster_centers</span>

<span class="c1"># plot the clustering result
# Initialize the plot with the specified dimensions.
</span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="c1"># Colors uses a color map, which will produce an array of colors based on
# the number of labels there are. We use set(k_means_labels) to get the
# unique labels.
</span><span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Spectral</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">k_means_labels</span><span class="p">))))</span>

<span class="c1"># Create a plot
</span><span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># For loop that plots the data points and centroids.
# k will range from 0-3, which will match the possible clusters that each
# data point is in.
</span><span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])),</span> <span class="n">colors</span><span class="p">):</span>

    <span class="c1"># Create a list of all data points, where the data poitns that are
</span>    <span class="c1"># in the cluster (ex. cluster 0) are labeled as true, else they are
</span>    <span class="c1"># labeled as false.
</span>    <span class="n">my_members</span> <span class="o">=</span> <span class="p">(</span><span class="n">k_means_labels</span> <span class="o">==</span> <span class="n">k</span><span class="p">)</span>

    <span class="c1"># Define the centroid, or cluster center.
</span>    <span class="n">cluster_center</span> <span class="o">=</span> <span class="n">k_means_cluster_centers</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

    <span class="c1"># Plots the datapoints with color col.
</span>    <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">my_members</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">my_members</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="s">'w'</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="n">col</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">)</span>

    <span class="c1"># Plots the centroids with specified color, but with a darker outline
</span>    <span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cluster_center</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cluster_center</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">'o'</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="n">col</span><span class="p">,</span>  <span class="n">markeredgecolor</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

<span class="c1"># Title of the plot
</span><span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">'KMeans'</span><span class="p">)</span>

<span class="c1"># Remove x-axis ticks
</span><span class="n">ax</span><span class="p">.</span><span class="n">set_xticks</span><span class="p">(())</span>

<span class="c1"># Remove y-axis ticks
</span><span class="n">ax</span><span class="p">.</span><span class="n">set_yticks</span><span class="p">(())</span>

<span class="c1"># Show the plot
</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/media/15842755659220/15845439726791.jpg" alt="-w500" width="600px" /></p>

<h3 id="hierarchical-clustering">Hierarchical Clustering</h3>

<p>Hierarchical clustering algorithms build a hierarchy of clusters where <strong>each node is a cluster</strong> consists of the clusters of its daughter nods.</p>

<p><strong>Agglomerative Vs Divisive</strong></p>

<p><img src="/media/15842755659220/15845423504083.jpg" alt="-w600" width="600px" /></p>

<p><img src="/media/15842755659220/15845426100398.jpg" alt="-w600" width="600px" /></p>

<p><strong>Agglomerative algorithm</strong></p>

<ul>
  <li>
    <p>Create n clusters, one for each data point</p>

    <p><img src="/media/15842755659220/15845426922190.jpg" alt="-w300" width="600px" /></p>
  </li>
  <li>
    <p>Compute the Proximity matrix</p>
  </li>
</ul>

<p><img src="/media/15842755659220/15845427050113.jpg" alt="-w300" width="600px" /></p>

<ul>
  <li>
    <p>Repeat</p>

    <ul>
      <li>Merge the two closets clusters</li>
      <li>Update the Proximity Matrix</li>
    </ul>
  </li>
  <li>
    <p>Until only a single cluster remains</p>
  </li>
</ul>

<p><strong>How to measure Distance between clusters:</strong></p>

<ul>
  <li>Single-linkage clustering: minimum distance between clusters</li>
  <li>Complete-linkage clustering: Maximum distance between clusters</li>
  <li>Average Linkage Clustering: Average distance between clusters</li>
  <li>
    <p>Centroid Linkage clustering: distance between cluster centroids (the average of points within a cluster)</p>

    <p><img src="/media/15842755659220/15845429513913.jpg" alt="-w700" width="600px" /></p>
  </li>
</ul>

<p><strong>Advantages VS Disadvantages</strong></p>

<p><img src="/media/15842755659220/15845430432457.jpg" alt="-w800" width="600px" /></p>

<p><strong>K means VS Hierarchical clustering</strong></p>

<p><img src="/media/15842755659220/15845430830282.jpg" alt="-w700" width="600px" /></p>

<h4 id="lab-hierarchical-clustering">Lab: Hierarchical Clustering</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">ndimage</span>
<span class="kn">from</span> <span class="nn">scipy.cluster</span> <span class="kn">import</span> <span class="n">hierarchy</span>
<span class="kn">from</span> <span class="nn">scipy.spatial</span> <span class="kn">import</span> <span class="n">distance_matrix</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">manifold</span><span class="p">,</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>


<span class="c1"># Generating random Data
</span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="p">[[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">]],</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">)</span>

<span class="c1"># Agglomerative clustering
</span><span class="n">agglom</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">linkage</span> <span class="o">=</span> <span class="s">'average'</span><span class="p">)</span>
<span class="n">agglom</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">y1</span><span class="p">)</span>

<span class="c1"># plot the clustering
# Create a figure of size 6 inches by 4 inches.
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="c1"># These two lines of code are used to scale the data points down,
# Or else the data points will be scattered very far apart.
</span>
<span class="c1"># Create a minimum and maximum range of X1.
</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Get the average distance for X1.
</span><span class="n">X1</span> <span class="o">=</span> <span class="p">(</span><span class="n">X1</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span>

<span class="c1"># This loop displays all of the datapoints.
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X1</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="c1"># Replace the data points with their respective cluster value
</span>    <span class="c1"># (ex. 0) and is color coded with a colormap (plt.cm.spectral)
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">X1</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X1</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="nb">str</span><span class="p">(</span><span class="n">y1</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span>
            <span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">nipy_spectral</span><span class="p">(</span><span class="n">agglom</span><span class="p">.</span><span class="n">labels_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="mf">10.</span><span class="p">),</span>
            <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s">'weight'</span><span class="p">:</span> <span class="s">'bold'</span><span class="p">,</span> <span class="s">'size'</span><span class="p">:</span> <span class="mi">9</span><span class="p">})</span>

<span class="c1"># Remove the x ticks, y ticks, x and y axis
</span><span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="c1">#plt.axis('off')
</span>


<span class="c1"># Display the plot of the original data before clustering
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">'.'</span><span class="p">)</span>
<span class="c1"># Display the plot
</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>


</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="c1"># Dendrogram Associated for the Agglomerative Hierarchical Clustering
</span><span class="n">dist_matrix</span> <span class="o">=</span> <span class="n">distance_matrix</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span><span class="n">X1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">dist_matrix</span><span class="p">)</span>

<span class="n">Z</span> <span class="o">=</span> <span class="n">hierarchy</span><span class="p">.</span><span class="n">linkage</span><span class="p">(</span><span class="n">dist_matrix</span><span class="p">,</span> <span class="s">'complete'</span><span class="p">)</span>

<span class="n">dendro</span> <span class="o">=</span> <span class="n">hierarchy</span><span class="p">.</span><span class="n">dendrogram</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Note: <code class="language-plaintext highlighter-rouge">pd.apply()</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td class="rouge-code"><pre><span class="nb">filter</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">sequence</span><span class="p">)</span>
<span class="c1"># find those can be divided by 3 in range(1,11)
</span><span class="n">selected_numbers</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>

<span class="c1"># apply for every element
</span><span class="n">df</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">square</span><span class="p">)</span>
<span class="c1"># apply for specific col or row-- with the x.name or x.index to limit
</span><span class="n">df</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="n">name</span><span class="o">==</span><span class="s">'col'</span> <span class="k">else</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># by default axis=0, that is down the rows, and each col is applied together
</span>

<span class="n">df</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">square</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="n">x</span><span class="p">.</span><span class="n">name</span><span class="o">==</span><span class="s">'rowname'</span> <span class="k">else</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># convert data into numeric
# coerce: if not convertible, it will be set as np.nan
</span><span class="n">df</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'coerce'</span><span class="p">)</span>
<span class="c1"># ignore: keep the original value
</span><span class="n">df</span><span class="p">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'ignore'</span><span class="p">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
</pre></td><td class="rouge-code"><pre><span class="c1"># Clustering on Vehicle dataset
</span><span class="n">filename</span> <span class="o">=</span> <span class="s">'cars_clus.csv'</span>

<span class="c1">#Read csv
</span><span class="n">pdf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"Shape of dataset: "</span><span class="p">,</span> <span class="n">pdf</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">pdf</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="s">"Shape of dataset before cleaning: "</span><span class="p">,</span> <span class="n">pdf</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
<span class="n">pdf</span><span class="p">[[</span> <span class="s">'sales'</span><span class="p">,</span> <span class="s">'resale'</span><span class="p">,</span> <span class="s">'type'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">,</span> <span class="s">'engine_s'</span><span class="p">,</span>
      <span class="s">'horsepow'</span><span class="p">,</span> <span class="s">'wheelbas'</span><span class="p">,</span> <span class="s">'width'</span><span class="p">,</span> <span class="s">'length'</span><span class="p">,</span> <span class="s">'curb_wgt'</span><span class="p">,</span> <span class="s">'fuel_cap'</span><span class="p">,</span>
      <span class="s">'mpg'</span><span class="p">,</span> <span class="s">'lnsales'</span><span class="p">]]</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[[</span><span class="s">'sales'</span><span class="p">,</span> <span class="s">'resale'</span><span class="p">,</span> <span class="s">'type'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">,</span> <span class="s">'engine_s'</span><span class="p">,</span>
      <span class="s">'horsepow'</span><span class="p">,</span> <span class="s">'wheelbas'</span><span class="p">,</span> <span class="s">'width'</span><span class="p">,</span> <span class="s">'length'</span><span class="p">,</span> <span class="s">'curb_wgt'</span><span class="p">,</span> <span class="s">'fuel_cap'</span><span class="p">,</span>
      <span class="s">'mpg'</span><span class="p">,</span> <span class="s">'lnsales'</span><span class="p">]].</span><span class="nb">apply</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="n">to_numeric</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s">'coerce'</span><span class="p">)</span>
<span class="n">pdf</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">pdf</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">"Shape of dataset after cleaning: "</span><span class="p">,</span> <span class="n">pdf</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
<span class="n">pdf</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">featureset</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[[</span><span class="s">'engine_s'</span><span class="p">,</span>  <span class="s">'horsepow'</span><span class="p">,</span> <span class="s">'wheelbas'</span><span class="p">,</span> <span class="s">'width'</span><span class="p">,</span> <span class="s">'length'</span><span class="p">,</span> <span class="s">'curb_wgt'</span><span class="p">,</span> <span class="s">'fuel_cap'</span><span class="p">,</span> <span class="s">'mpg'</span><span class="p">]]</span>

<span class="c1"># Normalization
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">featureset</span><span class="p">.</span><span class="n">values</span> <span class="c1">#returns a numpy array
</span><span class="n">min_max_scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">feature_mtx</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">feature_mtx</span> <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>



<span class="c1"># clustering using scipy
</span><span class="kn">import</span> <span class="nn">scipy</span>
<span class="n">leng</span> <span class="o">=</span> <span class="n">feature_mtx</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">leng</span><span class="p">,</span><span class="n">leng</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">leng</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">leng</span><span class="p">):</span>
        <span class="n">D</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">spatial</span><span class="p">.</span><span class="n">distance</span><span class="p">.</span><span class="n">euclidean</span><span class="p">(</span><span class="n">feature_mtx</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">feature_mtx</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>


<span class="kn">import</span> <span class="nn">pylab</span>
<span class="kn">import</span> <span class="nn">scipy.cluster.hierarchy</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">hierarchy</span><span class="p">.</span><span class="n">linkage</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="s">'complete'</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">fcluster</span>
<span class="n">max_d</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">max_d</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s">'distance'</span><span class="p">)</span>
<span class="n">clusters</span>

<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">fcluster</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s">'maxclust'</span><span class="p">)</span>
<span class="n">clusters</span>

<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">fcluster</span>
<span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">fcluster</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s">'maxclust'</span><span class="p">)</span>
<span class="n">clusters</span>

<span class="n">dist_matrix</span> <span class="o">=</span> <span class="n">distance_matrix</span><span class="p">(</span><span class="n">feature_mtx</span><span class="p">,</span><span class="n">feature_mtx</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">dist_matrix</span><span class="p">)</span>


<span class="n">agglom</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="n">linkage</span> <span class="o">=</span> <span class="s">'complete'</span><span class="p">)</span>
<span class="n">agglom</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">feature_mtx</span><span class="p">)</span>
<span class="n">agglom</span><span class="p">.</span><span class="n">labels_</span>

<span class="n">pdf</span><span class="p">[</span><span class="s">'cluster_'</span><span class="p">]</span> <span class="o">=</span> <span class="n">agglom</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">pdf</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">matplotlib.cm</span> <span class="k">as</span> <span class="n">cm</span>
<span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">agglom</span><span class="p">.</span><span class="n">labels_</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">cm</span><span class="p">.</span><span class="n">rainbow</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">))</span>
<span class="n">cluster_labels</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">))</span>

<span class="c1"># Create a figure of size 6 inches by 4 inches.
</span><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">14</span><span class="p">))</span>

<span class="k">for</span> <span class="n">color</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">):</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[</span><span class="n">pdf</span><span class="p">.</span><span class="n">cluster_</span> <span class="o">==</span> <span class="n">label</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">subset</span><span class="p">.</span><span class="n">index</span><span class="p">:</span>
            <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">subset</span><span class="p">.</span><span class="n">horsepow</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">subset</span><span class="p">.</span><span class="n">mpg</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="nb">str</span><span class="p">(</span><span class="n">subset</span><span class="p">[</span><span class="s">'model'</span><span class="p">][</span><span class="n">i</span><span class="p">]),</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">subset</span><span class="p">.</span><span class="n">horsepow</span><span class="p">,</span> <span class="n">subset</span><span class="p">.</span><span class="n">mpg</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span> <span class="n">subset</span><span class="p">.</span><span class="n">price</span><span class="o">*</span><span class="mi">10</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'cluster'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">label</span><span class="p">),</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1">#    plt.scatter(subset.horsepow, subset.mpg)
</span><span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Clusters'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'horsepow'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'mpg'</span><span class="p">)</span>


<span class="n">pdf</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'cluster_'</span><span class="p">,</span><span class="s">'type'</span><span class="p">])[</span><span class="s">'cluster_'</span><span class="p">].</span><span class="n">count</span><span class="p">()</span>

<span class="n">agg_cars</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'cluster_'</span><span class="p">,</span><span class="s">'type'</span><span class="p">])[</span><span class="s">'horsepow'</span><span class="p">,</span><span class="s">'engine_s'</span><span class="p">,</span><span class="s">'mpg'</span><span class="p">,</span><span class="s">'price'</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
<span class="n">agg_cars</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">color</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="n">cluster_labels</span><span class="p">):</span>
    <span class="n">subset</span> <span class="o">=</span> <span class="n">agg_cars</span><span class="p">.</span><span class="n">loc</span><span class="p">[(</span><span class="n">label</span><span class="p">,),]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">subset</span><span class="p">.</span><span class="n">index</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">subset</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">5</span><span class="p">,</span> <span class="n">subset</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span> <span class="s">'type='</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">))</span> <span class="o">+</span> <span class="s">', price='</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">subset</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">3</span><span class="p">]))</span><span class="o">+</span><span class="s">'k'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">subset</span><span class="p">.</span><span class="n">horsepow</span><span class="p">,</span> <span class="n">subset</span><span class="p">.</span><span class="n">mpg</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="n">subset</span><span class="p">.</span><span class="n">price</span><span class="o">*</span><span class="mi">20</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'cluster'</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Clusters'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'horsepow'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'mpg'</span><span class="p">)</span>


</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="dbscan-clustering">DBSCAN Clustering</h3>

<p>DBSCAN: Density-based Spatial Clustering of Applications with noise.</p>

<ul>
  <li>is one of the most common clustering algorithms</li>
  <li>works based on density of objects</li>
</ul>

<p>R: radius of neighborhood</p>

<p>M: min number of neighbors</p>

<p><img src="/media/15842755659220/15847860619164.jpg" alt="-w600" width="600px" /></p>

<p>Core Point: within the radius R, there are at least M points (include the core point itself)</p>

<p><img src="/media/15842755659220/15847861925749.jpg" alt="-w400" width="600px" /></p>

<p>Border point: not a core point, but reachable to a core point.</p>

<p><img src="/media/15842755659220/15847862187324.jpg" alt="-w400" width="600px" /></p>

<p>Outlier: points which cannot be reached by a core point.</p>

<p><img src="/media/15842755659220/15847862377977.jpg" alt="-w400" width="600px" /></p>

<p>Cluster: connected core points together with their border point.</p>

<p><img src="/media/15842755659220/15847862675680.jpg" alt="-w400" width="600px" /></p>

<p>Advantages:</p>

<ol>
  <li>Arbitrarily shaped clusters</li>
  <li>Robust to outliers</li>
  <li>Does not require specification of the number of clusters</li>
</ol>

<h4 id="lab-dbscan">Lab: DBSCAN</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>


<span class="k">def</span> <span class="nf">createDataPoints</span><span class="p">(</span><span class="n">centroidLocation</span><span class="p">,</span> <span class="n">numSamples</span><span class="p">,</span> <span class="n">clusterDeviation</span><span class="p">):</span>
    <span class="c1"># Create random data and store in feature matrix X and response vector y.
</span>    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">numSamples</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="n">centroidLocation</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="n">clusterDeviation</span><span class="p">)</span>

    <span class="c1"># Standardize features by removing the mean and scaling to unit variance
</span>    <span class="n">X</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>



<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">createDataPoints</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">]]</span> <span class="p">,</span> <span class="mi">1500</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="c1"># Training(modeling)
</span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">minimumSamples</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="n">epsilon</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="n">minimumSamples</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">labels</span>


<span class="c1"># Distinguish outliers
# Firts, create an array of booleans using the labels from db.
</span><span class="n">core_samples_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">db</span><span class="p">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">core_samples_mask</span><span class="p">[</span><span class="n">db</span><span class="p">.</span><span class="n">core_sample_indices_</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">core_samples_mask</span>

<span class="c1"># Number of clusters in labels, ignoring noise if present.
</span><span class="n">n_clusters_</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">labels</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">n_clusters_</span>

<span class="c1"># Remove repetition in labels by turning it into a set.
</span><span class="n">unique_labels</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="n">unique_labels</span>

<span class="c1"># Data Visualization
# Create colors for the clusters.
</span><span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">cm</span><span class="p">.</span><span class="n">Spectral</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">)))</span>

<span class="c1"># Plot the points with colors
</span><span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique_labels</span><span class="p">,</span> <span class="n">colors</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Black used for noise.
</span>        <span class="n">col</span> <span class="o">=</span> <span class="s">'k'</span>

    <span class="n">class_member_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">k</span><span class="p">)</span>

    <span class="c1"># Plot the datapoints that are clustered
</span>    <span class="n">xy</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">class_member_mask</span> <span class="o">&amp;</span> <span class="n">core_samples_mask</span><span class="p">]</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">u'o'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="c1"># Plot the outliers
</span>    <span class="n">xy</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">class_member_mask</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">core_samples_mask</span><span class="p">]</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">xy</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span><span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s">u'o'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>


</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Real problem</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
</pre></td><td class="rouge-code"><pre><span class="err">!</span><span class="n">wget</span> <span class="o">-</span><span class="n">O</span> <span class="n">weather</span><span class="o">-</span><span class="n">stations20140101</span><span class="o">-</span><span class="mf">20141231.</span><span class="n">csv</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">s3</span><span class="o">-</span><span class="n">api</span><span class="p">.</span><span class="n">us</span><span class="o">-</span><span class="n">geo</span><span class="p">.</span><span class="n">objectstorage</span><span class="p">.</span><span class="n">softlayer</span><span class="p">.</span><span class="n">net</span><span class="o">/</span><span class="n">cf</span><span class="o">-</span><span class="n">courses</span><span class="o">-</span><span class="n">data</span><span class="o">/</span><span class="n">CognitiveClass</span><span class="o">/</span><span class="n">ML0101ENv3</span><span class="o">/</span><span class="n">labs</span><span class="o">/</span><span class="n">weather</span><span class="o">-</span><span class="n">stations20140101</span><span class="o">-</span><span class="mf">20141231.</span><span class="n">csv</span>

<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">filename</span><span class="o">=</span><span class="s">'weather-stations20140101-20141231.csv'</span>

<span class="c1">#Read csv
</span><span class="n">pdf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">pdf</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="n">pdf</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[</span><span class="n">pd</span><span class="p">.</span><span class="n">notnull</span><span class="p">(</span><span class="n">pdf</span><span class="p">[</span><span class="s">"™"</span><span class="p">])]</span>
<span class="n">pdf</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">pdf</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Visualization
</span><span class="kn">from</span> <span class="nn">mpl_toolkits.basemap</span> <span class="kn">import</span> <span class="n">Basemap</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="n">rcParams</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>

<span class="n">llon</span><span class="o">=-</span><span class="mi">140</span>
<span class="n">ulon</span><span class="o">=-</span><span class="mi">50</span>
<span class="n">llat</span><span class="o">=</span><span class="mi">40</span>
<span class="n">ulat</span><span class="o">=</span><span class="mi">65</span>

<span class="n">pdf</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[(</span><span class="n">pdf</span><span class="p">[</span><span class="s">'Long'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">llon</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">pdf</span><span class="p">[</span><span class="s">'Long'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">ulon</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">pdf</span><span class="p">[</span><span class="s">'Lat'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">llat</span><span class="p">)</span> <span class="o">&amp;</span><span class="p">(</span><span class="n">pdf</span><span class="p">[</span><span class="s">'Lat'</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">ulat</span><span class="p">)]</span>

<span class="n">my_map</span> <span class="o">=</span> <span class="n">Basemap</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s">'merc'</span><span class="p">,</span>
            <span class="n">resolution</span> <span class="o">=</span> <span class="s">'l'</span><span class="p">,</span> <span class="n">area_thresh</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">,</span>
            <span class="n">llcrnrlon</span><span class="o">=</span><span class="n">llon</span><span class="p">,</span> <span class="n">llcrnrlat</span><span class="o">=</span><span class="n">llat</span><span class="p">,</span> <span class="c1">#min longitude (llcrnrlon) and latitude (llcrnrlat)
</span>            <span class="n">urcrnrlon</span><span class="o">=</span><span class="n">ulon</span><span class="p">,</span> <span class="n">urcrnrlat</span><span class="o">=</span><span class="n">ulat</span><span class="p">)</span> <span class="c1">#max longitude (urcrnrlon) and latitude (urcrnrlat)
</span>
<span class="n">my_map</span><span class="p">.</span><span class="n">drawcoastlines</span><span class="p">()</span>
<span class="n">my_map</span><span class="p">.</span><span class="n">drawcountries</span><span class="p">()</span>
<span class="c1"># my_map.drawmapboundary()
</span><span class="n">my_map</span><span class="p">.</span><span class="n">fillcontinents</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s">'white'</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">my_map</span><span class="p">.</span><span class="n">shadedrelief</span><span class="p">()</span>

<span class="c1"># To collect data based on stations
</span>
<span class="n">xs</span><span class="p">,</span><span class="n">ys</span> <span class="o">=</span> <span class="n">my_map</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">pdf</span><span class="p">.</span><span class="n">Long</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">pdf</span><span class="p">.</span><span class="n">Lat</span><span class="p">))</span>
<span class="n">pdf</span><span class="p">[</span><span class="s">'xm'</span><span class="p">]</span><span class="o">=</span> <span class="n">xs</span><span class="p">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">pdf</span><span class="p">[</span><span class="s">'ym'</span><span class="p">]</span> <span class="o">=</span><span class="n">ys</span><span class="p">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="c1">#Visualization1
</span><span class="k">for</span> <span class="n">index</span><span class="p">,</span><span class="n">row</span> <span class="ow">in</span> <span class="n">pdf</span><span class="p">.</span><span class="n">iterrows</span><span class="p">():</span>
<span class="c1">#  x,y = my_map(row.Long, row.Lat)
</span>  <span class="n">my_map</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">row</span><span class="p">.</span><span class="n">xm</span><span class="p">,</span> <span class="n">row</span><span class="p">.</span><span class="n">ym</span><span class="p">,</span><span class="n">markerfacecolor</span> <span class="o">=</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]),</span>  <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">)</span>
<span class="c1">#plt.text(x,y,stn)
</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1"># clustering of stations besed on their location
</span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="kn">import</span> <span class="nn">sklearn.utils</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">check_random_state</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">Clus_dataSet</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[[</span><span class="s">'xm'</span><span class="p">,</span><span class="s">'ym'</span><span class="p">]]</span>
<span class="n">Clus_dataSet</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Clus_dataSet</span><span class="p">)</span>
<span class="n">Clus_dataSet</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Clus_dataSet</span><span class="p">)</span>

<span class="c1"># Compute DBSCAN
</span><span class="n">db</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">Clus_dataSet</span><span class="p">)</span>
<span class="n">core_samples_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">db</span><span class="p">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">core_samples_mask</span><span class="p">[</span><span class="n">db</span><span class="p">.</span><span class="n">core_sample_indices_</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">pdf</span><span class="p">[</span><span class="s">"Clus_Db"</span><span class="p">]</span><span class="o">=</span><span class="n">labels</span>

<span class="n">realClusterNum</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">labels</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">clusterNum</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>


<span class="c1"># A sample of clusters
</span><span class="n">pdf</span><span class="p">[[</span><span class="s">"Stn_Name"</span><span class="p">,</span><span class="s">"Tx"</span><span class="p">,</span><span class="s">"™"</span><span class="p">,</span><span class="s">"Clus_Db"</span><span class="p">]].</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

<span class="c1"># Visualization of clusters based on location
</span><span class="kn">from</span> <span class="nn">mpl_toolkits.basemap</span> <span class="kn">import</span> <span class="n">Basemap</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="n">rcParams</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>

<span class="n">my_map</span> <span class="o">=</span> <span class="n">Basemap</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s">'merc'</span><span class="p">,</span>
            <span class="n">resolution</span> <span class="o">=</span> <span class="s">'l'</span><span class="p">,</span> <span class="n">area_thresh</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">,</span>
            <span class="n">llcrnrlon</span><span class="o">=</span><span class="n">llon</span><span class="p">,</span> <span class="n">llcrnrlat</span><span class="o">=</span><span class="n">llat</span><span class="p">,</span> <span class="c1">#min longitude (llcrnrlon) and latitude (llcrnrlat)
</span>            <span class="n">urcrnrlon</span><span class="o">=</span><span class="n">ulon</span><span class="p">,</span> <span class="n">urcrnrlat</span><span class="o">=</span><span class="n">ulat</span><span class="p">)</span> <span class="c1">#max longitude (urcrnrlon) and latitude (urcrnrlat)
</span>
<span class="n">my_map</span><span class="p">.</span><span class="n">drawcoastlines</span><span class="p">()</span>
<span class="n">my_map</span><span class="p">.</span><span class="n">drawcountries</span><span class="p">()</span>
<span class="c1">#my_map.drawmapboundary()
</span><span class="n">my_map</span><span class="p">.</span><span class="n">fillcontinents</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s">'white'</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">my_map</span><span class="p">.</span><span class="n">shadedrelief</span><span class="p">()</span>

<span class="c1"># To create a color map
</span><span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s">'jet'</span><span class="p">)(</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">clusterNum</span><span class="p">))</span>



<span class="c1">#Visualization1
</span><span class="k">for</span> <span class="n">clust_number</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
    <span class="n">c</span><span class="o">=</span><span class="p">(([</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.4</span><span class="p">])</span> <span class="k">if</span> <span class="n">clust_number</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">colors</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nb">int</span><span class="p">(</span><span class="n">clust_number</span><span class="p">)])</span>
    <span class="n">clust_set</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[</span><span class="n">pdf</span><span class="p">.</span><span class="n">Clus_Db</span> <span class="o">==</span> <span class="n">clust_number</span><span class="p">]</span>
    <span class="n">my_map</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">clust_set</span><span class="p">.</span><span class="n">xm</span><span class="p">,</span> <span class="n">clust_set</span><span class="p">.</span><span class="n">ym</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="n">c</span><span class="p">,</span>  <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.85</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">clust_number</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">cenx</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">clust_set</span><span class="p">.</span><span class="n">xm</span><span class="p">)</span>
        <span class="n">ceny</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">clust_set</span><span class="p">.</span><span class="n">ym</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">cenx</span><span class="p">,</span><span class="n">ceny</span><span class="p">,</span><span class="nb">str</span><span class="p">(</span><span class="n">clust_number</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">,)</span>
        <span class="k">print</span> <span class="p">(</span><span class="s">"Cluster "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">clust_number</span><span class="p">)</span><span class="o">+</span><span class="s">', Avg Temp: '</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">clust_set</span><span class="p">.</span><span class="err">™</span><span class="p">)))</span>


<span class="c1"># clustering of stations based on their location, mean ,max and min temperature
</span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="kn">import</span> <span class="nn">sklearn.utils</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">sklearn</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">check_random_state</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">Clus_dataSet</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[[</span><span class="s">'xm'</span><span class="p">,</span><span class="s">'ym'</span><span class="p">,</span><span class="s">'Tx'</span><span class="p">,</span><span class="s">'™'</span><span class="p">,</span><span class="s">'Tn'</span><span class="p">]]</span>
<span class="n">Clus_dataSet</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Clus_dataSet</span><span class="p">)</span>
<span class="n">Clus_dataSet</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Clus_dataSet</span><span class="p">)</span>

<span class="c1"># Compute DBSCAN
</span><span class="n">db</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">Clus_dataSet</span><span class="p">)</span>
<span class="n">core_samples_mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">db</span><span class="p">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">core_samples_mask</span><span class="p">[</span><span class="n">db</span><span class="p">.</span><span class="n">core_sample_indices_</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">pdf</span><span class="p">[</span><span class="s">"Clus_Db"</span><span class="p">]</span><span class="o">=</span><span class="n">labels</span>

<span class="n">realClusterNum</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">in</span> <span class="n">labels</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">clusterNum</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>


<span class="c1"># A sample of clusters
</span><span class="n">pdf</span><span class="p">[[</span><span class="s">"Stn_Name"</span><span class="p">,</span><span class="s">"Tx"</span><span class="p">,</span><span class="s">"™"</span><span class="p">,</span><span class="s">"Clus_Db"</span><span class="p">]].</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Visualization of clusters based on location and temperture
</span><span class="kn">from</span> <span class="nn">mpl_toolkits.basemap</span> <span class="kn">import</span> <span class="n">Basemap</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="n">rcParams</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">rcParams</span><span class="p">[</span><span class="s">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>

<span class="n">my_map</span> <span class="o">=</span> <span class="n">Basemap</span><span class="p">(</span><span class="n">projection</span><span class="o">=</span><span class="s">'merc'</span><span class="p">,</span>
            <span class="n">resolution</span> <span class="o">=</span> <span class="s">'l'</span><span class="p">,</span> <span class="n">area_thresh</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">,</span>
            <span class="n">llcrnrlon</span><span class="o">=</span><span class="n">llon</span><span class="p">,</span> <span class="n">llcrnrlat</span><span class="o">=</span><span class="n">llat</span><span class="p">,</span> <span class="c1">#min longitude (llcrnrlon) and latitude (llcrnrlat)
</span>            <span class="n">urcrnrlon</span><span class="o">=</span><span class="n">ulon</span><span class="p">,</span> <span class="n">urcrnrlat</span><span class="o">=</span><span class="n">ulat</span><span class="p">)</span> <span class="c1">#max longitude (urcrnrlon) and latitude (urcrnrlat)
</span>
<span class="n">my_map</span><span class="p">.</span><span class="n">drawcoastlines</span><span class="p">()</span>
<span class="n">my_map</span><span class="p">.</span><span class="n">drawcountries</span><span class="p">()</span>
<span class="c1">#my_map.drawmapboundary()
</span><span class="n">my_map</span><span class="p">.</span><span class="n">fillcontinents</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="s">'white'</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">my_map</span><span class="p">.</span><span class="n">shadedrelief</span><span class="p">()</span>

<span class="c1"># To create a color map
</span><span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s">'jet'</span><span class="p">)(</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">clusterNum</span><span class="p">))</span>



<span class="c1">#Visualization1
</span><span class="k">for</span> <span class="n">clust_number</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">):</span>
    <span class="n">c</span><span class="o">=</span><span class="p">(([</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.4</span><span class="p">,</span><span class="mf">0.4</span><span class="p">])</span> <span class="k">if</span> <span class="n">clust_number</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">colors</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nb">int</span><span class="p">(</span><span class="n">clust_number</span><span class="p">)])</span>
    <span class="n">clust_set</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">[</span><span class="n">pdf</span><span class="p">.</span><span class="n">Clus_Db</span> <span class="o">==</span> <span class="n">clust_number</span><span class="p">]</span>
    <span class="n">my_map</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">clust_set</span><span class="p">.</span><span class="n">xm</span><span class="p">,</span> <span class="n">clust_set</span><span class="p">.</span><span class="n">ym</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="n">c</span><span class="p">,</span>  <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.85</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">clust_number</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">cenx</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">clust_set</span><span class="p">.</span><span class="n">xm</span><span class="p">)</span>
        <span class="n">ceny</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">clust_set</span><span class="p">.</span><span class="n">ym</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">cenx</span><span class="p">,</span><span class="n">ceny</span><span class="p">,</span><span class="nb">str</span><span class="p">(</span><span class="n">clust_number</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">,)</span>
        <span class="k">print</span> <span class="p">(</span><span class="s">"Cluster "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">clust_number</span><span class="p">)</span><span class="o">+</span><span class="s">', Avg Temp: '</span><span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">clust_set</span><span class="p">.</span><span class="err">™</span><span class="p">)))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="introduction-to-recommender-system">Introduction to Recommender System</h2>

<h3 id="two-types-of-recommender-systems">Two Types of recommender systems</h3>

<p><strong>Content-based</strong>: Show more of the type of content which the user has liked before.
<strong>Collaborative Filtering:</strong> show more of the content which is popular among the neighbors of the client.</p>

<p><img src="/media/15842755659220/15847911144009.jpg" alt="-w840" width="600px" /></p>

<p><strong>Implementing recommender system</strong></p>

<ul>
  <li>Memory-based
    <ul>
      <li>Uses the entire user-item dataset to generate a recommendation</li>
      <li>uses statistical techniques to approximate users or items. E.g.: Pearson correlation, cosine similarity, euclidean distance, etc.</li>
    </ul>
  </li>
  <li>Model-based
    <ul>
      <li>Develops a model of users in an attempt to learn their preference</li>
      <li>Models can be created using ML techniques like regression, clustering, classification, etc.</li>
    </ul>
  </li>
</ul>

<h3 id="content-based-recommender-systems">Content-based recommender systems</h3>

<p>In content-based recommender system, the features X of the items are available.</p>

<p><img src="/media/15842755659220/15847915455544.jpg" alt="-w400" width="600px" /></p>

<p><strong>Weighing the genres</strong></p>

<p><code class="language-plaintext highlighter-rouge">Weighted Genre Matrix = X.*r</code>
Then we can predict the <strong>user profile</strong> as the sum of each rows: <code class="language-plaintext highlighter-rouge">(X.*r).sum(axis=0)</code></p>

<p><img src="/media/15842755659220/15847939370913.jpg" alt="-w900" width="600px" /></p>

<p>We have to normalize the user profile vector, since the it is now related to the number of ratings given by the user.</p>

<p><img src="/media/15842755659220/15847939623412.jpg" alt="-w500" width="600px" /></p>

<p>We then use the user profile vector to predict the predicted ratings: $X*\theta $</p>

<h3 id="lab-content-based-recommender-system">Lab: content-based recommender system</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
</pre></td><td class="rouge-code"><pre><span class="c1">#Dataframe manipulation library
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="c1">#Math functions, we'll only need the sqrt function so let's import only that
</span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c1">#Storing the movie information into a pandas dataframe
</span><span class="n">movies_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'movies.csv'</span><span class="p">)</span>
<span class="c1">#Storing the user information into a pandas dataframe
</span><span class="n">ratings_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'ratings.csv'</span><span class="p">)</span>
<span class="c1">#Head is a function that gets the first N rows of a dataframe. N's default is 5.
</span><span class="n">movies_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1">#Using regular expressions to find a year stored between parentheses
#We specify the parantheses so we don't conflict with movies that have years in their titles
</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'year'</span><span class="p">]</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">.</span><span class="n">title</span><span class="p">.</span><span class="nb">str</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="s">'(\(\d\d\d\d\))'</span><span class="p">,</span><span class="n">expand</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1">#Removing the parentheses
</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'year'</span><span class="p">]</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">.</span><span class="n">year</span><span class="p">.</span><span class="nb">str</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="s">'(\d\d\d\d)'</span><span class="p">,</span><span class="n">expand</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1">#Removing the years from the 'title' column
</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">.</span><span class="n">title</span><span class="p">.</span><span class="nb">str</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'(\(\d\d\d\d\))'</span><span class="p">,</span> <span class="s">''</span><span class="p">)</span>
<span class="c1">#Applying the strip function to get rid of any ending whitespace characters that may have appeared
</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">[</span><span class="s">'title'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="n">strip</span><span class="p">())</span>
<span class="n">movies_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1">#Every genre is separated by a | so we simply have to call the split function on |
</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'genres'</span><span class="p">]</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">.</span><span class="n">genres</span><span class="p">.</span><span class="nb">str</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'|'</span><span class="p">)</span>
<span class="n">movies_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1">#Copying the movie dataframe into a new one since we won't need to use the genre information in our first case.
</span><span class="n">moviesWithGenres_df</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1">#For every row in the dataframe, iterate through the list of genres and place a 1 into the corresponding column
</span><span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">movies_df</span><span class="p">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">genre</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[</span><span class="s">'genres'</span><span class="p">]:</span>
        <span class="n">moviesWithGenres_df</span><span class="p">.</span><span class="n">at</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="n">genre</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1">#Filling in the NaN values with 0 to show that a movie doesn't have that column's genre
</span><span class="n">moviesWithGenres_df</span> <span class="o">=</span> <span class="n">moviesWithGenres_df</span><span class="p">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">moviesWithGenres_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>


<span class="n">ratings_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
<span class="c1">#Drop removes a specified row or column from a dataframe
</span><span class="n">ratings_df</span> <span class="o">=</span> <span class="n">ratings_df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'timestamp'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ratings_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">userInput</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s">'title'</span><span class="p">:</span><span class="s">'Breakfast Club, The'</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">:</span><span class="mi">5</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'title'</span><span class="p">:</span><span class="s">'Toy Story'</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">:</span><span class="mf">3.5</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'title'</span><span class="p">:</span><span class="s">'Jumanji'</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">:</span><span class="mi">2</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'title'</span><span class="p">:</span><span class="s">"Pulp Fiction"</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">:</span><span class="mi">5</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'title'</span><span class="p">:</span><span class="s">'Akira'</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">:</span><span class="mf">4.5</span><span class="p">}</span>
        <span class="p">]</span>
<span class="n">inputMovies</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">userInput</span><span class="p">)</span>
<span class="n">inputMovies</span>

<span class="c1"># Add movieID to input user
#Filtering out the movies by title
</span><span class="n">inputId</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">[</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'title'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">inputMovies</span><span class="p">[</span><span class="s">'title'</span><span class="p">].</span><span class="n">tolist</span><span class="p">())]</span>
<span class="c1">#Then merging it so we can get the movieId. It's implicitly merging it by title.
</span><span class="n">inputMovies</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">inputId</span><span class="p">,</span> <span class="n">inputMovies</span><span class="p">)</span>
<span class="c1">#Dropping information we won't use from the input dataframe
</span><span class="n">inputMovies</span> <span class="o">=</span> <span class="n">inputMovies</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'genres'</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">drop</span><span class="p">(</span><span class="s">'year'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1">#Final input dataframe
#If a movie you added in above isn't here, then it might not be in the original
#dataframe or it might spelled differently, please check capitalisation.
</span><span class="n">inputMovies</span>


<span class="c1">#Filtering out the movies from the input
</span><span class="n">userMovies</span> <span class="o">=</span> <span class="n">moviesWithGenres_df</span><span class="p">[</span><span class="n">moviesWithGenres_df</span><span class="p">[</span><span class="s">'movieId'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">inputMovies</span><span class="p">[</span><span class="s">'movieId'</span><span class="p">].</span><span class="n">tolist</span><span class="p">())]</span>
<span class="n">userMovies</span>

<span class="c1">#Resetting the index to avoid future issues
</span><span class="n">userMovies</span> <span class="o">=</span> <span class="n">userMovies</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#Dropping unnecessary issues due to save memory and to avoid issues
</span><span class="n">userGenreTable</span> <span class="o">=</span> <span class="n">userMovies</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'movieId'</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">drop</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">drop</span><span class="p">(</span><span class="s">'genres'</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">drop</span><span class="p">(</span><span class="s">'year'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">userGenreTable</span>

<span class="n">inputMovies</span><span class="p">[</span><span class="s">'rating'</span><span class="p">]</span>

<span class="c1">#Dot produt to get weights
</span><span class="n">userProfile</span> <span class="o">=</span> <span class="n">userGenreTable</span><span class="p">.</span><span class="n">transpose</span><span class="p">().</span><span class="n">dot</span><span class="p">(</span><span class="n">inputMovies</span><span class="p">[</span><span class="s">'rating'</span><span class="p">])</span>
<span class="c1">#The user profile
</span><span class="n">userProfile</span>

<span class="c1">#Now let's get the genres of every movie in our original dataframe
</span><span class="n">genreTable</span> <span class="o">=</span> <span class="n">moviesWithGenres_df</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">moviesWithGenres_df</span><span class="p">[</span><span class="s">'movieId'</span><span class="p">])</span>
<span class="c1">#And drop the unnecessary information
</span><span class="n">genreTable</span> <span class="o">=</span> <span class="n">genreTable</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'movieId'</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">drop</span><span class="p">(</span><span class="s">'title'</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">drop</span><span class="p">(</span><span class="s">'genres'</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">drop</span><span class="p">(</span><span class="s">'year'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">genreTable</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1">#Multiply the genres by the weights and then take the weighted average
</span><span class="n">recommendationTable_df</span> <span class="o">=</span> <span class="p">((</span><span class="n">genreTable</span><span class="o">*</span><span class="n">userProfile</span><span class="p">).</span><span class="nb">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">userProfile</span><span class="p">.</span><span class="nb">sum</span><span class="p">())</span>
<span class="n">recommendationTable_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1">#Sort our recommendations in descending order
</span><span class="n">recommendationTable_df</span> <span class="o">=</span> <span class="n">recommendationTable_df</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1">#Just a peek at the values
</span><span class="n">recommendationTable_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1">#The final recommendation table
</span><span class="n">movies_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'movieId'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">recommendationTable_df</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">20</span><span class="p">).</span><span class="n">keys</span><span class="p">())]</span>



</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="collaborative-filtering">Collaborative Filtering</h3>

<p><img src="/media/15842755659220/15847971392764.jpg" alt="-w600" width="600px" /></p>

<p><img src="/media/15842755659220/15847971831100.jpg" alt="-w600" width="600px" /></p>

<p><img src="/media/15842755659220/15847972974344.jpg" alt="-w600 " width="600px" /></p>

<p><strong>User-based VS Item-based</strong></p>

<p><img src="/media/15842755659220/15847973819217.jpg" alt="-w600" width="600px" /></p>

<p><strong>Challenges of collaborative filtering</strong></p>

<ul>
  <li>Data Sparcity
    <ul>
      <li>Users in general rate only a limited number of items</li>
    </ul>
  </li>
  <li>Cold start
    <ul>
      <li>Difficulty in recommendations to new users or new items</li>
    </ul>
  </li>
  <li>Scalibility
    <ul>
      <li>Increase in number of users or items</li>
    </ul>
  </li>
</ul>

<h4 id="lab-collaborative-filtering-on-movies">Lab: Collaborative filtering on movies</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
</pre></td><td class="rouge-code"><pre><span class="c1"># Preprocessing
#Dataframe manipulation library
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="c1">#Math functions, we'll only need the sqrt function so let's import only that
</span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="c1">#Storing the movie information into a pandas dataframe
</span><span class="n">movies_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'movies.csv'</span><span class="p">)</span>
<span class="c1">#Storing the user information into a pandas dataframe
</span><span class="n">ratings_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'ratings.csv'</span><span class="p">)</span>

<span class="c1">#Head is a function that gets the first N rows of a dataframe. N's default is 5.
</span><span class="n">movies_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1">#Using regular expressions to find a year stored between parentheses
#We specify the parantheses so we don't conflict with movies that have years in their titles
</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'year'</span><span class="p">]</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">.</span><span class="n">title</span><span class="p">.</span><span class="nb">str</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="s">'(\(\d\d\d\d\))'</span><span class="p">,</span><span class="n">expand</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1">#Removing the parentheses
</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'year'</span><span class="p">]</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">.</span><span class="n">year</span><span class="p">.</span><span class="nb">str</span><span class="p">.</span><span class="n">extract</span><span class="p">(</span><span class="s">'(\d\d\d\d)'</span><span class="p">,</span><span class="n">expand</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1">#Removing the years from the 'title' column
</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">.</span><span class="n">title</span><span class="p">.</span><span class="nb">str</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'(\(\d\d\d\d\))'</span><span class="p">,</span> <span class="s">''</span><span class="p">)</span>
<span class="c1">#Applying the strip function to get rid of any ending whitespace characters that may have appeared
</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">[</span><span class="s">'title'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="n">strip</span><span class="p">())</span>


<span class="c1">#Dropping the genres column
</span><span class="n">movies_df</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'genres'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1">#Drop removes a specified row or column from a dataframe
</span><span class="n">ratings_df</span> <span class="o">=</span> <span class="n">ratings_df</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'timestamp'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Collaborative filtering
</span>
<span class="n">userInput</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s">'title'</span><span class="p">:</span><span class="s">'Breakfast Club, The'</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">:</span><span class="mi">5</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'title'</span><span class="p">:</span><span class="s">'Toy Story'</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">:</span><span class="mf">3.5</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'title'</span><span class="p">:</span><span class="s">'Jumanji'</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">:</span><span class="mi">2</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'title'</span><span class="p">:</span><span class="s">"Pulp Fiction"</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">:</span><span class="mi">5</span><span class="p">},</span>
            <span class="p">{</span><span class="s">'title'</span><span class="p">:</span><span class="s">'Akira'</span><span class="p">,</span> <span class="s">'rating'</span><span class="p">:</span><span class="mf">4.5</span><span class="p">}</span>
        <span class="p">]</span>
<span class="n">inputMovies</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">userInput</span><span class="p">)</span>
<span class="n">inputMovies</span>


<span class="c1">#Filtering out the movies by title
</span><span class="n">inputId</span> <span class="o">=</span> <span class="n">movies_df</span><span class="p">[</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'title'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">inputMovies</span><span class="p">[</span><span class="s">'title'</span><span class="p">].</span><span class="n">tolist</span><span class="p">())]</span>
<span class="c1">#Then merging it so we can get the movieId. It's implicitly merging it by title.
</span><span class="n">inputMovies</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">inputId</span><span class="p">,</span> <span class="n">inputMovies</span><span class="p">)</span>
<span class="c1">#Dropping information we won't use from the input dataframe
</span><span class="n">inputMovies</span> <span class="o">=</span> <span class="n">inputMovies</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="s">'year'</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1">#Final input dataframe
#If a movie you added in above isn't here, then it might not be in the original
#dataframe or it might spelled differently, please check capitalisation.
</span><span class="n">inputMovies</span>

<span class="c1">#Filtering out users that have watched movies that the input has watched and storing it
</span><span class="n">userSubset</span> <span class="o">=</span> <span class="n">ratings_df</span><span class="p">[</span><span class="n">ratings_df</span><span class="p">[</span><span class="s">'movieId'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">inputMovies</span><span class="p">[</span><span class="s">'movieId'</span><span class="p">].</span><span class="n">tolist</span><span class="p">())]</span>
<span class="n">userSubset</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1">#Groupby creates several sub dataframes where they all have the same value in the column specified as the parameter
</span><span class="n">userSubsetGroup</span> <span class="o">=</span> <span class="n">userSubset</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'userId'</span><span class="p">])</span>

<span class="c1"># Lets look at the one of the users: ID=1130
</span><span class="n">userSubsetGroup</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="mi">1130</span><span class="p">)</span>

<span class="c1">#Sorting it so users with movie most in common with the input will have priority
</span><span class="n">userSubsetGroup</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">userSubsetGroup</span><span class="p">,</span>  <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># We will select a subset of users to iterate through. This limit is imposed because we don't want to waste too much time going through every single user.
</span>
<span class="n">userSubsetGroup</span> <span class="o">=</span> <span class="n">userSubsetGroup</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">]</span>

<span class="c1">#Store the Pearson Correlation in a dictionary, where the key is the user Id and the value is the coefficient
</span><span class="n">pearsonCorrelationDict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1">#For every user group in our subset
</span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">userSubsetGroup</span><span class="p">:</span>
    <span class="c1">#Let's start by sorting the input and current user group so the values aren't mixed up later on
</span>    <span class="n">group</span> <span class="o">=</span> <span class="n">group</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">'movieId'</span><span class="p">)</span>
    <span class="n">inputMovies</span> <span class="o">=</span> <span class="n">inputMovies</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">'movieId'</span><span class="p">)</span>
    <span class="c1">#Get the N for the formula
</span>    <span class="n">nRatings</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">)</span>
    <span class="c1">#Get the review scores for the movies that they both have in common
</span>    <span class="n">temp_df</span> <span class="o">=</span> <span class="n">inputMovies</span><span class="p">[</span><span class="n">inputMovies</span><span class="p">[</span><span class="s">'movieId'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="s">'movieId'</span><span class="p">].</span><span class="n">tolist</span><span class="p">())]</span>
    <span class="c1">#And then store them in a temporary buffer variable in a list format to facilitate future calculations
</span>    <span class="n">tempRatingList</span> <span class="o">=</span> <span class="n">temp_df</span><span class="p">[</span><span class="s">'rating'</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
    <span class="c1">#Let's also put the current user group reviews in a list format
</span>    <span class="n">tempGroupList</span> <span class="o">=</span> <span class="n">group</span><span class="p">[</span><span class="s">'rating'</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
    <span class="c1">#Now let's calculate the pearson correlation between two users, so called, x and y
</span>    <span class="n">Sxx</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">i</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tempRatingList</span><span class="p">])</span> <span class="o">-</span> <span class="nb">pow</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">tempRatingList</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">nRatings</span><span class="p">)</span>
    <span class="n">Syy</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">i</span><span class="o">**</span><span class="mi">2</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tempGroupList</span><span class="p">])</span> <span class="o">-</span> <span class="nb">pow</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">tempGroupList</span><span class="p">),</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">nRatings</span><span class="p">)</span>
    <span class="n">Sxy</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span> <span class="n">i</span><span class="o">*</span><span class="n">j</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tempRatingList</span><span class="p">,</span> <span class="n">tempGroupList</span><span class="p">))</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">tempRatingList</span><span class="p">)</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">tempGroupList</span><span class="p">)</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">nRatings</span><span class="p">)</span>

    <span class="c1">#If the denominator is different than zero, then divide, else, 0 correlation.
</span>    <span class="k">if</span> <span class="n">Sxx</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">Syy</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">pearsonCorrelationDict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Sxy</span><span class="o">/</span><span class="n">sqrt</span><span class="p">(</span><span class="n">Sxx</span><span class="o">*</span><span class="n">Syy</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">pearsonCorrelationDict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>


<span class="n">pearsonCorrelationDict</span><span class="p">.</span><span class="n">items</span><span class="p">()</span>

<span class="n">pearsonDF</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">pearsonCorrelationDict</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s">'index'</span><span class="p">)</span>
<span class="n">pearsonDF</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'similarityIndex'</span><span class="p">]</span>
<span class="n">pearsonDF</span><span class="p">[</span><span class="s">'userId'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pearsonDF</span><span class="p">.</span><span class="n">index</span>
<span class="n">pearsonDF</span><span class="p">.</span><span class="n">index</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pearsonDF</span><span class="p">))</span>
<span class="n">pearsonDF</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>


<span class="n">topUsers</span><span class="o">=</span><span class="n">pearsonDF</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">'similarityIndex'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">50</span><span class="p">]</span>
<span class="n">topUsers</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>


<span class="n">topUsersRating</span><span class="o">=</span><span class="n">topUsers</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">ratings_df</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="s">'userId'</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="s">'userId'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s">'inner'</span><span class="p">)</span>
<span class="n">topUsersRating</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1">#Multiplies the similarity by the user's ratings
</span><span class="n">topUsersRating</span><span class="p">[</span><span class="s">'weightedRating'</span><span class="p">]</span> <span class="o">=</span> <span class="n">topUsersRating</span><span class="p">[</span><span class="s">'similarityIndex'</span><span class="p">]</span><span class="o">*</span><span class="n">topUsersRating</span><span class="p">[</span><span class="s">'rating'</span><span class="p">]</span>
<span class="n">topUsersRating</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1">#Applies a sum to the topUsers after grouping it up by userId
</span><span class="n">tempTopUsersRating</span> <span class="o">=</span> <span class="n">topUsersRating</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'movieId'</span><span class="p">).</span><span class="nb">sum</span><span class="p">()[[</span><span class="s">'similarityIndex'</span><span class="p">,</span><span class="s">'weightedRating'</span><span class="p">]]</span>
<span class="n">tempTopUsersRating</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'sum_similarityIndex'</span><span class="p">,</span><span class="s">'sum_weightedRating'</span><span class="p">]</span>
<span class="n">tempTopUsersRating</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>


<span class="c1">#Creates an empty dataframe
</span><span class="n">recommendation_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="c1">#Now we take the weighted average
</span><span class="n">recommendation_df</span><span class="p">[</span><span class="s">'weighted average recommendation score'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tempTopUsersRating</span><span class="p">[</span><span class="s">'sum_weightedRating'</span><span class="p">]</span><span class="o">/</span><span class="n">tempTopUsersRating</span><span class="p">[</span><span class="s">'sum_similarityIndex'</span><span class="p">]</span>
<span class="n">recommendation_df</span><span class="p">[</span><span class="s">'movieId'</span><span class="p">]</span> <span class="o">=</span> <span class="n">tempTopUsersRating</span><span class="p">.</span><span class="n">index</span>
<span class="n">recommendation_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">recommendation_df</span> <span class="o">=</span> <span class="n">recommendation_df</span><span class="p">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">'weighted average recommendation score'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">recommendation_df</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="n">movies_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">movies_df</span><span class="p">[</span><span class="s">'movieId'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">recommendation_df</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)[</span><span class="s">'movieId'</span><span class="p">].</span><span class="n">tolist</span><span class="p">())]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="final-assignment">Final Assignment</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184
185
186
187
188
189
190
191
192
193
194
195
196
197
198
199
200
201
202
203
204
205
206
207
208
209
210
211
212
213
214
215
216
217
218
219
220
221
222
223
224
225
226
227
228
229
230
231
232
233
234
235
236
237
238
239
240
241
242
243
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="n">NullFormatter</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.ticker</span> <span class="k">as</span> <span class="n">ticker</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'loan_train.csv'</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">df</span><span class="p">[</span><span class="s">'due_date'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'due_date'</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s">'effective_date'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'effective_date'</span><span class="p">])</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">df</span><span class="p">[</span><span class="s">'loan_status'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>


<span class="c1"># sns.FacetGrid
# on principle
</span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">Principal</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">.</span><span class="n">Principal</span><span class="p">.</span><span class="nb">max</span><span class="p">(),</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">FacetGrid</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">"Gender"</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">"loan_status"</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">"Set1"</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">g</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">,</span> <span class="s">'Principal'</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s">"k"</span><span class="p">)</span>

<span class="n">g</span><span class="p">.</span><span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># on payment status
</span><span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">.</span><span class="n">age</span><span class="p">.</span><span class="nb">max</span><span class="p">(),</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">FacetGrid</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">"Gender"</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">"loan_status"</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">"Set1"</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">g</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">,</span> <span class="s">'age'</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s">"k"</span><span class="p">)</span>

<span class="n">g</span><span class="p">.</span><span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># day of week
</span><span class="n">df</span><span class="p">[</span><span class="s">'dayofweek'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'effective_date'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">dayofweek</span>
<span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">dayofweek</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">.</span><span class="n">dayofweek</span><span class="p">.</span><span class="nb">max</span><span class="p">(),</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">FacetGrid</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">"Gender"</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">"loan_status"</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">"Set1"</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">g</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">,</span> <span class="s">'dayofweek'</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s">"k"</span><span class="p">)</span>
<span class="n">g</span><span class="p">.</span><span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1"># feature binarization
</span><span class="n">df</span><span class="p">[</span><span class="s">'weekend'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'dayofweek'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="n">x</span><span class="o">&gt;</span><span class="mi">3</span><span class="p">)</span>  <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1"># Convert Categorical Features to numerical values
</span><span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'Gender'</span><span class="p">])[</span><span class="s">'loan_status'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Here normalize=True will give the probability instead of the number.
</span>
<span class="n">df</span><span class="p">[</span><span class="s">'Gender'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">to_replace</span><span class="o">=</span><span class="p">[</span><span class="s">'male'</span><span class="p">,</span><span class="s">'female'</span><span class="p">],</span> <span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>


<span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'education'</span><span class="p">])[</span><span class="s">'loan_status'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># How about education
</span><span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'education'</span><span class="p">])[</span><span class="s">'loan_status'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame
</span>
<span class="n">Feature</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'Principal'</span><span class="p">,</span><span class="s">'terms'</span><span class="p">,</span><span class="s">'age'</span><span class="p">,</span><span class="s">'Gender'</span><span class="p">,</span><span class="s">'weekend'</span><span class="p">]]</span>
<span class="n">Feature</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Feature</span><span class="p">,</span><span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'education'</span><span class="p">])],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Feature</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Master or Above'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">Feature</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1"># Feature selection
</span><span class="n">X</span> <span class="o">=</span> <span class="n">Feature</span>
<span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'loan_status'</span><span class="p">].</span><span class="n">values</span>
<span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># Normalize Data
</span><span class="n">X</span><span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># Classification
# KNN
# Train Test Split
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Train set:'</span><span class="p">,</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span>  <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="s">'Test set:'</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span>  <span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Find the Best K
</span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="n">Ks</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">mean_acc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Ks</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">std_acc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">Ks</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">ConfustionMx</span> <span class="o">=</span> <span class="p">[];</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">Ks</span><span class="p">):</span>

    <span class="c1">#Train Model and Predict
</span>    <span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">n</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">yhat</span><span class="o">=</span><span class="n">neigh</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">mean_acc</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>


    <span class="n">std_acc</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">yhat</span><span class="o">==</span><span class="n">y_test</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">yhat</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">mean_acc</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">Ks</span><span class="p">),</span><span class="n">mean_acc</span><span class="p">,</span><span class="s">'g'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">fill_between</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">Ks</span><span class="p">),</span><span class="n">mean_acc</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">std_acc</span><span class="p">,</span><span class="n">mean_acc</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">std_acc</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">((</span><span class="s">'Accuracy '</span><span class="p">,</span> <span class="s">'+/- 3xstd'</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Accuracy '</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Number of Nabors (K)'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Train with the Best K
# Train data
</span><span class="n">k</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1">#Train Model and Predict
</span><span class="n">neigh</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">k</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">neigh</span>
<span class="n">yhat_KNN</span> <span class="o">=</span> <span class="n">neigh</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Evaluation
</span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Train set Accuracy: "</span><span class="p">,</span> <span class="n">metrics</span><span class="p">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">neigh</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>

<span class="c1"># Decision Tree
</span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="c1"># X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.3, random_state=3)
</span>
<span class="c1"># Train the model
</span><span class="n">drugTree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s">"entropy"</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">drugTree</span> <span class="c1"># it shows the default parameters
</span>
<span class="n">drugTree</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="n">yhat_predTree</span> <span class="o">=</span> <span class="n">drugTree</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1">#SVM
# Training/Modeling
</span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'rbf'</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">yhat_svm</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">yhat</span> <span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="c1"># Logistic Regression
</span>
<span class="c1"># Split the test and train set
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Training
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="n">LR</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s">'liblinear'</span><span class="p">).</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">LR</span>

<span class="n">yhat_lr</span> <span class="o">=</span> <span class="n">LR</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">yhat_lr</span>


<span class="c1"># Evaluation
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">jaccard_similarity_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>

<span class="c1"># Load test set for evaluation
</span><span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'loan_test.csv'</span><span class="p">)</span>
<span class="n">test_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">test_df</span><span class="p">[</span><span class="s">'due_date'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s">'due_date'</span><span class="p">])</span>
<span class="n">test_df</span><span class="p">[</span><span class="s">'effective_date'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s">'effective_date'</span><span class="p">])</span>
<span class="n">test_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">test_df</span><span class="p">[</span><span class="s">'dayofweek'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s">'effective_date'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">dayofweek</span>
<span class="n">test_df</span><span class="p">[</span><span class="s">'weekend'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s">'dayofweek'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="n">x</span><span class="o">&gt;</span><span class="mi">3</span><span class="p">)</span>  <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">test_df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'Gender'</span><span class="p">])[</span><span class="s">'loan_status'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">test_df</span><span class="p">[</span><span class="s">'Gender'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">to_replace</span><span class="o">=</span><span class="p">[</span><span class="s">'male'</span><span class="p">,</span><span class="s">'female'</span><span class="p">],</span> <span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">test_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>


<span class="n">test_df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'education'</span><span class="p">])[</span><span class="s">'loan_status'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">Feature_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[[</span><span class="s">'Principal'</span><span class="p">,</span><span class="s">'terms'</span><span class="p">,</span><span class="s">'age'</span><span class="p">,</span><span class="s">'Gender'</span><span class="p">,</span><span class="s">'weekend'</span><span class="p">]]</span>
<span class="n">Feature_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Feature_test</span><span class="p">,</span><span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">test_df</span><span class="p">[</span><span class="s">'education'</span><span class="p">])],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">Feature_test</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Master or Above'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">Feature_test</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">Feature_test</span>
<span class="n">X_test</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="p">[</span><span class="s">'loan_status'</span><span class="p">].</span><span class="n">values</span>
<span class="n">y_test</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="n">X_test</span><span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">StandardScaler</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">).</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="n">yh_knn</span><span class="o">=</span><span class="n">neigh</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">yh_dt</span><span class="o">=</span><span class="n">drugTree</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">yh_svm</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">yh_lr</span><span class="o">=</span><span class="n">LR</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">yhat_all</span><span class="o">=</span><span class="p">[</span><span class="n">yh_knn</span><span class="p">,</span><span class="n">yh_dt</span><span class="p">,</span><span class="n">yh_svm</span><span class="p">,</span><span class="n">yh_lr</span><span class="p">]</span>

<span class="c1"># Report
# f1_score
</span><span class="n">score_f1</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">yi</span> <span class="ow">in</span> <span class="n">yhat_all</span><span class="p">:</span>
    <span class="n">score_f1</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s">'weighted'</span><span class="p">)</span> <span class="p">)</span>


<span class="c1">#jaccard_similarity_score
</span><span class="n">score_jaccard</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">yi</span> <span class="ow">in</span> <span class="n">yhat_all</span><span class="p">:</span>
    <span class="n">score_jaccard</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">jaccard_similarity_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yi</span><span class="p">)</span> <span class="p">)</span>


<span class="c1">#log loss
</span>
<span class="c1"># y_test_num=pd.DataFrame(y_test).iloc[:,0].apply(lambda x:1  if (x=="PAIDOFF") else 0 ).tolist()
# yh_lr_num=pd.DataFrame(yh_lr).iloc[:,0].apply(lambda x:1  if (x=="PAIDOFF") else 0 ).tolist()
</span><span class="n">yh_lr_prob</span> <span class="o">=</span> <span class="n">LR</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="c1"># use the predicted probability to calculate the log_loss
</span><span class="n">score_logloss</span><span class="o">=</span><span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">yh_lr_prob</span><span class="p">)</span>
<span class="n">score_logloss</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span><span class="n">score_logloss</span><span class="p">])</span>

<span class="c1"># Final report
</span><span class="n">df_result</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s">'KNN'</span><span class="p">,</span><span class="s">'Decision Tree'</span><span class="p">,</span><span class="s">'SVM'</span><span class="p">,</span><span class="s">'LogisticRegression'</span><span class="p">],</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Jaccard'</span><span class="p">,</span><span class="s">'F1-score'</span><span class="p">,</span><span class="s">'LogLoss'</span><span class="p">])</span>
<span class="n">df_result</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">name</span><span class="o">=</span><span class="s">'Algorithm'</span>
<span class="n">df_result</span><span class="p">.</span><span class="n">Jaccard</span><span class="o">=</span><span class="n">score_jaccard</span>
<span class="n">df_result</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="n">score_f1</span>
<span class="n">df_result</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span><span class="o">=</span><span class="n">score_logloss</span>
<span class="n">df_result</span>
</pre></td></tr></tbody></table></code></pre></div></div>
:ET