I"€1<p class="notice--info">This series of Data Science posts are my notes for the <a href="https://www.coursera.org/professional-certificates/ibm-data-science">IBM Data Science Professional Certificate</a>.</p>

<h2 id="importing-datasets">Importing Datasets</h2>

<h3 id="python-packages-for-data-science">Python Packages for Data Science</h3>

<p>We have divided the Python data analysis libraries into three groups.</p>

<ul>
  <li>
    <p>Scientific Computing Libraries</p>

    <ul>
      <li><strong>Pandas</strong> offers data structure and tools for effective data manipulation and analysis. It is designed to provided easy indexing functionality.</li>
      <li>The <strong>NumPy</strong> library uses arrays for its inputs and outputs. It can be extended to objects for matrices and with minor coding changes, developers can perform fast array processing.</li>
      <li><strong>SciPy</strong> includes functions for some advanced math problems as listed on this slide, as well as data visualization.</li>
    </ul>
  </li>
  <li>
    <p>Visualization Libraries</p>

    <ul>
      <li>
        <p><strong>The Matplotlib package</strong> is the most well known library for data visualization. It is great for making graphs and plots. The graphs are also highly customizable.</p>
      </li>
      <li>
        <p><strong>Seaborn</strong>. It is based on Matplotlib. It‚Äôs very easy to generate various plots such as heat maps, time series and violin plots.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Algorithmic Libraries</p>

    <ul>
      <li>The <strong>Scikit-learn</strong> library contains tools statistical modeling, including regression, classification, clustering, and so on. This library is built on NumPy, SciPy and Matplotib.</li>
      <li><strong>Statsmodels</strong> is also a Python module that allows users to explore data, estimate statistical models, and perform statistical tests.</li>
    </ul>
  </li>
</ul>

<h3 id="importing-and-exporting-data-in-python">Importing and Exporting Data in Python</h3>

<p>Two important properties:</p>

<ul>
  <li>Format: csv, json, xlsx‚Ä¶</li>
  <li>File Path of Dataset:
    <ul>
      <li>Computer: /User/Desktop/my.csv</li>
      <li>Internet: https://google.com/my.csv</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="c1"># read the online file by the URL provided above, and assign it to variable "df"
</span><span class="n">path</span><span class="o">=</span><span class="s">"https://archive.ics.uci.edu/ml/machine-learning-database/autos/imports-85.data"</span>

<span class="c1">#By default, the pd.read_csv assumes there is a header line. If no header, claim it.
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span><span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">tail</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="c1">#Replace the default header:
</span><span class="n">headers</span><span class="o">=</span><span class="p">[</span><span class="s">'c1'</span><span class="p">,</span><span class="s">'c2'</span><span class="p">,</span><span class="s">'c3'</span><span class="p">,....,</span><span class="s">'c10'</span><span class="p">]</span>
<span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="o">=</span><span class="n">headers</span>

<span class="c1">#Exporting a pandas dataframe to csv
</span><span class="n">path</span><span class="o">=</span><span class="s">'c:\windows\...\my.csv'</span>
<span class="n">df</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

\[\begin{array}{|l|l|l|}\hline \text { Data Format } &amp; \text { Read } &amp; \text { Save } \\ \hline \text { csv } &amp; \text { pd.read_csv() } &amp; \text { df.to }_{-} \text {csv }() \\ \hline \text { json } &amp; \text { pd.read } \text { json }() &amp; \text { df.to }_{\text {json }()} \\ \hline \text { Excel } &amp; \text { pd.read_excel }() &amp; \text { df.to }_{\text {- excel }()} \\ \hline \text { sq } 1 &amp; \text { pd.read_sql() } &amp; \text { df.to_sql() } \\ \hline\end{array}\]

<h3 id="getting-started-analyzing-data-in-python">Getting Started Analyzing Data in Python</h3>

<table>
  <thead>
    <tr>
      <th>Data Formate</th>
      <th>Read</th>
      <th>Save</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>csv</td>
      <td><code class="language-plaintext highlighter-rouge">pd.read_csv()</code></td>
      <td><code class="language-plaintext highlighter-rouge">df.to_csv()</code></td>
    </tr>
    <tr>
      <td>json</td>
      <td><code class="language-plaintext highlighter-rouge">pd.read_json()</code></td>
      <td><code class="language-plaintext highlighter-rouge">df.to_json()</code></td>
    </tr>
    <tr>
      <td>excel</td>
      <td><code class="language-plaintext highlighter-rouge">pd.read_excel()</code></td>
      <td><code class="language-plaintext highlighter-rouge">df.to_excel()</code></td>
    </tr>
    <tr>
      <td>hdf</td>
      <td><code class="language-plaintext highlighter-rouge">pd.read_hdf()</code></td>
      <td><code class="language-plaintext highlighter-rouge">df.to_hdf()</code></td>
    </tr>
    <tr>
      <td>sql</td>
      <td><code class="language-plaintext highlighter-rouge">pd.read_sql()</code></td>
      <td><code class="language-plaintext highlighter-rouge">df.to_sql()</code></td>
    </tr>
    <tr>
      <td>‚Ä¶</td>
      <td>‚Ä¶</td>
      <td>‚Ä¶</td>
    </tr>
  </tbody>
</table>

<p><strong>Check Data Types for two main reasons:</strong></p>

<ul>
  <li>Potential info and type mismatch</li>
  <li>Cimpatibility with python methods</li>
</ul>

<p>In pandas, we use <code class="language-plaintext highlighter-rouge">dataframe.dtypes</code> to check data types</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">df</span><span class="p">.</span><span class="n">dtypes</span>
<span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
<span class="c1"># for full summary statistics
</span><span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s">'all'</span><span class="p">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="n">df</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
<span class="o">------</span>
<span class="o">&lt;</span><span class="k">class</span> <span class="err">'</span><span class="nc">pandas</span><span class="p">.</span><span class="n">core</span><span class="p">.</span><span class="n">frame</span><span class="p">.</span><span class="n">DataFrame</span><span class="s">'&gt;
RangeIndex: 4 entries, 0 to 3
Data columns (total 2 columns):
 #   Column   Non-Null Count  Dtype
---  ------   --------------  -----
 0   Student  4 non-null      object
 1   Grade    4 non-null      int64
dtypes: int64(1), object(1)
memory usage: 192.0+ bytes

#Show the top 30 rows and the bottom 30 rows:
df.info

</span></pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="accessing-databases-with-python">Accessing Databases with Python</h3>

<p>Please check for the SQL category.</p>

<h2 id="data-pre-processing">Data Pre-processing</h2>

<p>Also known as data cleaning, or data wrangling.</p>

<p>Data preprocessing is a necessary step in data analysis. It is the process of converting or mapping data from</p>

<p>one raw form into another format to make it ready for further analysis.</p>

<p>Main learning objectives:</p>

<ul>
  <li>Identify and handle missing values</li>
  <li>Data Formatting</li>
  <li>Data Normalization (centering/scaling)</li>
  <li>Data Binning</li>
  <li>Turning categorical values into numerical variables to make statistical model easier.</li>
</ul>

<h3 id="dealing-with-missing-values-in-python">Dealing with missing values in Python</h3>

<ul>
  <li>
    <p>Check the data collection source</p>
  </li>
  <li>Drop the missing values
    <ul>
      <li>Drop the variable</li>
      <li>Drop the data entry</li>
    </ul>
  </li>
  <li>Replacing the missing values
    <ul>
      <li>Replace it with an average of similar points</li>
      <li>Replace it by frequency</li>
      <li>Replace it based on conditional expectations</li>
    </ul>
  </li>
  <li>Leave it as missing data</li>
</ul>

<p><strong>How to drop missing values in Python?</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td class="rouge-code"><pre><span class="c1">#Check the nulls
</span><span class="n">missing_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">isnull</span><span class="p">()</span>
<span class="n">missing_data</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="c1"># Count missing values in each column
</span><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">missing_data</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="n">values</span><span class="p">.</span><span class="n">tolist</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
    <span class="k">print</span> <span class="p">(</span><span class="n">missing_datadata</span><span class="p">[</span><span class="n">column</span><span class="p">].</span><span class="n">value_counts</span><span class="p">())</span>
    <span class="k">print</span><span class="p">(</span><span class="s">""</span><span class="p">)</span>
<span class="c1"># Use dataframes.dropna()
# Set axis=0 to drop the rows, axis=1 to drop the columns
</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s">'Price'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># Set inplace = True to allow the operation to work on the dataframe itself directly.
</span><span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s">'Price'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">inplace</span> <span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># The codes above are equivalent.
</span>
<span class="c1"># Drop all the rows which contain missing value
</span><span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># reset the index, because we droped several rows!!
</span><span class="n">df</span><span class="p">.</span><span class="n">rest_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>How to replace missing values in Python?</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td class="rouge-code"><pre><span class="c1"># Use dataframe.replace(missing_value,new_value)
</span><span class="n">mean</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'col1'</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
<span class="c1"># Incase the data type is not correct
</span><span class="n">mean</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'col1'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">'float'</span><span class="p">).</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'col1'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'col1'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span><span class="n">mean</span><span class="p">)</span>
<span class="c1"># Alternatively, we can use inplce=Ture
</span><span class="n">df</span><span class="p">[</span><span class="s">'col1'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span><span class="n">mean</span><span class="p">,</span><span class="n">inplce</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># To see the counts for all the unique values in a column
</span><span class="n">df</span><span class="p">[</span><span class="s">'col1'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>
<span class="c1"># We can also use the ".idxmax()" method to calculate for us the most common type automatically:
</span><span class="n">df</span><span class="p">[</span><span class="s">'col1'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">idxmax</span><span class="p">()</span>
<span class="c1"># After we drop some values, we may rant to reset the index
</span><span class="n">df</span><span class="p">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="c1"># convert the value_counts result into a dataframe
</span>
<span class="n">drive_wheels_counts</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'drive-wheels'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">drive_wheels_counts</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'drive-wheels'</span><span class="p">:</span> <span class="s">'value_counts'</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">drive_wheels_counts</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="s">'drive-wheels'</span>
<span class="n">drive_wheels_counts</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="data-formatting-in-python">Data Formatting in Python</h3>

<p>Data is usually collected from different places by different people which may be stored in different formats.  Data formatting means bringing data into a common standard of expression that <strong>allows users to make meaningful comparisons.</strong></p>

<p>As a part of dataset cleaning, data formatting ensures the data is consistent and easily understandable.</p>

<table>
  <thead>
    <tr>
      <th>City</th>
      <th>City</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>NY</td>
      <td>New York</td>
    </tr>
    <tr>
      <td>N.Y</td>
      <td>New York</td>
    </tr>
    <tr>
      <td>NYC</td>
      <td>New York</td>
    </tr>
    <tr>
      <td>New York</td>
      <td>New York</td>
    </tr>
  </tbody>
</table>

<p>For this task, we can use <code class="language-plaintext highlighter-rouge">dataframe.replace(old_value,new_value)</code></p>

<p><strong>Applying calculation to an entire column:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">df</span><span class="p">[</span><span class="s">'col1'</span><span class="p">]</span><span class="o">=</span><span class="mi">100</span><span class="o">/</span><span class="n">df</span><span class="p">[</span><span class="s">'col1'</span><span class="p">]</span>
<span class="n">df</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s">'col1'</span><span class="p">:</span><span class="s">'100_over_col_divided'</span><span class="p">},</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Incorrect Data Types</strong></p>

<p>To identify data types:</p>

<p><code class="language-plaintext highlighter-rouge">dataframe.dtypes</code></p>

<p>To convert data types:</p>

<p><code class="language-plaintext highlighter-rouge">dataframe.astype()</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="c1"># Example: convert data type into integer
</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">].</span><span class="n">astype</span><span class="p">(</span><span class="s">"int64"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[[</span><span class="s">"bore"</span><span class="p">,</span> <span class="s">"stroke"</span><span class="p">]]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">"bore"</span><span class="p">,</span> <span class="s">"stroke"</span><span class="p">]].</span><span class="n">astype</span><span class="p">(</span><span class="s">"float"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[[</span><span class="s">"normalized-losses"</span><span class="p">]]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">"normalized-losses"</span><span class="p">]].</span><span class="n">astype</span><span class="p">(</span><span class="s">"int"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[[</span><span class="s">"price"</span><span class="p">]]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">"price"</span><span class="p">]].</span><span class="n">astype</span><span class="p">(</span><span class="s">"float"</span><span class="p">)</span>
<span class="n">df</span><span class="p">[[</span><span class="s">"peak-rpm"</span><span class="p">]]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">"peak-rpm"</span><span class="p">]].</span><span class="n">astype</span><span class="p">(</span><span class="s">"float"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="data-normalization-in-python">Data Normalization in Python</h3>

<p>Several approaches for normalization:</p>

<p>Min-Max: $\frac{X-mean(X)}{X_{max}-X_{min}}$</p>

<p>Z-score: $\frac{X-mean(X)}{Std(X)}$</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="c1"># Min-Max:
</span><span class="n">df</span><span class="p">[</span><span class="s">'col'</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'col'</span><span class="p">]</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="s">'col'</span><span class="p">].</span><span class="nb">min</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'col'</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="s">'col'</span><span class="p">].</span><span class="nb">min</span><span class="p">())</span>
<span class="c1"># Z-score
</span><span class="n">df</span><span class="p">[</span><span class="s">'col'</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'col'</span><span class="p">]</span><span class="o">-</span><span class="n">df</span><span class="p">[</span><span class="s">'col'</span><span class="p">].</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="n">df</span><span class="p">[</span><span class="s">'col'</span><span class="p">].</span><span class="n">std</span><span class="p">()</span>
<span class="c1"># Alternatively, we can use
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">df</span><span class="p">[</span><span class="s">'Grade'</span><span class="p">]</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Grade'</span><span class="p">]</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Grade'</span><span class="p">]))</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Grade'</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="bnning-in-python">Bnning in Python</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">pandas</span><span class="p">.</span><span class="n">cut</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'col'</span><span class="p">],</span><span class="n">bins</span><span class="p">,</span><span class="n">group_names</span><span class="p">,</span> <span class="n">include_lowest</span> <span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Binning is the process of grouping of values into bins.</p>

<p>Converts numeric into categorical variables.</p>

<p>For example, price is a feature range from 0 to 1000000. We can convert to price into ‚Äúlow price‚Äù, ‚ÄúMid Price‚Äù and ‚ÄúHigh Price‚Äù.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="rouge-code"><pre><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"Price"</span><span class="p">])</span>
<span class="c1"># set x/y labels and plot title
</span><span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"horsepower"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"count"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"horsepower bins"</span><span class="p">)</span>

<span class="c1"># say we want to divide the data into n subsets
</span><span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">"price"</span><span class="p">]),</span><span class="nb">max</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]),</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">goup_names</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,....,</span><span class="n">n</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="s">"price-binned"</span><span class="p">]</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">cut</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span><span class="n">bins</span><span class="p">,</span><span class="n">labels</span><span class="o">=</span><span class="n">group_names</span><span class="p">,</span><span class="n">include_lowest</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">"price-binned"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>

<span class="c1"># Visualization
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="n">pyplot</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">group_names</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">"horsepower-binned"</span><span class="p">].</span><span class="n">value_counts</span><span class="p">())</span>

<span class="c1"># set x/y labels and plot title
</span><span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"horsepower"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"count"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"horsepower bins"</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="turning-categorical-variables-into-quantitative-variables-in-python">Turning categorical variables into quantitative variables in Python</h3>

<p>Approach 1: use dummy variables.</p>

<p>We encode the values by adding new features corresponding to each unique element in the original feature we would like to encode.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="c1"># use pandas.get_dummies() method
</span><span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'fuel'</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right">¬†</th>
      <th style="text-align: right">Student</th>
      <th style="text-align: right">Grade</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: right">John Smith</td>
      <td style="text-align: right">80</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">Jane Smith</td>
      <td style="text-align: right">75</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">John Doe</td>
      <td style="text-align: right">65</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">Jane Doe</td>
      <td style="text-align: right">90</td>
    </tr>
  </tbody>
</table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">dm</span><span class="o">=</span><span class="n">pandas</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">Student</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<table>
  <thead>
    <tr>
      <th style="text-align: right">¬†</th>
      <th style="text-align: right">Jane Doe</th>
      <th style="text-align: right">Jane Smith</th>
      <th style="text-align: right">John Doe</th>
      <th>John Smith</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">0</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">0</td>
      <td>1</td>
    </tr>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">0</td>
      <td>0</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">1</td>
      <td>0</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">1</td>
      <td style="text-align: right">0</td>
      <td style="text-align: right">0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

<h2 id="exploratory-data-analysis-eda">Exploratory Data Analysis (EDA)</h2>

<p>In this module, you will learn about:</p>

<ul>
  <li>Descriptive Statistics</li>
  <li>Groupby</li>
  <li>ANOVA</li>
  <li>Correlation</li>
  <li>Correlation - Statistics</li>
</ul>

<h3 id="descriptive-statistics">Descriptive Statistics</h3>

<h4 id="describe-and-value_counts">describe and value_counts</h4>

<p>Descriptive statistical analysis helps to describe basic features of a dataset and obtains a short summary about the sample and measures of the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s">'all'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s">'column_name'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="box-plots">Box Plots</h4>

<p>Box plots are great way to visualize numeric data, since you can visualize the various distributions of the data.</p>

<p><img src="/media/15832429806135/15836424178554.jpg" alt="-w500" width="500px" /></p>

<p><img src="/media/15832429806135/15836424779223.jpg" alt="-w600" width="500px" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'Drive-wheels'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/media/15832429806135/15836423968486.jpg" alt="-w500" width="500px" /></p>

<hr />

<h4 id="scatter-plot">Scatter Plot</h4>

<p>Scatter plot show the relationship between two variables</p>

<ul>
  <li>Predictor/independent variables on x-axis</li>
  <li>Target/dependent variables on y-axis</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'size_of_house'</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"scatter of house size Vs price"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'size of house'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'price'</span><span class="p">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="groupby-in-python">GroupBy in Python</h3>

<h4 id="groupby">Groupby()</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="n">df</span><span class="p">[</span><span class="s">'Student'</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>

<span class="c1">#groupby single property
</span><span class="n">gg</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">"Student"</span><span class="p">,</span><span class="n">as_index</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># Groupby Multiple Properties
</span><span class="n">gg</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">"Student"</span><span class="p">,</span><span class="s">"Grade"</span><span class="p">],</span><span class="n">as_index</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>
<span class="n">gg</span><span class="p">.</span><span class="n">index</span>

<span class="c1"># We can set the as_index=False
</span><span class="n">gg2</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">"Student"</span><span class="p">,</span><span class="s">"Grade"</span><span class="p">],</span><span class="n">as_index</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">mean</span><span class="p">()</span>

<span class="c1"># We can only work with the columns we care about by slicing first
</span><span class="n">df</span><span class="p">[[</span><span class="s">'price'</span><span class="p">,</span><span class="s">'body-style'</span><span class="p">]].</span><span class="n">groupby</span><span class="p">([</span><span class="s">'body-style'</span><span class="p">]).</span><span class="n">mean</span><span class="p">()</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="pivot">Pivot()</h4>

<p>One variable as the columns and another variable as rows, the rest values are displayed in this <strong>two-dimensional</strong> panel.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="n">df_pivot</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s">'Student'</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="s">"NewCol"</span><span class="p">)</span>
<span class="c1"># Use heatmap plot
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="n">pcolor</span><span class="p">(</span><span class="n">df_pivot</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s">"RdBu"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/media/15832429806135/15836443731193.jpg" alt="-w500" width="500px" /></p>

<p>he heatmap plots the target variable (price) proportional to colour with respect to the variables ‚Äòdrive-wheel‚Äô and ‚Äòbody-style‚Äô in the vertical and horizontal axis respectively. This allows us to visualize how the price is related to ‚Äòdrive-wheel‚Äô and ‚Äòbody-style‚Äô.</p>

<p>The default labels convey no useful information to us. Let‚Äôs change that:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre></td><td class="rouge-code"><pre><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="n">pcolor</span><span class="p">(</span><span class="n">grouped_pivot</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'RdBu'</span><span class="p">)</span>

<span class="c1">#label names
</span><span class="n">row_labels</span> <span class="o">=</span> <span class="n">grouped_pivot</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="n">levels</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">col_labels</span> <span class="o">=</span> <span class="n">grouped_pivot</span><span class="p">.</span><span class="n">index</span>

<span class="c1">#move ticks and labels to the center
</span><span class="n">ax</span><span class="p">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">grouped_pivot</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">minor</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">grouped_pivot</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">minor</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">#insert labels
</span><span class="n">ax</span><span class="p">.</span><span class="n">set_xticklabels</span><span class="p">(</span><span class="n">row_labels</span><span class="p">,</span> <span class="n">minor</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">set_yticklabels</span><span class="p">(</span><span class="n">col_labels</span><span class="p">,</span> <span class="n">minor</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1">#rotate label if too long
</span><span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>

<span class="n">fig</span><span class="p">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="c1"># Often, we won't have data for some of the pivot cells. We can fill these missing cells with the value 0, but any other value could potentially be used as well. It should be mentioned that missing data is quite a complex subject and is an entire course on its own.
</span><span class="n">grouped_pivot</span> <span class="o">=</span> <span class="n">grouped_pivot</span><span class="p">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
 <span class="c1">#fill missing values with 0
</span><span class="n">grouped_pivot</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="correlation">Correlation</h3>
<h4 id="regressin-plot">regressin plot</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'engine-size'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">'Price'</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/media/15832429806135/15836446867078.jpg" alt="-w400" width="400px" /></p>

<h4 id="pearson-correlation">Pearson Correlation</h4>

<p>P-value:</p>
<ul>
  <li>p-value&lt;0.001, Strong certainty in the result</li>
  <li>p-value&lt;0.05, Moderate certainty in the result</li>
  <li>p-value&lt;0.1, Weak certainty in the result</li>
  <li>p-value&gt;0.1, No certainty in the result</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">pearson_coef</span><span class="p">,</span> <span class="n">p_value</span><span class="o">=</span><span class="n">stats</span><span class="p">.</span><span class="n">pearson</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'horsepower'</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Correlation Heatmap</strong>:
It shows the correlation between any different pair of columns.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>

<span class="c1"># say we want to know the correlations bwtween certain columns
</span><span class="n">df</span><span class="p">[[</span><span class="s">"stroke"</span><span class="p">,</span><span class="s">"price"</span><span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/media/15832429806135/15836450790278.jpg" alt="-w600" width="500px" /></p>

<h3 id="analysis-of-variance-anova">Analysis of Variance (ANOVA)</h3>

<h4 id="statsf_oneway">stats.f_oneway</h4>

<p><img src="/media/15832429806135/15836526973769.jpg" alt="-w600" width="500px" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="c1"># Anova between "honda" and "subaru"
</span><span class="n">df_anova</span><span class="o">=</span><span class="n">df</span><span class="p">[[</span><span class="s">'make'</span><span class="p">,</span><span class="s">'price'</span><span class="p">]]</span>
<span class="n">grouped_anova</span><span class="o">=</span><span class="n">df_anova</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">'make'</span><span class="p">])</span>
<span class="n">anova_results_1</span><span class="o">=</span><span class="n">stats</span><span class="p">.</span><span class="n">f_oneway</span><span class="p">(</span><span class="n">grouped_anova</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'honda'</span><span class="p">)[</span><span class="s">'Price'</span><span class="p">],</span><span class="n">grouped_anova</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'subaru'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">])</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre></td><td class="rouge-code"><pre><span class="n">grouped_test2</span><span class="o">=</span><span class="n">df_gptest</span><span class="p">[[</span><span class="s">'drive-wheels'</span><span class="p">,</span> <span class="s">'price'</span><span class="p">]].</span><span class="n">groupby</span><span class="p">([</span><span class="s">'drive-wheels'</span><span class="p">])</span>
<span class="n">grouped_test2</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># We can obtain the values of the method group using the method "get_group".
</span><span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'4wd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">]</span>

<span class="c1"># ANOVA: we can use the function 'f_oneway' in the module 'stats' to obtain the F-test score and P-value.
</span><span class="n">f_val</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">f_oneway</span><span class="p">(</span><span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'fwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'rwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'4wd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span> <span class="s">"ANOVA results: F="</span><span class="p">,</span> <span class="n">f_val</span><span class="p">,</span> <span class="s">", P ="</span><span class="p">,</span> <span class="n">p_val</span><span class="p">)</span>

<span class="c1"># This is a great result, with a large F test score showing a strong correlation and a P value of almost 0 implying almost certain statistical significance. But does this mean all three tested groups are all this highly correlated?
# Separately: fwd and rwd
</span><span class="n">f_val</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">f_oneway</span><span class="p">(</span><span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'fwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'rwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span> <span class="s">"ANOVA results: F="</span><span class="p">,</span> <span class="n">f_val</span><span class="p">,</span> <span class="s">", P ="</span><span class="p">,</span> <span class="n">p_val</span> <span class="p">)</span>

<span class="c1"># 4wd and rwd
</span><span class="n">f_val</span><span class="p">,</span> <span class="n">p_val</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">f_oneway</span><span class="p">(</span><span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'4wd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">grouped_test2</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'rwd'</span><span class="p">)[</span><span class="s">'price'</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span> <span class="s">"ANOVA results: F="</span><span class="p">,</span> <span class="n">f_val</span><span class="p">,</span> <span class="s">", P ="</span><span class="p">,</span> <span class="n">p_val</span><span class="p">)</span>


</pre></td></tr></tbody></table></code></pre></div></div>
<h4 id="about-get_group">About <code class="language-plaintext highlighter-rouge">Get_group</code></h4>
<p>ÈÄöËøáÂØπDataFrameÂØπË±°Ë∞ÉÁî®groupby()ÂáΩÊï∞ËøîÂõûÁöÑÁªìÊûúÊòØ‰∏Ä‰∏™DataFrameGroupByÂØπË±°ÔºåËÄå‰∏çÊòØ‰∏Ä‰∏™DataFrameÊàñËÄÖSeriesÂØπË±°ÔºåÊâÄ‰ª•ÔºåÂÆÉ‰ª¨‰∏≠ÁöÑ‰∏Ä‰∫õÊñπÊ≥ïÊàñËÄÖÂáΩÊï∞ÊòØÊó†Ê≥ïÁõ¥Êé•Ë∞ÉÁî®ÁöÑÔºåÈúÄË¶ÅÊåâÁÖßGroupByÂØπË±°‰∏≠ÂÖ∑ÊúâÁöÑÂáΩÊï∞ÂíåÊñπÊ≥ïËøõË°åË∞ÉÁî®„ÄÇ</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="n">grouped</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'Gender'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">grouped</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">grouped</span><span class="p">)</span>
<span class="o">&lt;</span><span class="k">class</span> <span class="err">'</span><span class="nc">pandas</span><span class="p">.</span><span class="n">core</span><span class="p">.</span><span class="n">groupby</span><span class="p">.</span><span class="n">groupby</span><span class="p">.</span><span class="n">DataFrameGroupBy</span><span class="s">'&gt;
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p>ÈÄöËøáË∞ÉÁî®get_group()ÂáΩÊï∞ÂèØ‰ª•ËøîÂõû‰∏Ä‰∏™ÊåâÁÖßÂàÜÁªÑÂæóÂà∞ÁöÑDataFrameÂØπË±°ÔºåÊâÄ‰ª•Êé•‰∏ãÊù•ÁöÑ‰ΩøÁî®Â∞±ÂèØ‰ª•ÊåâÁÖß¬∑DataFrame¬∑ÂØπË±°Êù•‰ΩøÁî®„ÄÇÂ¶ÇÊûúÊÉ≥ËÆ©Ëøô‰∏™DataFrameÂØπË±°ÁöÑÁ¥¢ÂºïÈáçÊñ∞ÂÆö‰πâÂèØ‰ª•ÈÄöËøáÔºö</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="n">df</span> <span class="o">=</span> <span class="n">grouped</span><span class="p">.</span><span class="n">get_group</span><span class="p">(</span><span class="s">'Female'</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>

   <span class="n">index</span>   <span class="n">Name</span>  <span class="n">Gender</span>  <span class="n">Age</span>  <span class="n">Score</span>
<span class="mi">0</span>      <span class="mi">2</span>   <span class="n">Cidy</span>  <span class="n">Female</span>   <span class="mi">18</span>     <span class="mi">93</span>
<span class="mi">1</span>      <span class="mi">4</span>  <span class="n">Ellen</span>  <span class="n">Female</span>   <span class="mi">17</span>     <span class="mi">96</span>
<span class="mi">2</span>      <span class="mi">7</span>   <span class="n">Hebe</span>  <span class="n">Female</span>   <span class="mi">22</span>     <span class="mi">98</span>
<span class="err">‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p>ËøôÈáåÂèØ‰ª•ÊÄªÁªì‰∏Ä‰∏ãÔºåÁî±‰∫éÈÄöËøágroupby()ÂáΩÊï∞ÂàÜÁªÑÂæóÂà∞ÁöÑÊòØ‰∏Ä‰∏™DataFrameGroupByÂØπË±°ÔºåËÄåÈÄöËøáÂØπËøô‰∏™ÂØπË±°Ë∞ÉÁî®get_group()ÔºåËøîÂõûÁöÑÂàôÊòØ‰∏Ä‰∏™¬∑DataFrame¬∑ÂØπË±°ÔºåÊâÄ‰ª•ÂèØ‰ª•Â∞ÜDataFrameGroupByÂØπË±°ÁêÜËß£‰∏∫ÊòØÂ§ö‰∏™DataFrameÁªÑÊàêÁöÑ„ÄÇ
ËÄåÊ≤°ÊúâË∞ÉÁî®get_group()ÂáΩÊï∞‰πãÂâçÔºåÊ≠§Êó∂ÁöÑÊï∞ÊçÆÁªìÊûÑ‰ªªÁÑ∂ÊòØDataFrameGroupByÔºåÊ≠§Êó∂ËøõË°åÂØπDataFrameGroupByÊåâÁÖßÂàóÂêçËøõË°åÁ¥¢ÂºïÔºåÂêåÁêÜÂ∞±ÂèØ‰ª•ÂæóÂà∞SeriesGroupByÂØπË±°ÔºåÂèñÂ§ö‰∏™ÂàóÂêçÔºåÂàôÂæóÂà∞ÁöÑ‰ªªÁÑ∂ÊòØDataFrameGroupByÂØπË±°ÔºåËøôÈáåÂèØ‰ª•Á±ªÊØîDataFrameÂíåSeriesÁöÑÂÖ≥Á≥ª„ÄÇ</p>

<h4 id="f-test">F-test</h4>

<p>An F-test is any statistical test in which the test statistic has an F-distribution under the null hypothesis. It is most often used when comparing statistical models that have been fitted to a data set, in order to identify the model that best fits the population from which the data were sampled.</p>

<h5 id="common-examples">Common examples</h5>
<ul>
  <li>The hypothesis that the means of a given set of normally distributed populations, all having the same standard deviation, are equal. This is perhaps the best-known F-test, and plays an important role in the analysis of variance (ANOVA).</li>
  <li>The hypothesis that a proposed regression model fits the data well. See Lack-of-fit sum of squares.</li>
  <li>The hypothesis that a data set in a regression analysis follows the simpler of two proposed linear models that are nested within each other.</li>
</ul>

<h5 id="one-way-analysis">One-way Analysis</h5>
<p>The F-test in one-way analysis of variance is used to assess whether the expected values of a quantitative variable within several pre-defined groups differ from each other.</p>

<p>The formula for the one-way ANOVA F-test statistic is</p>

\[{\displaystyle F={\frac {\text{explained variance}}{\text{unexplained variance}}},}\]

<p>or</p>

\[{\displaystyle F={\frac {\text{between-group variability}}{\text{within-group variability}}}.}\]

<p>The ‚Äúexplained variance‚Äù, or ‚Äúbetween-group variability‚Äù is</p>

\[{\displaystyle \sum _{i=1}^{K}n_{i}({\bar {Y}}_{i\cdot }-{\bar {Y}})^{2}/(K-1)}\]

<p>where \({\displaystyle {\bar {Y}}_{i \cdot }}\) denotes the sample mean in the i-th group, ${ n_{i}}$ is the number of observations in the i-th group,${ {\bar {Y}}}$ denotes the overall mean of the data, and ${ K}$ denotes the number of groups.
The ‚Äúunexplained variance‚Äù, or ‚Äúwithin-group variability‚Äù is</p>

\[{\displaystyle \sum _{i=1}^{K}\sum _{j=1}^{n_{i}}\left(Y_{ij}-{\bar {Y}}_{i\cdot }\right)^{2}/(N-K),}\]

<p>where $Y_{ij}$  is the j-th observation in the i-th out of K groups and N is the overall sample size. This F-statistic follows the F-distribution with degrees of freedom ${ d_{1}=K-1}$ and ${ d_{2}=N-K}$ under the null hypothesis. The statistic will be large if the between-group variability is large relative to the within-group variability, which is unlikely to happen if the population means of the groups all have the same value.</p>

<p>Note that when there are only two groups for the one-way ANOVA F-test, ${F=t^{2}}$ where t is the Student‚Äôs t statistic.</p>

<h2 id="model-development">Model Development</h2>

<h3 id="linear-regression-and-multiple-linear-regression">Linear Regression and Multiple Linear Regression</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="n">lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">Yhat</span><span class="o">=</span><span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1"># check the parameters
</span><span class="n">lm</span><span class="p">.</span><span class="n">intercept_</span>
<span class="n">lm</span><span class="p">.</span><span class="n">coef_</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="model-evaluation-using-visualization">Model Evaluation Using Visualization</h3>
<p><strong>Regression Plot</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'highway-mpg'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Residual Plot</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="n">sns</span><span class="p">.</span><span class="n">residplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'highway-mpg'</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/media/15832429806135/15836574485930.jpg" alt="-w500" width="500px" /></p>

<p><img src="/media/15832429806135/15836574699862.jpg" alt="-w500" width="500px" /></p>

<p><img src="/media/15832429806135/15836574851246.jpg" alt="-w500" width="500px" /></p>

<p><strong>Distribution Plot</strong>
Density function for the target value and predicted value.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">ax1</span><span class="o">=</span><span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span><span class="n">hist</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'r'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">'Actual Value'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">Yhat</span><span class="p">,</span><span class="n">hist</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'b'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">'Fitted Values'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/media/15832429806135/15836578976971.jpg" alt="-w500" width="500px" /></p>

<h3 id="polinomial-regression-and-pipelines">Polinomial Regression and Pipelines</h3>

<h4 id="single-independent-variable">Single independent variable</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="c1"># calculate polynomial of 3rd order
</span><span class="n">f</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="n">p</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="c1"># we can print out the method
</span><span class="k">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="multiple-dimensional-independent-variables">Multiple dimensional independent variables</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="n">pr</span><span class="o">=</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">include_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">result_features</span><span class="o">=</span><span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">include_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="pre-processing">Pre-processing</h4>
<p><strong>Normalize the features:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">SCALE</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">SCALE</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_data</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span><span class="s">'highway-mpg'</span><span class="p">]])</span>
<span class="n">x_scale</span><span class="o">=</span><span class="n">SCALE</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_data</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span><span class="s">'highway-mpg'</span><span class="p">]])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="pipelines">Pipelines</h4>
<p>There are many steps to getting a predction:</p>

<p><img src="/media/15832429806135/15836723392611.jpg" alt="-w600" width="500px" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">Input</span><span class="o">=</span><span class="p">[(</span><span class="s">'scale'</span><span class="p">,</span><span class="n">StandardScaler</span><span class="p">()),</span> <span class="p">(</span><span class="s">'polynomial'</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">include_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)),</span> <span class="p">(</span><span class="s">'model'</span><span class="p">,</span><span class="n">LinearRegression</span><span class="p">())]</span>

<span class="n">pipe</span><span class="o">=</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">Input</span><span class="p">)</span>
<span class="n">pipe</span>

<span class="n">pipe</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>

<span class="n">ypipe</span><span class="o">=</span><span class="n">pipe</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="n">ypipe</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="measure-for-in-sample-evaluation">Measure for In-sample Evaluation</h3>
<p>Two important measures:</p>
<ul>
  <li>Mean Square Error (MSE)</li>
</ul>

\[{ \operatorname {MSE} ={\frac {1}{n}}\sum _{i=1}^{n}(Y_{i}-{\hat {Y_{i}}})^{2}}\]

<ul>
  <li>R-squared</li>
  <li>The total sum of squares (proportional to the variance of the data):</li>
</ul>

\[SS_{\text{tot}}=\sum _{i}(y_{i}-{\bar {y}})^{2}\]

<ul>
  <li>The regression sum of squares, also called the explained sum of squares:</li>
</ul>

\[SS_{\text{reg}}=\sum _{i}(f_{i}-{\bar {y}})^{2}\]

<ul>
  <li>The sum of squares of residuals, also called the residual sum of squares</li>
</ul>

\[{\displaystyle SS_{\text{res}}=\sum _{i}(y_{i}-f_{i})^{2}=\sum _{i}e_{i}^{2}\,}\]

<ul>
  <li>The most general definition of the coefficient of determination is</li>
</ul>

\[{\displaystyle R^{2}\equiv 1-{SS_{\rm {res}} \over SS_{\rm {tot}}}\,}\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span><span class="n">Y_hat</span><span class="p">)</span>

<span class="c1"># we can calculate R^2 as follows
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">lm</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="prediction-and-decision-making">Prediction and Decision Making</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="c1"># First we train the model
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'highway-mpg'</span><span class="p">],</span><span class="n">df</span><span class="p">[</span><span class="s">'prices'</span><span class="p">])</span>
<span class="c1"># Predict the price with 30 highway-mgp
</span><span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="mf">30.0</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="c1"># check the coef and intercetp
</span><span class="n">lm</span><span class="p">.</span><span class="n">coef_</span>
<span class="n">lm</span><span class="p">.</span><span class="n">intercept_</span>

<span class="c1"># Check wether the prediction make sense
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">new_input</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">101</span><span class="p">,</span><span class="mi">1</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">yhat</span><span class="o">=</span><span class="n">lm</span><span class="p">.</span><span class="n">predcit</span><span class="p">(</span><span class="n">new_input</span><span class="p">)</span>
<span class="c1"># use visualization
# Regression Plot
# Residual Plot
# Distribution Plot
# Mean squared error
</span></pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="lab-example">LAB-example</h3>
<h4 id="linear-regression-and-multiple-linear-regression-1">Linear regression and multiple Linear regression</h4>
<p><strong>1. Linear Regression:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td class="rouge-code"><pre><span class="c1"># Setup
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">path</span> <span class="o">=</span> <span class="s">'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/automobileEDA.csv'</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>

<span class="c1"># Load the modules for linear regression
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="n">lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'highway-mpg'</span><span class="p">]]</span>
<span class="c1"># Note!!: X must be a matrix, that's why we keep the dafaframe form here by using df[['col_name']]
</span><span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>

<span class="c1"># Train the model
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="c1"># Predict an output
</span><span class="n">Yhat</span><span class="o">=</span><span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">Yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
<span class="c1"># check the coefs
</span><span class="n">lm</span><span class="p">.</span><span class="n">intercept_</span>
<span class="n">lm</span><span class="p">.</span><span class="n">coefs_</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>2. Multiple Linear Regression</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="n">Z</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]]</span>
<span class="c1"># Still, it is a dataframe (matrix), not a series.
</span>
<span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">lm</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<h4 id="model-evaluation-using-visualization-1">Model Evaluation using Visualization</h4>
<p><strong># 1. Regression Plot</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td class="rouge-code"><pre><span class="c1"># import the visualization package: seaborn
</span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>


<span class="n">width</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">height</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"highway-mpg"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"price"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,)</span>

<span class="c1">#  Use the method ".corr()" to verify the result we conclude from regression plot:
</span><span class="n">df</span><span class="p">[[</span><span class="s">'peak-rpm'</span><span class="p">,</span><span class="s">'highway-mpg'</span><span class="p">,</span><span class="s">'price'</span><span class="p">]].</span><span class="n">corr</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p><strong>2. Residual Plot</strong>:  <code class="language-plaintext highlighter-rouge">sns.residplot</code>
residual VS x plot</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre></td><td class="rouge-code"><pre><span class="n">width</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">height</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">residplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'highway-mpg'</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="c1"># We look at the spread of the residuals:If the points in a residual plot are randomly spread out around the x-axis, then a linear model is appropriate for the data.
</span>
<span class="c1"># For multiple linear regression, we can not use residual plot or the regression plot. Alternatively, we can check the distribution plot
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>3. Distribution Plot</strong>: <code class="language-plaintext highlighter-rouge">sns.distplot()</code></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td class="rouge-code"><pre><span class="n">Z</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'horsepower'</span><span class="p">,</span> <span class="s">'curb-weight'</span><span class="p">,</span> <span class="s">'engine-size'</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">]]</span>
<span class="n">lm</span><span class="o">=</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="n">Y_hat</span> <span class="o">=</span> <span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>


<span class="n">ax1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">hist</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"r"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Actual Value"</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">Yhat</span><span class="p">,</span> <span class="n">hist</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"b"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"Fitted Values"</span> <span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Actual vs Fitted Values for Price'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Price (in dollars)'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Proportion of Cars'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>4. Polinomial Regression and Pipelines</strong>: <code class="language-plaintext highlighter-rouge">polyfit, poly1d</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td class="rouge-code"><pre><span class="c1"># Def the function to draw the shape of model and real data points (X,Y)
</span><span class="k">def</span> <span class="nf">PlotPolly</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">independent_variable</span><span class="p">,</span> <span class="n">dependent_variabble</span><span class="p">,</span> <span class="n">Name</span><span class="p">):</span>
    <span class="n">x_new</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">y_new</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_new</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">independent_variable</span><span class="p">,</span> <span class="n">dependent_variabble</span><span class="p">,</span> <span class="s">'.'</span><span class="p">,</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">y_new</span><span class="p">,</span> <span class="s">'-'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Polynomial Fit with Matplotlib for Price ~ Length'</span><span class="p">)</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gca</span><span class="p">()</span> <span class="c1"># get the current AXE (subplot)
</span>    <span class="n">ax</span><span class="p">.</span><span class="n">set_facecolor</span><span class="p">((</span><span class="mf">0.898</span><span class="p">,</span> <span class="mf">0.898</span><span class="p">,</span> <span class="mf">0.898</span><span class="p">))</span> <span class="c1"># set the facecolor as grey
</span>    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">gcf</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="n">Name</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Price of Cars'</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>

<span class="c1"># get the value
</span><span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'highway-mpg'</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>

<span class="c1"># Here we use a polynomial of the 3rd order (cubic)
</span><span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">poly1d</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="n">PlotPolly</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s">'highway-mpg'</span><span class="p">)</span>


</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>5. Multivariate Polynomial regression</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="n">pr</span><span class="o">=</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">Z_pr</span><span class="o">=</span><span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="c1"># by default, it will include bias
</span>
<span class="c1"># use pipeline
</span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="c1"># we set include_biase=False, because the LinearRegression Model will automatically add intercept here!
</span><span class="n">Input</span><span class="o">=</span><span class="p">[(</span><span class="s">'scale'</span><span class="p">,</span><span class="n">StandardScaler</span><span class="p">()),</span> <span class="p">(</span><span class="s">'polynomial'</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">include_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)),</span> <span class="p">(</span><span class="s">'model'</span><span class="p">,</span><span class="n">LinearRegression</span><span class="p">())]</span>
<span class="c1"># Train the pipeline
</span><span class="n">pipe</span><span class="o">=</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">Input</span><span class="p">)</span>
<span class="n">pipe</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="c1"># Use the pipeline model to predict
</span><span class="n">ypipe</span><span class="o">=</span><span class="n">pipe</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="n">ypipe</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>6. Measures for In-Sample Evaluation</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td class="rouge-code"><pre><span class="c1"># Model 1: Simple Linear Regression
#highway_mpg_fit
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="c1"># Find the R^2
</span><span class="k">print</span><span class="p">(</span><span class="s">'The R-square is: '</span><span class="p">,</span> <span class="n">lm</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">))</span>
<span class="c1"># Find the MSE
</span><span class="n">Yhat</span><span class="o">=</span><span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">Yhat</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The mean square error of price and predicted value is: '</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>
<span class="n">mse</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">Yhat</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The mean square error of price and predicted value is: '</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>

<span class="c1"># Model 2: Multiple Linear Regression
# fit the model
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">])</span>
<span class="c1"># Find the R^2
</span><span class="k">print</span><span class="p">(</span><span class="s">'The R-square is: '</span><span class="p">,</span> <span class="n">lm</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]))</span>
<span class="n">Y_predict_multifit</span> <span class="o">=</span> <span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="n">mse</span><span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">Y_predict_multifit</span><span class="p">)</span>

<span class="c1"># Model 3: Polynomial Fit
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>
<span class="c1"># Notice p(x) is the transformed X
</span><span class="n">r_squared</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'The R-square value is: '</span><span class="p">,</span> <span class="n">r_squared</span><span class="p">)</span>
<span class="n">mse</span><span class="o">=</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">],</span> <span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>7. Prediction and Decision Making</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">new_input</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># fit the model
</span><span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">lm</span>
<span class="c1"># Produce a prediction
</span><span class="n">yhat</span><span class="o">=</span><span class="n">lm</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_input</span><span class="p">)</span>
<span class="n">yhat</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">new_input</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="model-evaluation-and-refinement">Model Evaluation and Refinement</h2>
<p>In-sample evaluation tells us how well our model will fit the data used to train it. Use out-of-sample evaluations or test sets to evaluate and refine the model.</p>

<p><strong>Function:</strong> `train_test_split()</p>
<ul>
  <li>split data into random train and test subsets.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">x_train</span><span class="p">,</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="o">=</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span><span class="n">y_data</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># random_state: number generator used for random sampling
</span></pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="cross-validation">Cross Validation</h3>
<p>In this method, the dataset is split into K equal groups. Each group is referred to as a fold. Some of the folds can be used as a training set which we use to train the model and the remaining parts are used as a test set, which we use to test the model. This is repeated until each partition is used for both training and testing. <strong>At the end, we use the average results as the estimate of out-of-sample error.</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="n">scores</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span><span class="n">x_data</span><span class="p">,</span><span class="n">y_data</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="c1"># the scores is for the test sets!
</span></pre></td></tr></tbody></table></code></pre></div></div>

<ul>
  <li>lr: the type of model we are using</li>
  <li>cv: number of equal partitions/folds</li>
</ul>

<p><img src="/media/15832429806135/15836812040158.jpg" alt="-w500" width="500px" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="c1"># to return the predictions for the cross validation
</span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
<span class="n">yhat</span><span class="o">=</span><span class="n">cross_val_predict</span><span class="p">(</span><span class="n">lr2e</span><span class="p">,</span><span class="n">x_data</span><span class="p">,</span><span class="n">y_data</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># the y_hat is for the test set
</span></pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="/media/15832429806135/15836813766247.jpg" alt="-w300" width="300px" /></p>

<p><img src="/media/15832429806135/15836813880164.jpg" alt="-w300" width="300px" /></p>

<h3 id="overfitting-and-underfitting">Overfitting and Underfitting</h3>

<p><img src="/media/15832429806135/15836818859941.jpg" alt="-w800" width="500px" /></p>

<p>Check the cross-validation score for the test sets.</p>

<p><img src="/media/15832429806135/15836819772880.jpg" alt="-w600" width="500px" /></p>

<p>Use the test sets</p>

<p><img src="/media/15832429806135/15836820288690.jpg" alt="-w600" width="500px" /></p>

<h3 id="ridge-regression">Ridge Regression</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="n">RR</span><span class="o">=</span><span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">RR</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">RR</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p>Add  penalty function to reduce the overfitting problem.</p>

<p>In order to give preference to a particular solution with desirable properties, a regularization term can be included in this minimization:</p>

\[{ \| A \mathbf {x} -\mathbf {b} \|_{2}^{2}+\|\Gamma \mathbf {x} \|_{2}^{2}}\]

<p>for some suitably chosen Tikhonov matrix ${ \Gamma }$ . In many cases, this matrix is chosen as a multiple of the identity matrix (${ \Gamma =\alpha I}$), giving preference to solutions with smaller norms; this is known as L2 regularization.</p>

<p>In other cases, high-pass operators (e.g., a difference operator or a weighted Fourier operator) may be used to enforce smoothness if the underlying vector is believed to be mostly continuous. This regularization improves the conditioning of the problem, thus enabling a direct numerical solution. An explicit solution, denoted by ${ {\hat {x}}}$, is given by
${ {\hat {x}}=(A^{\top }A+\Gamma ^{\top }\Gamma )^{-1}A^{\top }\mathbf {b} .}$</p>

<p>The effect of regularization may be varied by the scale of matrix ${ \Gamma }$ . For ${ \Gamma =0}$ this reduces to the unregularized least-squares solution, provided that (ATA)‚àí1 exists.</p>

<p>L2 regularization is used in many contexts aside from linear regression, such as classification with logistic regression or support vector machines,[14] and matrix factorization.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
</pre></td><td class="rouge-code"><pre><span class="k">print</span><span class="p">(</span><span class="n">__doc__</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span><span class="p">,</span><span class="n">RidgeCV</span>

<span class="kn">import</span> <span class="nn">matplotlib.font_manager</span> <span class="k">as</span> <span class="n">fm</span>
<span class="n">myfont</span> <span class="o">=</span> <span class="n">fm</span><span class="p">.</span><span class="n">FontProperties</span><span class="p">(</span><span class="n">fname</span><span class="o">=</span><span class="s">'C:\Windows\Fonts\simsun.ttc'</span><span class="p">)</span>
<span class="n">data</span><span class="o">=</span><span class="p">[</span>
    <span class="p">[</span><span class="mf">0.607492</span><span class="p">,</span> <span class="mf">3.965162</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.358622</span><span class="p">,</span> <span class="mf">3.514900</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.147846</span><span class="p">,</span> <span class="mf">3.125947</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.637820</span><span class="p">,</span> <span class="mf">4.094115</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.230372</span><span class="p">,</span> <span class="mf">3.476039</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.070237</span><span class="p">,</span> <span class="mf">3.210610</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.067154</span><span class="p">,</span> <span class="mf">3.190612</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.925577</span><span class="p">,</span> <span class="mf">4.631504</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.717733</span><span class="p">,</span> <span class="mf">4.295890</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.015371</span><span class="p">,</span> <span class="mf">3.085028</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.067732</span><span class="p">,</span> <span class="mf">3.176513</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.427810</span><span class="p">,</span> <span class="mf">3.816464</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.995731</span><span class="p">,</span> <span class="mf">4.550095</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.738336</span><span class="p">,</span> <span class="mf">4.256571</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.981083</span><span class="p">,</span> <span class="mf">4.560815</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.247809</span><span class="p">,</span> <span class="mf">3.476346</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.648270</span><span class="p">,</span> <span class="mf">4.119688</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.731209</span><span class="p">,</span> <span class="mf">4.282233</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.236833</span><span class="p">,</span> <span class="mf">3.486582</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.969788</span><span class="p">,</span> <span class="mf">4.655492</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.335070</span><span class="p">,</span> <span class="mf">3.448080</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.040486</span><span class="p">,</span> <span class="mf">3.167440</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.212575</span><span class="p">,</span> <span class="mf">3.364266</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.617218</span><span class="p">,</span> <span class="mf">3.993482</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.541196</span><span class="p">,</span> <span class="mf">3.891471</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">0.526171</span><span class="p">,</span> <span class="mf">3.929515</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.378887</span><span class="p">,</span> <span class="mf">3.526170</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.033859</span><span class="p">,</span> <span class="mf">3.156393</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.132791</span><span class="p">,</span> <span class="mf">3.110301</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.138306</span><span class="p">,</span> <span class="mf">3.149813</span><span class="p">]</span>
<span class="p">]</span>

<span class="c1">#ÁîüÊàêXÂíåyÁü©Èòµ
</span><span class="n">dataMat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># X = dataMat[:,0:1]   # ÂèòÈáèx
</span><span class="n">X</span> <span class="o">=</span> <span class="n">dataMat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">1</span><span class="p">]</span>   <span class="c1"># ÂèòÈáèx
</span><span class="n">y</span> <span class="o">=</span> <span class="n">dataMat</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>   <span class="c1">#ÂèòÈáèy
</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span> <span class="p">,</span><span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="c1"># model = Ridge(alpha=0.5)
</span><span class="n">model</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">alphas</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">])</span>  <span class="c1"># ÈÄöËøáRidgeCVÂèØ‰ª•ËÆæÁΩÆÂ§ö‰∏™ÂèÇÊï∞ÂÄºÔºåÁÆóÊ≥ï‰ΩøÁî®‰∫§ÂèâÈ™åËØÅËé∑ÂèñÊúÄ‰Ω≥ÂèÇÊï∞ÂÄº
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>   <span class="c1"># Á∫øÊÄßÂõûÂΩíÂª∫Ê®°
# print('Á≥ªÊï∞Áü©Èòµ:\n',model.coef_)
# print('Á∫øÊÄßÂõûÂΩíÊ®°Âûã:\n',model)
# print('‰∫§ÂèâÈ™åËØÅÊúÄ‰Ω≥alphaÂÄº',model.alpha_)  # Âè™ÊúâÂú®‰ΩøÁî®RidgeCVÁÆóÊ≥ïÊó∂ÊâçÊúâÊïà
# ‰ΩøÁî®Ê®°ÂûãÈ¢ÑÊµã
</span><span class="n">y_predicted</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'green'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">'ËÆ≠ÁªÉÊï∞ÊçÆ'</span><span class="p">)</span>

<span class="c1"># ÁªòÂà∂Êï£ÁÇπÂõæ ÂèÇÊï∞ÔºöxÊ®™ËΩ¥ yÁ∫µËΩ¥
</span><span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'*'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">'ÊµãËØïÊï∞ÊçÆ'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">prop</span><span class="o">=</span><span class="n">myfont</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s">'r'</span><span class="p">)</span>

<span class="c1"># ÁªòÂà∂xËΩ¥ÂíåyËΩ¥ÂùêÊ†á
</span><span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"x"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"y"</span><span class="p">)</span>

<span class="c1"># ÊòæÁ§∫ÂõæÂΩ¢
</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="grid-search">Grid Search</h3>

<p>Search on the grid of hyperparameters.</p>

<p><img src="/media/15832429806135/15837584720258.jpg" alt="-w600" width="500px" /></p>

<p>We split the data into 3 sets. We use the validation set to find the optimal heperparameter.</p>

<p><img src="/media/15832429806135/15837586290393.jpg" alt="-w600" width="500px" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="n">parameters1</span><span class="o">=</span><span class="p">[{</span><span class="s">'alpha'</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">,</span><span class="mi">1000</span><span class="p">],</span><span class="s">'normalize'</span><span class="p">:[</span><span class="bp">True</span><span class="p">,</span><span class="bp">False</span><span class="p">]}]</span>
<span class="n">RR</span><span class="o">=</span><span class="n">Ridge</span><span class="p">()</span> <span class="c1"># the model object
</span><span class="n">Grid1</span><span class="o">=</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">RR</span><span class="p">,</span><span class="n">parameters1</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># hyperparameters
</span><span class="n">Grid1</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span><span class="n">y_data</span><span class="p">)</span>
<span class="n">Grid1</span><span class="p">.</span><span class="n">best_estimator_</span>

<span class="c1">#check the cross_validation results
</span><span class="n">scores</span><span class="o">=</span><span class="n">Grid1</span><span class="p">.</span><span class="n">cv_results_</span>

<span class="c1">#we can print out the scores for different parameters
</span>
<span class="k">for</span> <span class="n">param</span><span class="p">,</span><span class="n">mean_test</span><span class="p">,</span><span class="n">mean_train</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s">'params'</span><span class="p">],</span><span class="n">scores</span><span class="p">[</span><span class="s">'mean_test_score'</span><span class="p">],</span><span class="n">scores</span><span class="p">[</span><span class="s">'mean_train_score'</span><span class="p">]]:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">param</span><span class="p">,</span><span class="s">"R^2 on test data:"</span><span class="p">,</span><span class="n">mean_test</span><span class="p">,</span><span class="s">"R^2 on train data:"</span><span class="p">,</span><span class="n">mean_train</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Result:</strong></p>

<p><img src="/media/15832429806135/15837589750997.jpg" alt="-w600" width="500px" /></p>

<p><img src="/media/15832429806135/15837589984885.jpg" alt="-w600" width="500px" /></p>

<h2 id="final-assignment">Final Assignment</h2>

<p><strong>House Sales in King County, USA</strong></p>

<p>This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.</p>

<p><b>id</b> :a notation for a house</p>

<p><b> date</b>: Date house was sold</p>

<p><b>price</b>: Price is prediction target</p>

<p><b>bedrooms</b>: Number of Bedrooms/House</p>

<p><b>bathrooms</b>: Number of bathrooms/bedrooms</p>

<p><b>sqft_living</b>: square footage of the home</p>

<p><b>sqft_lot</b>: square footage of the lot</p>

<p><b>floors</b> :Total floors (levels) in house</p>

<p><b>waterfront</b> :House which has a view to a waterfront</p>

<p><b>view</b>: Has been viewed</p>

<p><b>condition</b> :How good the condition is  Overall</p>

<p><b>grade</b>: overall grade given to the housing unit, based on King County grading system</p>

<p><b>sqft_above</b> :square footage of house apart from basement</p>

<p><b>sqft_basement</b>: square footage of the basement</p>

<p><b>yr_built</b> :Built Year</p>

<p><b>yr_renovated</b> :Year when house was renovated</p>

<p><b>zipcode</b>:zip code</p>

<p><b>lat</b>: Latitude coordinate</p>

<p><b>long</b>: Longitude coordinate</p>

<p><b>sqft_living15</b> :Living room area in 2015(implies‚Äì some renovations) This might or might not have affected the lotsize area</p>

<p><b>sqft_lot15</b> :lotSize area in 2015(implies‚Äì some renovations)</p>

<p>You will require the following libraries</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span><span class="n">PolynomialFeatures</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p><strong>Import Data</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="n">file_name</span><span class="o">=</span><span class="s">'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DA0101EN/coursera/project/kc_house_data_NaN.csv'</span>
<span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file_name</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
<span class="n">df</span><span class="p">.</span><span class="n">dtypes</span>
<span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Data Cleaning</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="n">df</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'id'</span><span class="p">,</span><span class="s">'Unnamed: 0'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">"number of NaN values for the column bedrooms :"</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'bedrooms'</span><span class="p">].</span><span class="n">isnull</span><span class="p">().</span><span class="nb">sum</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"number of NaN values for the column bathrooms :"</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'bathrooms'</span><span class="p">].</span><span class="n">isnull</span><span class="p">().</span><span class="nb">sum</span><span class="p">())</span>


<span class="n">mean</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'bedrooms'</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s">'bedrooms'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span><span class="n">mean</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">mean</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s">'bathrooms'</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s">'bathrooms'</span><span class="p">].</span><span class="n">replace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span><span class="n">mean</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"number of NaN values for the column bedrooms :"</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'bedrooms'</span><span class="p">].</span><span class="n">isnull</span><span class="p">().</span><span class="nb">sum</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">"number of NaN values for the column bathrooms :"</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s">'bathrooms'</span><span class="p">].</span><span class="n">isnull</span><span class="p">().</span><span class="nb">sum</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Exploratory Data Analysis</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre><span class="n">df</span><span class="p">[</span><span class="s">'floors'</span><span class="p">].</span><span class="n">value_counts</span><span class="p">().</span><span class="n">to_frame</span><span class="p">()</span>

<span class="n">mydf</span><span class="o">=</span><span class="n">df</span><span class="p">[[</span><span class="s">'waterfront'</span><span class="p">,</span><span class="s">'price'</span><span class="p">]]</span>
<span class="n">sns</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'waterfront'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">mydf</span><span class="p">)</span>


<span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'sqft_above'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="s">'price'</span><span class="p">,</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">[[</span><span class="s">'sqft_above'</span><span class="p">,</span><span class="s">'price'</span><span class="p">]])</span>

<span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">()[</span><span class="s">'price'</span><span class="p">].</span><span class="n">sort_values</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Model Development</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="c1">#  Fit a linear regression model
</span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s">'long'</span><span class="p">]]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>
<span class="n">lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lm</span>
<span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">lm</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># Fit a MLR
</span>
<span class="n">features</span> <span class="o">=</span><span class="p">[</span><span class="s">"floors"</span><span class="p">,</span> <span class="s">"waterfront"</span><span class="p">,</span><span class="s">"lat"</span> <span class="p">,</span><span class="s">"bedrooms"</span> <span class="p">,</span><span class="s">"sqft_basement"</span> <span class="p">,</span><span class="s">"view"</span> <span class="p">,</span><span class="s">"bathrooms"</span><span class="p">,</span><span class="s">"sqft_living15"</span><span class="p">,</span><span class="s">"sqft_above"</span><span class="p">,</span><span class="s">"grade"</span><span class="p">,</span><span class="s">"sqft_living"</span><span class="p">]</span>

<span class="n">Z</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">lm</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">lm</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># Pipeline
</span>
<span class="n">Input</span><span class="o">=</span><span class="p">[(</span><span class="s">'scale'</span><span class="p">,</span><span class="n">StandardScaler</span><span class="p">()),(</span><span class="s">'polynomial'</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">include_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)),(</span><span class="s">'model'</span><span class="p">,</span><span class="n">LinearRegression</span><span class="p">())]</span>

<span class="n">pipe</span><span class="o">=</span><span class="n">Pipeline</span><span class="p">(</span><span class="n">Input</span><span class="p">)</span>
<span class="n">pipe</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">pipe</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>Model Evaluation and refinement</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="k">print</span><span class="p">(</span><span class="s">"done"</span><span class="p">)</span>


<span class="c1"># train_test_split
</span><span class="n">features</span> <span class="o">=</span><span class="p">[</span><span class="s">"floors"</span><span class="p">,</span> <span class="s">"waterfront"</span><span class="p">,</span><span class="s">"lat"</span> <span class="p">,</span><span class="s">"bedrooms"</span> <span class="p">,</span><span class="s">"sqft_basement"</span> <span class="p">,</span><span class="s">"view"</span> <span class="p">,</span><span class="s">"bathrooms"</span><span class="p">,</span><span class="s">"sqft_living15"</span><span class="p">,</span><span class="s">"sqft_above"</span><span class="p">,</span><span class="s">"grade"</span><span class="p">,</span><span class="s">"sqft_living"</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">features</span> <span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'price'</span><span class="p">]</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="k">print</span><span class="p">(</span><span class="s">"number of test samples :"</span><span class="p">,</span> <span class="n">x_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"number of training samples:"</span><span class="p">,</span><span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># Ridge regression
</span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="n">RR</span><span class="o">=</span><span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">RR</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">RR</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>

<span class="c1"># Use polynomial transform
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="n">pr</span><span class="o">=</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">x_train_pr</span><span class="o">=</span><span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span> <span class="c1"># by default, it will include bias
</span><span class="n">x_test_pr</span><span class="o">=</span><span class="n">pr</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="n">RR2</span><span class="o">=</span><span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">RR2</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train_pr</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">RR2</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test_pr</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>
:ET